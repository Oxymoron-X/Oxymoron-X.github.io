<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>高斯混合模型和EM算法</title>
    <url>/2018/gaussian-mixture-model-and-expectation-maximun-algorithm.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="http://7xrrje.com1.z0.glb.clouddn.com/luxury-silver-pen-with-a-business-diary-picjumbo-com.jpg" alt=""><br>本篇文章概览:</p>
<ol>
<li>什么是高斯混合模型</li>
<li>什么是EM算法</li>
<li>如何利用EM算法推导GMM</li>
<li>使用Python实现GMM</li>
</ol>
<a id="more"></a>

<hr>
<h1 id="一-高斯混合模型-GMM"><a href="#一-高斯混合模型-GMM" class="headerlink" title="一. 高斯混合模型(GMM)"></a>一. 高斯混合模型(GMM)</h1><p>高斯混合模型, 英文为Gaussian Mixture Model, 简称GMM, 是一种聚类算法. 它和K-means算法很像, 只不过GMM得到的结果是对概率密度的估计, 是一种软聚类. 那么究竟什么是高斯混合模型呢? 其实顾名思义, 其就假设数据是由多个服从高斯分布的数据混合而成的. 这里究竟有几个高斯分布不能确定, 就像K-means算法里的k值一样, 是一种超参数, 更多时候需要领域知识来决定. 模型中的每一个高斯分布被称为component, 即组分. 每一个组分的概率密度线性叠加就组成了GMM的概率密度函数:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/gmm1.png" alt=""><br>根据上面的式子，如果我们要从 GMM 的分布中随机地取一个点的话，实际上可以分为两步：首先随机地在这 K 个 Component 之中选一个，每个 Component 被选中的概率实际上就是它的系数 $\pi_k$ ，选中了 Component 之后，再单独地考虑从这个 Component 的分布中选取一个点就可以了──这里已经回到了普通的 Gaussian 分布，转化为了已知的问题。<sup>[1]</sup><br>给定一批数据, 我们想用GMM来对这批数据进行聚类. 具体如何做呢? 很简单, 我们只要通过这批数据来得到GMM的概率密度函数即可. 本质上就是通过数据来计算$\pi_k, \mu_k, \sigma_k$等参数.其中, 通过数据来推算概率密度被称作density estimation, 而估算参数被称作parameter estimation.<br>如何估计这些参数? 这就回到我们熟悉的最大似然估计了. 根据概率密度函数, 很容易写出对应的log似然函数:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/gmm2.png" alt=""><br>对于上式, 我们无法像普通的log似然函数那样通过求导来求出最大值. 具体地, 我们通过如下步骤来解决这个问题.</p>
<ol>
<li>估计当前模型下第i个观测数据来自第k个分模型的概率, 称为分模型k对观测数据$y_i$的响应度.<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/gmm3.png" alt=""><br>此时, 假设$\mu_k, \sigma_k$均已知(随机初始值).</li>
<li>利用第一步的$\gamma_i$估计每个组分的参数$\mu_k, \sigma_k$. 直观理解, 可以将看作$x_i$这个值其中有$\gamma(i, k)x_i$这部分是由 组分$k$所生成的, 即组份$k$在生成数据$x_i$时所做的贡献.<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/gmm4.png?imageMogr/v2/thumbnail/!45p" alt=""></li>
<li>不断迭代上面两步, 知道收敛为止.<br>上面这三步其实就是GMM的核心了, 至此我们应该可以轻松的实现GMM的代码了. 不过先不着急, 上面的步骤只是直观地展示了GMM求解的步骤, 那么这些步骤是怎么来的呢? 有没有严格的数学证明? 下面我们就来看看什么是EM算法.</li>
</ol>
<h1 id="二-EM算法"><a href="#二-EM算法" class="headerlink" title="二. EM算法"></a>二. EM算法</h1><p>假定有训练集<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1421.png?imageMogr/v2/thumbnail/!45p" alt=""><br>包含m个独立样本，希望从中找到该组数据的模型p(x,z)的参数.<br>常规操作, 对数似然函数为:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1422.png?imageMogr/v2/thumbnail/!45p" alt=""><br>z是隐随机变量，不方便直接找到参数估计。 策略:计算l(θ)下界，求该下界的最大值; 重复该过程，直到收敛到局部最大值。<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1423.png?imageMogr/v2/thumbnail/!45p" alt=""><br>令$Q_i$是$z$的某一个分布，$Q_i\gt 0$, 有:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1425.png?imageMogr/v2/thumbnail/!45p" alt=""><br>其中最后一步利用了Jensen不等式. 当且仅当$\log(\frac{P}{Q})=c(\text{常数})$时, 等号成立, 即:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1426.png?imageMogr/v2/thumbnail/!45p" alt=""><br>$$P(x^{(i)}, z^{(i)}; \theta)=cQ_i(z^{(i)}) \<br>\<br>\sum_z P(x^{(i)}, z^{(i)}; \theta)=\sum_zcQ_i(z^{(i)}) \<br>\<br>\sum_z P(x^{(i)}, z^{(i)}; \theta)=c \<br>\<br>\frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})}=\sum_z P(x^{(i)}, z^{(i)}; \theta) \<br>\<br>Q_i(z^{(i)})=\frac{P(x^{(i)}, z^{(i)}; \theta)}{\sum_z P(x^{(i)}, z^{(i)}; \theta)}=P(z^{(i)}|x^{(i)};\theta)$$<br>这样我们就推出了$Q_i(z^{(i)})$, 解决了$Q_i(z^{(i)})$如何选择的问题, 这就是E步, 有了$Q_i(z^{(i)})$, 就有了$l$的下界. 在M步中, 我们极大化这个下界. 一般的EM算法的步骤如下：<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1427.png?imageMogr/v2/thumbnail/!45p" alt=""><br>这里值得注意的是, 当我们把似然函数看成是关于$Q$和$\theta$的函数时, 其实我们上面的迭代步骤就是关于$Q$和$\theta$的坐标上升.<br>接下来, 我们来利用EM算法推导GMM.</p>
<h1 id="三-利用EM算法推导GMM"><a href="#三-利用EM算法推导GMM" class="headerlink" title="三. 利用EM算法推导GMM"></a>三. 利用EM算法推导GMM</h1><p>随机变量$X$是有$K$个高斯分布混合而成，取各个高斯分布的概率为$\phi_1, \phi_2… \phi_K$，第$i$个高斯分布的均值为$\mu_i$，方差为$\Sigma_i$。若观测到随机变量$X$的一系列样本$x_1,x_2,…,x_n$试估计参数 $\phi, \mu, \Sigma$。<br>E-step:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1428.png?imageMogr/v2/thumbnail/!45p" alt=""><br>M-step:<br>将多项分布和高斯分布的参数带入:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1429.png?imageMogr/v2/thumbnail/!45p" alt=""><br>对$\mu_l$求偏导:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1430.png?imageMogr/v2/thumbnail/!45p" alt=""><br>令上式=0:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1431.png?imageMogr/v2/thumbnail/!45p" alt=""><br>同理对$\Sigma_j$求偏导并令结果为0可得:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1432.png?imageMogr/v2/thumbnail/!45p" alt=""><br>上面就解决了高斯分布中的参数. 下面看多项分布中的参数.<br>考察M-step的目标函数，对于$\phi$，删除常数项:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1433.png?imageMogr/v2/thumbnail/!45p" alt=""><br>得到:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1434.png?imageMogr/v2/thumbnail/!45p" alt=""><br>由于多项分布的概率和为1，建立拉格朗日方程<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1435.png?imageMogr/v2/thumbnail/!45p" alt=""><br>对$\phi求偏导$:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1437.png?imageMogr/v2/thumbnail/!45p" alt=""><br>令上式等于0:<br>$$\sum_{i=1}^mw_j^{(i)}+\beta\phi_j=0$$<br>$$\sum_{j=1}^k\sum_{i=1}^mw_j^{(i)}+\sum_{j=1}^k\beta\phi_j=0$$<br>$$\sum_{i=1}^m\sum_{j=1}^kw_j^{(i)}+\beta\sum_{j=1}^k\phi_j=0$$<br>$$m+\beta\sum_{j=1}^k\phi_j=0$$<br>$$\beta=-m$$<br>带回式中可得:<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/screenshot_1438.png?imageMogr/v2/thumbnail/!45p" alt=""><br>这样, 我们通过EM算法一步步推导得到了第一节中的结论.<br>到这里, 我们就掌握了GMM和EM算法. 这里还需注意的是, EM算法是一种通用的算法, 常常用于解决含有因变量的参数估计问题. 它不仅可以用在这里的GMM, 在HMM和LDA(Latent Dirichlet Allocation)中, 我们还会看到EM的身影.<br>最后, 附上Python实现GMM的代码.</p>
<h1 id="四-Python实现GMM"><a href="#四-Python实现GMM" class="headerlink" title="四. Python实现GMM"></a>四. Python实现GMM</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.utils <span class="keyword">import</span> shuffle</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GMM</span><span class="params">()</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_components=<span class="number">2</span>, max_iter=<span class="number">100</span>)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.n_comp = <span class="number">2</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.max_iter = max_iter</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.weights_ = []</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.means_ = []</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.covariances_ = []</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m, n = X.shape</span></pre></td></tr><tr><td class="code"><pre><span class="line">        means = [np.random.standard_normal(n) <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_comp)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        sigmas = [np.identity(n) <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_comp)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        pis = [<span class="number">1</span>/self.n_comp <span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_comp)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># EM</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.max_iter):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># E Step</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            predict_gausses = [multivariate_normal(mean, sigma) <span class="keyword">for</span> mean, sigma <span class="keyword">in</span> zip(means, sigmas)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            gauss_sum = <span class="number">0</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="keyword">for</span> pi, predict_gauss <span class="keyword">in</span> zip(pis, predict_gausses):</span></pre></td></tr><tr><td class="code"><pre><span class="line">                gauss_sum += pi * predict_gauss.pdf(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            gammas = [pi * predict_gauss.pdf(X) / gauss_sum <span class="keyword">for</span> pi, predict_gauss <span class="keyword">in</span> zip(pis, predict_gausses)]</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># M Step</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            means = [np.dot(gamma, X) / np.sum(gamma) <span class="keyword">for</span> gamma <span class="keyword">in</span> gammas]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            sigmas = [np.dot(gamma * (X - mean).T, X - mean) / np.sum(gamma) <span class="keyword">for</span> gamma, mean <span class="keyword">in</span> zip(gammas, means)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            pis = [np.sum(gamma) / m <span class="keyword">for</span> gamma <span class="keyword">in</span> gammas]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.weights_ = pis</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.covariances_ = sigmas</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.means_ = means</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> self</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">    mean1, sigma1 = [<span class="number">0</span>, <span class="number">0</span>], [[<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>]]</span></pre></td></tr><tr><td class="code"><pre><span class="line">    mean2, sigma2 = [<span class="number">2</span>, <span class="number">4</span>], [[<span class="number">3</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>]]</span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="comment"># mean1, sigma1 = [0, 0, 0], [[1, 0, 0], [0, 1, 0], [0, 0, 1]]</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="comment"># mean2, sigma2 = [2, 4, 1], [[3, 0, 0], [0, 1, 0], [0, 0, 2]]</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    np.random.seed(<span class="number">8827</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    X1 = np.random.multivariate_normal(mean1, sigma1, <span class="number">500</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    X2 = np.random.multivariate_normal(mean2, sigma2, <span class="number">300</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    y = np.array([<span class="number">1</span>]*<span class="number">500</span> + [<span class="number">0</span>]*<span class="number">300</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    X = np.vstack([X1, X2])</span></pre></td></tr><tr><td class="code"><pre><span class="line">    X, y = shuffle(X, y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    gmm = GMM(n_components=<span class="number">2</span>).fit(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    weight1, weight2 = gmm.weights_</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict_mean1, predict_mean2 = gmm.means_</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict_sigma1, predict_sigma2 = gmm.covariances_</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict_gauss1 = multivariate_normal(predict_mean1, predict_sigma1)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict_gauss2 = multivariate_normal(predict_mean2, predict_sigma2)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict_y1 = predict_gauss1.pdf(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict_y2 = predict_gauss2.pdf(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict1 = (predict_y1 &gt; predict_y2).astype(int)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    predict2 = (predict_y1 &lt; predict_y2).astype(int)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    acc1, acc2 = np.mean(predict1 == y), np.mean(predict2 == y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    print(<span class="string">'accuracy: &#123;&#125;'</span>.format(acc1 <span class="keyword">if</span> acc1 &gt; acc2 <span class="keyword">else</span> acc2))</span></pre></td></tr><tr><td class="code"><pre><span class="line">    fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax = fig.add_subplot(<span class="number">121</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax.set_title(<span class="string">'True'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax.scatter(X[y==<span class="number">1</span>, <span class="number">0</span>], X[y==<span class="number">1</span>, <span class="number">1</span>], c=<span class="string">'r'</span>, s=<span class="number">10</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax.scatter(X[y==<span class="number">0</span>, <span class="number">0</span>], X[y==<span class="number">0</span>, <span class="number">1</span>], c=<span class="string">'b'</span>, s=<span class="number">10</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax = fig.add_subplot(<span class="number">122</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax.set_title(<span class="string">'Predict'</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax.scatter(X[predict1==<span class="number">1</span>, <span class="number">0</span>], X[predict1==<span class="number">1</span>, <span class="number">1</span>], c=<span class="string">'r'</span>, s=<span class="number">10</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ax.scatter(X[predict1==<span class="number">0</span>, <span class="number">0</span>], X[predict1==<span class="number">0</span>, <span class="number">1</span>], c=<span class="string">'b'</span>, s=<span class="number">10</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    plt.show()</span></pre></td></tr></table></figure>
<p>Output:<br>accuracy: 0.9825<br><img src="http://7xrrje.com1.z0.glb.clouddn.com/gmm_output.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<p>参考文献:</p>
<ol>
<li><a href="http://blog.pluskid.org/?p=39" target="_blank" rel="noopener">漫谈 Clustering (3): Gaussian Mixture Model - pluskid</a></li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006924.html" target="_blank" rel="noopener">混合高斯模型（Mixtures of Gaussians）和EM算法 - JerryLead</a></li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>GMM</tag>
        <tag>EM</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning-ai-专项课程二第三周</title>
    <url>/2017/deeplearning-ai-Improving-Deep-Neural-Networks-week3.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1327.png" alt=""><br>这是Andrew Ng在Coursera上的深度学习专项课程中第二门课Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization第一周Practical aspects of Deep Learning 的学习笔记.<br>注: 本课程适合有一定基本概念的同学使用, 如果没有任何基础, 可以先学习Andrew Ng在Coursera上的机器学习课程. 课程见这里: <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera Machine Learning</a>, 这门课程我也做了<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes.html">笔记</a>, 可供参考.</p>
<a id="more"></a>
<hr>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning-ai-专项课程二第二周</title>
    <url>/2017/deeplearning-ai-Improving-Deep-Neural-Networks-week2.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1326.png" alt=""><br>这是Andrew Ng在Coursera上的深度学习专项课程中第二门课Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization第一周Practical aspects of Deep Learning 的学习笔记.<br>注: 本课程适合有一定基本概念的同学使用, 如果没有任何基础, 可以先学习Andrew Ng在Coursera上的机器学习课程. 课程见这里: <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera Machine Learning</a>, 这门课程我也做了<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes.html">笔记</a>, 可供参考.</p>
<a id="more"></a>
<hr>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning-ai-专项课程二第一周</title>
    <url>/2017/deeplearning-ai-Improving-Deep-Neural-Networks-week1.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1325.png" alt=""><br>在深度学习专项课程的第一门课Neural Networks and Deep Learning中, 我们主要学习了深度神经网络中的前向反向传播, 并成功地使用Python+Numpy实现了任意结构的二分类深度神经网络. 而从这次开始我们要学习专项课程中第二门课Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization. 这次的笔记为第一周Practical aspects of Deep Learning, 主要内容包括: 数据集分割, 偏差与方差, 正则化, Normalization,  梯度检查等. 在学完本周的内容后, 我们会使用Python实现不同的权重初始化, L2正则, Dropout正则以及梯度下降.<br>注: 本课程适合有一定基本概念的同学使用, 如果没有任何基础, 可以先学习Andrew Ng在Coursera上的机器学习课程. 课程见这里: <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera Machine Learning</a>, 这门课程我也做了<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes.html">笔记</a>, 可供参考.</p>
<a id="more"></a>
<hr>
<h1 id="一-训练集-验证集与测试集"><a href="#一-训练集-验证集与测试集" class="headerlink" title="一. 训练集, 验证集与测试集"></a>一. 训练集, 验证集与测试集</h1><h2 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h2><p>在训练完一个模型时, 我们需要知道这个模型预测的效果. 此时就需要一个额外的数据集, 我们称为dev/hold out/validation set, 这里我们就统一称之为验证集. 如果我们需要知道模型最终效果的无偏估计, 那么我们还需要一个测试集. 在以往传统的机器学习中, 我们通常按照70/30来数据集分为训练集和验证集, 或者按照60/20/20的比例分为训练集, 验证集和测试集. 但在今天机器学习问题中, 我们可用的数据集的量级非常大(例如有100w个样本). 这时我们就不需要给验证集和测试集太大的比例, 例如98/1/1.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1329.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h2 id="数据源的分布"><a href="#数据源的分布" class="headerlink" title="数据源的分布"></a>数据源的分布</h2><p>在划分数据集中, 有一个比较常见的错误就是不小心使得在训练集中的数据和验证或测试集中的数据来自于不同的分布. 例如我们想要做一个猫的分类器, 在划分数据的时候发现训练集中的图片全都是来自于网页, 而验证集和测试集中的数据全都来自于用户. 这是一种完全错误的做法, 在实际中一定要杜绝.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1330.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="二-偏差-方差"><a href="#二-偏差-方差" class="headerlink" title="二. 偏差, 方差"></a>二. 偏差, 方差</h1><p>关于偏差与方差相比大家都很熟悉了, 在机器学习的课程中也已经学习到. 下面祭出Andrew经典的图例解释:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1331.png?imageMogr/v2/thumbnail/!35p" alt=""><br>我们该如何定位模型所处的问题? 如下图所示, 这里举了四中情况下的训练集和验证集误差. </p>
<ul>
<li>当训练误差很小, 但验证误差和训练误差相差很大时为高方差</li>
<li>当训练误差和验证误差接近且都很大时为高偏差</li>
<li>当训练误差很大, 验证误差更大时为高方差, 高偏差</li>
<li>当训练误差和验证误差接近且都很小时为低方差低偏差</li>
</ul>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1332.png?imageMogr/v2/thumbnail/!35p" alt=""><br>关于高方差高偏差可能是第一次听过, 如下图所示, 整体上模型处于高偏差, 但是对于一些噪声又拟合地很好. 此时就处于高偏差高方差的状态.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1333.png?imageMogr/v2/thumbnail/!35p" alt=""><br>当我们学会定位模型的问题后, 那么该怎样解决对应的问题呢? 见下图:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1334.png?imageMogr/v2/thumbnail/!35p" alt=""><br>若模型高偏差, 我们可以增加模型的复杂度例如使用一个”更大”的网络结构或者训练更久一点. 如模型高方差, 我们可以想办法获取更多的数据, 或者使用接下来我们要讲的正则化.</p>
<h1 id="三-正则化"><a href="#三-正则化" class="headerlink" title="三. 正则化"></a>三. 正则化</h1><p>在以前机器学习课程中已经学过正则化, 这里就不在赘述. </p>
<h2 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h2><p>L2正则化下的Cost Function如下所示, 只需要添加正则项$\frac{\lambda}{2m}\sum_{l=1}^L||w^{[l]}||^2_F$, 其中F代表Frobenius Norm. 在添加了正则项之后, 相应的梯度也要变化, 所以在更新参数的时候需要加上对应的项. 这里注意一点, 我们只对参数w正则, 而不对b. 因为对于每一层来说, w有很高的维度, 而b只是一个标量. w对整个模型的影响远大于b.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1335.png?imageMogr/v2/thumbnail/!35p" alt=""><br>下面给出添加正则项为什么能防止过拟合给出直观的解释. 如下图所示, 当我们的$\lambda$比较大的时候, 模型就会加大对w的惩罚, 这样有些w就会变得很小(L2正则也叫权重衰减, weights decay). 从下图左边的神经网络来看, 效果就是整个神经网络变得简单了, 从而降低了过拟合的风险.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1336.png?imageMogr/v2/thumbnail/!70p" alt=""><br>从另一个角度来看. 以tanh激活函数为例, 当$\lambda$增加时, w会偏小, 这样$z = wa +b$也会偏小, 此时的激活函数大致是线性的. 这样模型的复杂度也就降低了, 即降低了过拟合的风险.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1337.png?imageMogr/v2/thumbnail/!70p" alt=""></p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>dropout也是一种正则化的手段, 在训练时以1-keep_prob随机地”丢弃”一些节点. 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1339.png?imageMogr/v2/thumbnail/!35p" alt=""><br>具体可参考如下实现方式, 在前向传播时将$a$中的某些值置为0, 为了保证大概的大小不受添加dropout影响, 再将处理后的$a$除以keep_prob.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1338.png?imageMogr/v2/thumbnail/!35p" alt=""><br>更多细节请阅读<a href="https://github.com/daniellaah/deeplearning.ai-step-by-step-guide/blob/master/02-Improving-Deep-Neural-Networks/week1/02-regularization/DeepNeuralNetwork.py" target="_blank" rel="noopener">实现代码</a>.</p>
<h2 id="其他正则化"><a href="#其他正则化" class="headerlink" title="其他正则化"></a>其他正则化</h2><p>1.Data augmentation<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1340.png?imageMogr/v2/thumbnail/!35p" alt=""><br>2.Early stopping<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1341.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="四-Normalization"><a href="#四-Normalization" class="headerlink" title="四. Normalization"></a>四. Normalization</h1><p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1342.png?imageMogr/v2/thumbnail/!35p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1343.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="五-Vanishing-Exploding-gradients"><a href="#五-Vanishing-Exploding-gradients" class="headerlink" title="五. Vanishing/Exploding gradients"></a>五. Vanishing/Exploding gradients</h1><p>Vanishing/Exploding gradients指的是随着前向传播不断地进行, 激活单元的值会逐层指数级地增加或减小, 从而导致梯度无限增大或者趋近于零, 这样会严重影响神经网络的训练. 如下图.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1344.png?imageMogr/v2/thumbnail/!35p" alt=""><br>一个可以减小这种情况发生的方法, 就是用有效的参数初始化(该方法并不能完全解决这个问题). 具体可参见<a href="https://github.com/daniellaah/deeplearning.ai-step-by-step-guide/blob/master/02-Improving-Deep-Neural-Networks/week1/01-initialization/DeepNeuralNetwork.py" target="_blank" rel="noopener">代码实现</a><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1345.png?imageMogr/v2/thumbnail/!35p" alt=""><br>更多关于该问题, 也可参考Udacity的Deep Learning课程中的讲解:<a href="https://www.youtube.com/watch?v=VuamhbEWEWA" target="_blank" rel="noopener">Vanishing / Exploding Gradients</a>.</p>
<h1 id="六-梯度检查"><a href="#六-梯度检查" class="headerlink" title="六. 梯度检查"></a>六. 梯度检查</h1><p>待更新…<br><a href="https://github.com/daniellaah/deeplearning.ai-step-by-step-guide/blob/master/02-Improving-Deep-Neural-Networks/week1/03-gradient_checking/DeepNeuralNetwork.py" target="_blank" rel="noopener">代码实现</a></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning.ai 专项课程一第四周</title>
    <url>/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week4.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1305.png" alt=""><br>这是Andrew Ng在Coursera上的深度学习专项课程中第一门课Neural Networks and Deep Learning第四周Deep Neural Networks的学习笔记. 本周的大部分内容在上一周的笔记中都已经覆盖了, 所以本周的笔记会非常简略. 本周重点任务是使用Python要实现一个任意层的神经网络, 并在cat数据上测试.<br>注: 本课程适合有一定基本概念的同学使用, 如果没有任何基础, 可以先学习Andrew Ng在Coursera上的机器学习课程. 课程见这里: <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera Machine Learning</a>, 这门课程我也做了<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes.html">笔记</a>, 可供参考.</p>
<a id="more"></a>
<hr>
<h1 id="一-深度神经网络中的常用符号回顾"><a href="#一-深度神经网络中的常用符号回顾" class="headerlink" title="一. 深度神经网络中的常用符号回顾"></a>一. 深度神经网络中的常用符号回顾</h1><p>在上一周的内容中, 我们已经介绍了神经网络中的常用符号以及各种变量的维度. 这里就不再赘述, 不清楚的可以回顾上周的笔记或视频内容.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1306.png?imageMogr/v2/thumbnail/!20p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1308.png?imageMogr/v2/thumbnail/!20p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1309.png?imageMogr/v2/thumbnail/!35p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1310.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="二-Intuition-about-deep-representation"><a href="#二-Intuition-about-deep-representation" class="headerlink" title="二. Intuition about deep representation"></a>二. Intuition about deep representation</h1><p>关于深度神经网络直观地解释这部分笔记暂略, 请直接观看课程视频内容:<a href="https://www.coursera.org/learn/neural-networks-deep-learning/lecture/rz9xJ/why-deep-representations" target="_blank" rel="noopener">Why deep representation?</a>.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1311.png?imageMogr/v2/thumbnail/!35p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1312.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="三-深度神经网络中的前向-反向传播"><a href="#三-深度神经网络中的前向-反向传播" class="headerlink" title="三. 深度神经网络中的前向/反向传播"></a>三. 深度神经网络中的前向/反向传播</h1><p>在第三周的笔记中详细介绍了神经网络的前向/方向传播, 这里完全套用, 只是多了层数而已. 还不能手推的同学可以仔细研究上周的笔记内容(<a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week3.html">戳我</a>).</p>
<h1 id="四-参数与超参数"><a href="#四-参数与超参数" class="headerlink" title="四. 参数与超参数"></a>四. 参数与超参数</h1><p>在神经网络中参数指的是$W, b$, 这两个参数是通过梯度下降算法不断优化的. 而超参数指的是学习率, 迭代次数, 决定神经网络结构的参数以及激活函数的选择等等, 在后面我们还会提到momentum, minibatch size, regularization等等. 这些都属于超参数, 需要我们手动设定.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1320.png?imageMogr/v2/thumbnail/!35p" alt=""><br>这些超参数也决定了最终的参数$W, b$. 不同的超参数的选择会导致模型很大的差别, 所以超参数的选择也非常重要(后面的课程会讲解如何选择超参数).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1321.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="五-使用Python实现深度神经网络"><a href="#五-使用Python实现深度神经网络" class="headerlink" title="五. 使用Python实现深度神经网络"></a>五. 使用Python实现深度神经网络</h1><p>完成本周内容以及课后作业后, 我们应该可以使用Python+Numpy实现一个任意结构的二分类神经网络. 以下为参考代码, 也可从这里<a href="https://github.com/daniellaah/deeplearning.ai-notes-code/tree/master/Neural%20Networks%20and%20Deep%20Learning/week4" target="_blank" rel="noopener">Github</a>下载.  </p>
<p>DeepNeuralNetwork.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span>+np.exp(-z))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(Z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    A = np.maximum(<span class="number">0</span>,Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">return</span> A</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leaky_relu</span><span class="params">(Z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    A = np.maximum(<span class="number">0</span>,Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    A[Z &lt; <span class="number">0</span>] = <span class="number">0.01</span> * Z</span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">return</span> A</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DeepNeuralNetwork</span><span class="params">()</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layers_dim, activations)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># assert (layers_dim[-1] == 1)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># assert (activations[-1] == 'sigmoid')</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># assert (len(activations) == len(layers_dims)-1)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        np.random.seed(<span class="number">1</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.layers_dim = layers_dim</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.__num_layers = len(layers_dim)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.activations = activations</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.input_size = layers_dim[<span class="number">0</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.parameters = self.__parameters_initializer(layers_dim)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.output_size = layers_dim[<span class="number">-1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parameters_initializer</span><span class="params">(self, layers_dim)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># special initialzer with np.sqrt(layers_dims[l-1])</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        L = len(layers_dim)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        parameters = &#123;&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            parameters[<span class="string">'W'</span>+str(l)] = np.random.randn(layers_dim[l], layers_dim[l<span class="number">-1</span>]) / np.sqrt(layers_dims[l<span class="number">-1</span>])</span></pre></td></tr><tr><td class="code"><pre><span class="line">            parameters[<span class="string">'b'</span>+str(l)] = np.zeros((layers_dim[l], <span class="number">1</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> parameters</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__one_layer_forward</span><span class="params">(self, A_prev, W, b, activation)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        Z = np.dot(W, A_prev) + b</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'sigmoid'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            A = sigmoid(Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'relu'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            A = relu(Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'leaky_relu'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            A = leaky_relu(Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'tanh'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            A = np.tanh(Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        cache = &#123;<span class="string">'Z'</span>: Z, <span class="string">'A'</span>: A&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> A, cache</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward_propagation</span><span class="params">(self, X)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        caches = []</span></pre></td></tr><tr><td class="code"><pre><span class="line">        A_prev = X</span></pre></td></tr><tr><td class="code"><pre><span class="line">        caches.append(&#123;<span class="string">'A'</span>: A_prev&#125;)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># forward propagation by laryer</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, len(self.layers_dim)):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            W, b = self.parameters[<span class="string">'W'</span>+str(l)], self.parameters[<span class="string">'b'</span>+str(l)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            A_prev, cache = self.__one_layer_forward(A_prev, W, b, self.activations[l<span class="number">-1</span>])</span></pre></td></tr><tr><td class="code"><pre><span class="line">            caches.append(cache)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        AL = caches[<span class="number">-1</span>][<span class="string">'A'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> AL, caches</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_cost</span><span class="params">(self, AL, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = Y.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        cost = -np.sum(Y*np.log(AL) + (<span class="number">1</span>-Y)*np.log(<span class="number">1</span>-AL)) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> cost</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(self, X, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># use the result from forward propagation and the label Y to compute cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">assert</span> (self.input_size == X.shape[<span class="number">0</span>])</span></pre></td></tr><tr><td class="code"><pre><span class="line">        AL, _ = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> self.__compute_cost(AL, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sigmoid_backward</span><span class="params">(self, dA, Z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        s = sigmoid(Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ = dA * s*(<span class="number">1</span>-s)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> dZ</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">relu_backward</span><span class="params">(self, dA, Z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ = np.array(dA, copy=<span class="literal">True</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ[Z &lt;= <span class="number">0</span>] = <span class="number">0</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> dZ</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">leaky_relu_backward</span><span class="params">(self, dA, Z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ = np.array(dA, copy=<span class="literal">True</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ[Z &lt;= <span class="number">0</span>] = <span class="number">0.01</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> dZ</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tanh_backward</span><span class="params">(self, dA, Z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        s = np.tanh(Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ = <span class="number">1</span> - s*s</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> dZ</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__linear_backward</span><span class="params">(self, dZ, A_prev, W)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># assert(dZ.shape[0] == W.shape[0])</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># assert(W.shape[1] == A_prev.shape[0])</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = A_prev.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dW = np.dot(dZ, A_prev.T) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        db = np.sum(dZ, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dA_prev = np.dot(W.T, dZ)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> dA_prev, dW, db</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__activation_backward</span><span class="params">(self, dA, Z, activation)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">assert</span> (dA.shape == Z.shape)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'sigmoid'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            dZ = self.sigmoid_backward(dA, Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'relu'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            dZ = self.relu_backward(dA, Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'leaky_relu'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            dZ = self.leaky_relu_backward(dA, Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">if</span> activation == <span class="string">'tanh'</span>:</span></pre></td></tr><tr><td class="code"><pre><span class="line">            dZ = self.tanh_backward(dA, Z)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> dZ</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward_propagation</span><span class="params">(self, caches, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = Y.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        L = self.__num_layers</span></pre></td></tr><tr><td class="code"><pre><span class="line">        grads = &#123;&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># backward propagate last layer</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        AL, A_prev = caches[L<span class="number">-1</span>][<span class="string">'A'</span>], caches[L<span class="number">-2</span>][<span class="string">'A'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dAL =  - (Y/AL - (<span class="number">1</span>-Y)/(<span class="number">1</span>-AL))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        grads[<span class="string">'dZ'</span>+str(L<span class="number">-1</span>)] = self.__activation_backward(dAL, caches[L<span class="number">-1</span>][<span class="string">'Z'</span>], self.activations[<span class="number">-1</span>])</span></pre></td></tr><tr><td class="code"><pre><span class="line">        grads[<span class="string">'dA'</span>+str(L<span class="number">-2</span>)], \</span></pre></td></tr><tr><td class="code"><pre><span class="line">        grads[<span class="string">'dW'</span>+str(L<span class="number">-1</span>)], \</span></pre></td></tr><tr><td class="code"><pre><span class="line">        grads[<span class="string">'db'</span>+str(L<span class="number">-1</span>)] = self.__linear_backward(grads[<span class="string">'dZ'</span>+str(L<span class="number">-1</span>)],</span></pre></td></tr><tr><td class="code"><pre><span class="line">                                                      A_prev, self.parameters[<span class="string">'W'</span>+str(L<span class="number">-1</span>)])</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># backward propagate by layer</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> reversed(range(<span class="number">1</span>, L<span class="number">-1</span>)):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            grads[<span class="string">'dZ'</span>+str(l)] = self.__activation_backward(grads[<span class="string">'dA'</span>+str(l)],</span></pre></td></tr><tr><td class="code"><pre><span class="line">                                                            caches[l][<span class="string">'Z'</span>],</span></pre></td></tr><tr><td class="code"><pre><span class="line">                                                            self.activations[l<span class="number">-1</span>])</span></pre></td></tr><tr><td class="code"><pre><span class="line">            A_prev = caches[l<span class="number">-1</span>][<span class="string">'A'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            grads[<span class="string">'dA'</span>+str(l<span class="number">-1</span>)], \</span></pre></td></tr><tr><td class="code"><pre><span class="line">            grads[<span class="string">'dW'</span>+str(l)], \</span></pre></td></tr><tr><td class="code"><pre><span class="line">            grads[<span class="string">'db'</span>+str(l)] = self.__linear_backward(grads[<span class="string">'dZ'</span>+str(l)], A_prev, self.parameters[<span class="string">'W'</span>+str(l)])</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> grads</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__update_parameters</span><span class="params">(self, grads, learning_rate)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, self.__num_layers):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># assert (self.parameters['W'+str(l)].shape == grads['dW'+str(l)].shape)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># assert (self.parameters['b'+str(l)].shape == grads['db'+str(l)].shape)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            self.parameters[<span class="string">'W'</span>+str(l)] -= learning_rate * grads[<span class="string">'dW'</span>+str(l)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            self.parameters[<span class="string">'b'</span>+str(l)] -= learning_rate * grads[<span class="string">'db'</span>+str(l)]</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, Y, num_iterations, learning_rate, print_cost=False, print_num=<span class="number">100</span>)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># forward propagation</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            AL, caches = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># compute cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            cost = self.__compute_cost(AL, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># backward propagation</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            grads = self.__backward_propagation(caches, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># update parameters</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            self.__update_parameters(grads, learning_rate)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># print cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="keyword">if</span> i % print_num == <span class="number">0</span> <span class="keyword">and</span> print_cost:</span></pre></td></tr><tr><td class="code"><pre><span class="line">                    <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> self</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_prob</span><span class="params">(self, X)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        A, _ = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> A</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, threshold=<span class="number">0.5</span>)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        pred_prob = self.predict_prob(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        threshold_func = np.vectorize(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; threshold <span class="keyword">else</span> <span class="number">0</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        Y_prediction = threshold_func(pred_prob)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> Y_prediction</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(self, X, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        pred = self.predict(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> len(Y[pred == Y]) / Y.shape[<span class="number">1</span>]</span></pre></td></tr></table></figure>

<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> dnn_app_utils_v2 <span class="keyword">import</span> *</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">%matplotlib inline</span></pre></td></tr><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">5.0</span>, <span class="number">4.0</span>) <span class="comment"># set default size of plots</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">%load_ext autoreload</span></pre></td></tr><tr><td class="code"><pre><span class="line">%autoreload <span class="number">2</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">train_x_orig, train_y, test_x_orig, test_y, classes = load_data()</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Explore your dataset</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">m_train = train_x_orig.shape[<span class="number">0</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">num_px = train_x_orig.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">m_test = test_x_orig.shape[<span class="number">0</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"Number of training examples: "</span> + str(m_train))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"Number of testing examples: "</span> + str(m_test))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"Each image is of size: ("</span> + str(num_px) + <span class="string">", "</span> + str(num_px) + <span class="string">", 3)"</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"train_x_orig shape: "</span> + str(train_x_orig.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"train_y shape: "</span> + str(train_y.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"test_x_orig shape: "</span> + str(test_x_orig.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"test_y shape: "</span> + str(test_y.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Reshape the training and test examples</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">train_x_flatten = train_x_orig.reshape(train_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T   <span class="comment"># The "-1" makes reshape flatten the remaining dimensions</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">test_x_flatten = test_x_orig.reshape(test_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Standardize data to have feature values between 0 and 1.</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">train_x = train_x_flatten/<span class="number">255.</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">test_x = test_x_flatten/<span class="number">255.</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"train_x's shape: "</span> + str(train_x.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"test_x's shape: "</span> + str(test_x.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Please note that the above code is from the programming assignment</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> DeepNeuralNetwork</span></pre></td></tr><tr><td class="code"><pre><span class="line">layers_dims = (<span class="number">12288</span>, <span class="number">20</span>, <span class="number">7</span>, <span class="number">5</span>, <span class="number">1</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># layers_dims = (12288, 10, 1)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># layers_dims = [12288, 20, 7, 5, 1] #  5-layer model</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">activations = [<span class="string">'relu'</span>, <span class="string">'relu'</span>, <span class="string">'relu'</span>,<span class="string">'sigmoid'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">num_iter = <span class="number">2500</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">learning_rate = <span class="number">0.0075</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">clf = DeepNeuralNetwork(layers_dims, activations)\</span></pre></td></tr><tr><td class="code"><pre><span class="line">            .fit(train_x, train_y, num_iter, learning_rate, <span class="literal">True</span>, <span class="number">100</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(<span class="string">'train accuracy: &#123;:.2f&#125;%'</span>.format(clf.accuracy_score(train_x, train_y)*<span class="number">100</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(<span class="string">'test accuracy: &#123;:.2f&#125;%'</span>.format(clf.accuracy_score(test_x, test_y)*<span class="number">100</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># output</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 0: 0.771749</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 100: 0.672053</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 200: 0.648263</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 300: 0.611507</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 400: 0.567047</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 500: 0.540138</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 600: 0.527930</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 700: 0.465477</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 800: 0.369126</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 900: 0.391747</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1000: 0.315187</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1100: 0.272700</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1200: 0.237419</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1300: 0.199601</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1400: 0.189263</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1500: 0.161189</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1600: 0.148214</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1700: 0.137775</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1800: 0.129740</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1900: 0.121225</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 2000: 0.113821</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 2100: 0.107839</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 2200: 0.102855</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 2300: 0.100897</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 2400: 0.092878</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># train accuracy: 98.56%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># test accuracy: 80.00%</span></span></pre></td></tr></table></figure>

<p>相关链接: </p>
<ul>
<li><a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">Andrew Ng - deeplearning.ai</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
<li><a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome" target="_blank" rel="noopener">Coursera - Neural Networks and Deep Learning</a></li>
</ul>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning.ai 专项课程一第三周</title>
    <url>/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week3.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1286.png" alt=""><br>这是Andrew Ng在Coursera上的深度学习专项课程中第一课Neural Networks and Deep Learning第三周Shallow Neural Networks的学习笔记. 上周我们说了Logistic Regression是神经网络的基础, 在学习了上周的内容之后, 我们要正式地进入神经网络的学习. 当然, 我们先从简单的只有一个隐藏层的神经网络开始. 在学习完本周内容之后, 我们将会使用Python实现一个单个隐藏层的神经网络, 并在Planar data上测试.<br>注: 本课程适合有一定基本概念的同学使用, 如果没有任何基础, 可以先学习Andrew Ng在Coursera上的机器学习课程. 课程见这里: <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera Machine Learning</a>, 这门课程我也做了<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes.html">笔记</a>, 可供参考.</p>
<a id="more"></a>
<hr>
<h1 id="一-常用符号与基本概念"><a href="#一-常用符号与基本概念" class="headerlink" title="一. 常用符号与基本概念"></a>一. 常用符号与基本概念</h1><p>如下图第三行所示是一个简单的神经网络结构. 在神经网络中我们使用中括号的上角标来表示第几层, 例如$a^{[1]}$表示第一层的激活单元; 使用圆括号的上角标来表示第几个训练样本, 例如$x^{(1)}$表示第一个训练样本.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1287.png?imageMogr/v2/thumbnail/!35p" alt=""><br>该神经网络完全可以使用上一周所讲的计算图来表示, 和LR计算图的区别仅仅在于多了一个$z$和$a$的计算而已. 如果你已经完全掌握了上一周的内容, 那么其实你已经知道了神经网络的前向传播, 反向传播(梯度计算)等等. 要注意的是各种参数, 中间变量($a, z$)的维度问题. 关于神经网络的基本概念, 这里就不赘述了. 见下图回顾一下:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1288.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="二-神经网络中的前向传播"><a href="#二-神经网络中的前向传播" class="headerlink" title="二. 神经网络中的前向传播"></a>二. 神经网络中的前向传播</h1><p>我们先以一个训练样本来看神经网络中的前向传播. 现在我们只看这个神经网络中的输入层和隐藏层的第一个激活单元(如下图右边所示). 其实这就是一个Logistic Regression. 这样一来我们再看神经网络中输入层和隐藏层(不看输出层), 这就不就是四个LR放在一起吗? 在LR中$z$和$a$的计算我们已经掌握了, 那么在神经网络中$z$和$a$又是什么呢? 其实很简单, 我们记隐藏层第一个$z$为$z_1$, 第二个$z$记为$z_2$以此类推. 只要将这四个$z$纵向叠加在一起称为一个列向量即可得到神经网络中这一层的$z$($a$同理).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1289.png?imageMogr/v2/thumbnail/!35p" alt=""><br>那么这一层的$w, b$又是如何得到的? 别忘了, 对于参数$w$来说, 它本身就是一个列项量, 那么它是如何做纵向叠加的呢? 我们只需要将其转置变成一个横向量, 再纵向叠加即可.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1290.png?imageMogr/v2/thumbnail/!35p" alt=""><br>得到隐藏层的$a$之后, 我们可以将其视为输入, 现只看神经网络的隐藏层和输出层, 我们发现这不就是个LR嘛.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1291.png?imageMogr/v2/thumbnail/!35p" alt=""><br>这里总结一下各种变量的维度(注意这里是针对一个训练样本来说的, $n_L代表的L层的节点个数$):</p>
<ul>
<li>$w.shape : (n_L, n_{(L-1)})$</li>
<li>$b.shape : (n_L, 1)$</li>
<li>$z.shape : (n_L, 1)$</li>
<li>$a.shape : (n_L, 1)$</li>
</ul>
<p>那么如果有$m$个训练样本这些变量的维度又是怎样的呢. 我们思考哪些变量的维度会随着样本数的变化二变化. $w$是参数显然它的维度是不会变的. 而输入每一个样本都会有一个$z$和$a$, 还记得$X$的形式吗? 同样地, $Z$就是将每个样本算出来的$z$横向叠加($A$同理). 具体计算过程如下图:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1292.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="三-神经网络中的激活函数"><a href="#三-神经网络中的激活函数" class="headerlink" title="三. 神经网络中的激活函数"></a>三. 神经网络中的激活函数</h1><p>四中常用的激活函数: Sigmoid, Tanh, ReLU, Leaky ReLU. 其中sigmoid我们已经见过了, 它的输出可以看成一个概率值, 往往用在输出层. 对于中间层来说, 往往是ReLU的效果最好.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1296.png?imageMogr/v2/thumbnail/!35p" alt=""><br>以上激活函数的导数请自行在草稿纸上推导.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1297.png?imageMogr/v2/thumbnail/!35p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1298.png?imageMogr/v2/thumbnail/!35p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1299.png?imageMogr/v2/thumbnail/!35p" alt=""><br>为什么需要激活函数? 如果没有激活函数, 那么不论多少层的神经网络都只相当于一个LR. 证明如下:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1300.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="四-神经网络中的反向传播"><a href="#四-神经网络中的反向传播" class="headerlink" title="四. 神经网络中的反向传播"></a>四. 神经网络中的反向传播</h1><p>反向传播最主要的就是计算梯度, 在上一周的内容中, 我们已经知道了LR梯度的计算. 同样地我们使用计算图来计算神经网络中的各种梯度.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1303.png?imageMogr/v2/thumbnail/!35p" alt=""><br>$$dz^{[2]} = \frac{dL}{dz}= \frac{dL}{da^{[2]}}\frac{da^{[2]}}{dz^{[2]}}=a^{[2]}-y$$<br>$$dW^{[2]}=\frac{dL}{dW^{[2]}}=\frac{dL}{dz^{[2]}}\frac{dz^{[2]}}{dW^{[2]}}=dz^{[2]}a^{[1]}$$<br>$$db^{[2]}=\frac{dL}{db^{[2]}}=\frac{dL}{dz^{[2]}}\frac{dz^{[2]}}{db^{[2]}}=dz^{[2]}$$<br>$$dz^{[1]} = \frac{dL}{dz^{[2]}}\frac{dz^{[2]}}{da^{[1]}}\frac{da^{[1]}}{dz^{[1]}}=W^{[2]T}dz^{[2]}*g^{[1]’}(z^{[1]})$$<br>$$dW^{[1]}=\frac{dL}{dW^{[1]}}=\frac{dL}{dz^{[1]}}\frac{dz^{[1]}}{dW^{[1]}}=dz^{[1]}x^T$$<br>$$db^{[1]}=\frac{dL}{db^{[1]}}=\frac{dL}{dz^{[1]}}\frac{dz^{[1]}}{db^{[1]}}=dz^{[1]}$$<br>下图右边为在m个训练样本上的向量化表达:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1304.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="五-神经网络中的参数初始化"><a href="#五-神经网络中的参数初始化" class="headerlink" title="五. 神经网络中的参数初始化"></a>五. 神经网络中的参数初始化</h1><p>在LR中我们的参数$w$初始化为0, 如果在神经网络中也是用相同的初始化, 那么一个隐藏层的每个节点都是相同的, 不论迭代多少次. 这显然是不合理的, 所以我们应该随机地初始化$w$从而解决这个sysmetry breaking problem.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1301.png?imageMogr/v2/thumbnail/!35p" alt=""><br>具体初始化代码可参见下图, 其中乘以$0.01$是为了让参数较小, 加速梯度下降(如激活函数为tanh时, 若参数较大则$z$也较大, 此时的梯度接近于0, 更新缓慢).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1302.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="六-使用Python搭建简单神经网络"><a href="#六-使用Python搭建简单神经网络" class="headerlink" title="六. 使用Python搭建简单神经网络"></a>六. 使用Python搭建简单神经网络</h1><p>完成本周内容以及课后作业后, 我们应该可以使用Python+Numpy实现一个简单的神经网络. 以下为参考代码, 也可从这里<a href="https://github.com/daniellaah/deeplearning.ai-notes-code/tree/master/Neural%20Networks%20and%20Deep%20Learning/week3" target="_blank" rel="noopener">Github</a>下载.  </p>
<p>SimpleNeuralNetwork.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span>+np.exp(-z))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleNeuralNetwork</span><span class="params">()</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="comment"># simple neural network with one hidden layer</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_size, hidden_layer_size)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.paramters = self.__parameter_initailizer(input_size, hidden_layer_size)</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parameter_initailizer</span><span class="params">(self, n_x, n_h)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># W cannot be initialized with zeros</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        W1 = np.random.randn(n_h, n_x) * <span class="number">0.01</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        b1 = np.zeros((n_h, <span class="number">1</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        W2 = np.random.randn(<span class="number">1</span>, n_h) * <span class="number">0.01</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        b2 = np.zeros((<span class="number">1</span>, <span class="number">1</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'W1'</span>: W1,<span class="string">'b1'</span>: b1,<span class="string">'W2'</span>: W2,<span class="string">'b2'</span>: b2&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward_propagation</span><span class="params">(self, X)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        W1 = self.paramters[<span class="string">'W1'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        b1 = self.paramters[<span class="string">'b1'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        W2 = self.paramters[<span class="string">'W2'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        b2 = self.paramters[<span class="string">'b2'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># forward propagation</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        Z1 = np.dot(W1, X) + b1</span></pre></td></tr><tr><td class="code"><pre><span class="line">        A1 = np.tanh(Z1)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        Z2 = np.dot(W2, A1) + b2</span></pre></td></tr><tr><td class="code"><pre><span class="line">        A2 = sigmoid(Z2)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        cache = &#123;<span class="string">'Z1'</span>: Z1,<span class="string">'A1'</span>: A1,<span class="string">'Z2'</span>: Z2,<span class="string">'A2'</span>: A2&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> A2, cache</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_cost</span><span class="params">(self, A2, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = A2.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        cost = -np.sum(Y*np.log(A2) + (<span class="number">1</span>-Y)*np.log(<span class="number">1</span>-A2)) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> cost</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(self, X, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># use the result from forward propagation and the label Y to compute cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        A2, cache = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        cost = self.__compute_cost(A2, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> cost</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward_propagation</span><span class="params">(self, cache, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        A1, A2 = cache[<span class="string">'A1'</span>], cache[<span class="string">'A2'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        W2 = self.paramters[<span class="string">'W2'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = X.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># backward propagation computes gradients</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ2 = A2 - Y</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dW2 = np.dot(dZ2, A1.T) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        db2 = np.sum(dZ2, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dZ1 = np.dot(W2.T, dZ2) * (<span class="number">1</span> - np.power(A1, <span class="number">2</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        dW1 = np.dot(dZ1, X.T) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        db1 = np.sum(dZ1, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        grads = &#123;<span class="string">'dW1'</span>: dW1,<span class="string">'db1'</span>: db1,<span class="string">'dW2'</span>: dW2,<span class="string">'db2'</span>: db2&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> grads</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__update_parameters</span><span class="params">(self, grads, learning_rate)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.paramters[<span class="string">'W1'</span>] -= learning_rate * grads[<span class="string">'dW1'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.paramters[<span class="string">'b1'</span>] -= learning_rate * grads[<span class="string">'db1'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.paramters[<span class="string">'W2'</span>] -= learning_rate * grads[<span class="string">'dW2'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.paramters[<span class="string">'b2'</span>] -= learning_rate * grads[<span class="string">'db2'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, Y, num_iterations, learning_rate, print_cost=False, print_num=<span class="number">100</span>)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># forward propagation</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            A2, cache = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># compute cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            cost = self.cost_function(X, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># backward propagation</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            grads = self.__backward_propagation(cache, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># update parameters</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            self.__update_parameters(grads, learning_rate)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># print cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="keyword">if</span> i % print_num == <span class="number">0</span> <span class="keyword">and</span> print_cost:</span></pre></td></tr><tr><td class="code"><pre><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> self</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_prob</span><span class="params">(self, X)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># result of forward_propagation is the probability</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        A2, _ = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> A2</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, threshold=<span class="number">0.5</span>)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        pred_prob = self.predict_prob(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        threshold_func = np.vectorize(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; threshold <span class="keyword">else</span> <span class="number">0</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        Y_prediction = threshold_func(pred_prob)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> Y_prediction</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(self, X, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        pred = self.predict(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> len(Y[pred == Y]) / Y.shape[<span class="number">1</span>]</span></pre></td></tr></table></figure>

<p>main.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Package imports</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> testCases <span class="keyword">import</span> *</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.datasets</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn.linear_model</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> planar_utils <span class="keyword">import</span> plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets</span></pre></td></tr><tr><td class="code"><pre><span class="line">%matplotlib inline</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">1</span>) <span class="comment"># set a seed so that the results are consistent</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">X, Y = load_planar_dataset()</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Please note that the above code is from the programming assignment</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> SimpleNeuralNetwork</span></pre></td></tr><tr><td class="code"><pre><span class="line">np.random.seed(<span class="number">3</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">num_iter = <span class="number">10001</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">learning_rate = <span class="number">1.2</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">input_size = X.shape[<span class="number">0</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">hidden_layer_size = <span class="number">4</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">clf = SimpleNeuralNetwork(input_size=input_size,</span></pre></td></tr><tr><td class="code"><pre><span class="line">                          hidden_layer_size=hidden_layer_size)\</span></pre></td></tr><tr><td class="code"><pre><span class="line">        .fit(X, Y, num_iter, learning_rate, <span class="literal">True</span>, <span class="number">1000</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">train_acc = clf.accuracy_score(X, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(<span class="string">'training accuracy: &#123;&#125;%'</span>.format(train_acc*<span class="number">100</span>))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># output</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 0: 0.693162</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1000: 0.258625</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 2000: 0.239334</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 3000: 0.230802</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 4000: 0.225528</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 5000: 0.221845</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 6000: 0.219094</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 7000: 0.220628</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 8000: 0.219400</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 9000: 0.218482</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 10000: 0.217738</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># training accuracy: 90.5%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> hidden_layer_size <span class="keyword">in</span> [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">20</span>, <span class="number">50</span>]:</span></pre></td></tr><tr><td class="code"><pre><span class="line">    clf = SimpleNeuralNetwork(input_size=input_size,</span></pre></td></tr><tr><td class="code"><pre><span class="line">                               hidden_layer_size=hidden_layer_size)\</span></pre></td></tr><tr><td class="code"><pre><span class="line">            .fit(X, Y, num_iter, learning_rate, <span class="literal">False</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">    print(<span class="string">'&#123;&#125; hidden units, cost: &#123;&#125;, accuracy: &#123;&#125;%'</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">           .format(hidden_layer_size,</span></pre></td></tr><tr><td class="code"><pre><span class="line">                   clf.cost_function(X, Y),</span></pre></td></tr><tr><td class="code"><pre><span class="line">                   clf.accuracy_score(X, Y)))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># output</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># 1 hidden units, cost: 0.6315593779798304, accuracy: 67.5%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># 2 hidden units, cost: 0.5727606525435293, accuracy: 67.25%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># 3 hidden units, cost: 0.2521014374551156, accuracy: 91.0%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># 4 hidden units, cost: 0.24703039056643344, accuracy: 91.25%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># 5 hidden units, cost: 0.17206481441467936, accuracy: 91.5%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># 20 hidden units, cost: 0.16003869681611513, accuracy: 92.25%</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># 50 hidden units, cost: 0.16000569403994763, accuracy: 92.5%</span></span></pre></td></tr></table></figure>

<h1 id="七-本周内容回顾"><a href="#七-本周内容回顾" class="headerlink" title="七. 本周内容回顾"></a>七. 本周内容回顾</h1><p>通过本周内容的学习, 我们:</p>
<ol>
<li>学习了神经网络的基本概念</li>
<li>掌握了神经网络中各种变量的维度</li>
<li>掌握了神经网络中的前向传播与反向传播</li>
<li>了解了神经网络中的激活函数</li>
<li>学习了神经网络中参数初始化的重要性</li>
<li>掌握了使用Python实现简单的神经网络</li>
</ol>
<p>相关链接: </p>
<ul>
<li><a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">Andrew Ng - deeplearning.ai</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
<li><a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome" target="_blank" rel="noopener">Coursera - Neural Networks and Deep Learning</a></li>
<li><a href="http://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank" rel="noopener">网易微专业 - 深度学习工程师</a></li>
</ul>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning.ai 专项课程一第二周</title>
    <url>/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week2.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1266.png" alt=""><br>这是Andrew Ng在Coursera上的深度学习专项课程中第一课Neural Networks and Deep Learning第二周Neural Networks Basics的学习笔记. 本周我们将要学习Logistic Regression, 它是神经网络的基础. Logistic Regression可以看成是一种只有输入层和输出层(没有隐藏层)的神经网络. 在学习完本周的内容后, 我们将使用Python来实现一个这样的模型, 并将其应用在cat和non-cat的图像识别上.<br>注: 本课程适合有一定基本概念的同学使用, 如果没有任何基础, 可以先学习Andrew Ng在Coursera上的机器学习课程. 课程见这里: <a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">Coursera Machine Learning</a>, 这门课程我也做了<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes.html">笔记</a>, 可供参考.</p>
<a id="more"></a>
<hr>
<h1 id="一-基本概念回顾"><a href="#一-基本概念回顾" class="headerlink" title="一. 基本概念回顾"></a>一. 基本概念回顾</h1><p>这次Andrew出的系列课程在符号上有所改动(和机器学习课程中的行列有所区别, 主要是为了后面代码实现更方便), 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1270.png?imageMogr/v2/thumbnail/!35p" alt=""><br>更多关于本系列课程的符号<a href="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/deeplearningnotation.pdf" target="_blank" rel="noopener">点这里</a>同样地, 参数也有所变化(bias 单独拿出来作为b, 而不是添加$\theta_0$):<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1265.png?imageMogr/v2/thumbnail/!35p" alt=""><br>下图描述了Logistic Regression, 这在机器学习的课程里已经讲的很清楚了, 可以看我之前做的笔记回忆下<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes-Week-3-Logistic-Regression.html">Logistic Regression</a>. 这里需要明确两个概念. 一个是Loss function, 即损失函数, 它代表了对于<strong>一个样本</strong>估计值与真实值之间的误差; 另一个是Cost function, 它代表了所有样本loss的平均值.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1269.png?imageMogr/v2/thumbnail/!35p" alt=""><br>熟悉的梯度下降:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1272.png?imageMogr/v2/thumbnail/!35p" alt=""><br>如果上面提到的知识点都已经掌握了的话, 那么学这门课就没什么问题啦, 不会的赶紧去补.</p>
<h1 id="二-计算图与前向反向传播"><a href="#二-计算图与前向反向传播" class="headerlink" title="二. 计算图与前向反向传播"></a>二. 计算图与前向反向传播</h1><p>在神经网络中, forward propagation 用来计算输出, backward propagation 用来计算梯度, 得到梯度后就可以更新对应的参数了. 为了帮助更好地理解前向反向传播, 我们使用图的方式来描述这两个过程. 首先可以看一个简单的例子$J(a, b, c)=3(a+bc)$, 可用下面的图来表示:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1273.png?imageMogr/v2/thumbnail/!35p" alt=""><br>如上图所示通过前向传播, 我们可以得到$J=33$. 反向传播本质上就是通过链式法则不断求出前面各个变量的导数的过程.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1274.png?imageMogr/v2/thumbnail/!35p" alt=""><br>这里说明一下, 在后面代码实现中, 这些导数都可以用$dvar$来表示, 例如$dw1$, $db1$等等.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1275.png?imageMogr/v2/thumbnail/!35p" alt=""><br>有了计算图的概念之后, 我们将其运用到Logistic Regression上.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1276.png?imageMogr/v2/thumbnail/!35p" alt=""><br>上面的式子可以用下面的计算图来表达:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1277.png?imageMogr/v2/thumbnail/!35p" alt=""><br>有了上面的图之后, 我们现在来计算反向传播.<br>首先我们来计算$\frac{dL}{da}$:<br>$$<br>\begin{align}<br>\frac{dL}{da} &amp; = - (\frac{y}{a} - \frac{(1-y)}{(1-a)})<br>\end{align}<br>$$<br>通过链式法则, 计算$\frac{dL}{dz}$:<br>$$<br>\begin{align}<br>\frac{dL}{dz} &amp; = \frac{dL}{da}\frac{da}{dz} \<br>\<br>&amp; = - (\frac{y}{a} - \frac{(1-y)}{(1-a)})\sigma(z)(1-\sigma(z)) \<br>\<br>&amp; = - (\frac{y}{a} - \frac{(1-y)}{(1-a)})a(1-a)) \<br>\<br>&amp; = -y(1-a) + (1-y)a \<br>\<br>&amp; = a - y<br>\end{align}<br>$$<br>最后计算$\frac{dL}{dw1}, \frac{dL}{dw2}, \frac{dL}{db}$:<br>$$\frac{dL}{dw_1} = \frac{dL}{dz}\frac{dz}{dw_1} = (a - y)x_1$$<br>$$\frac{dL}{dw_2} = \frac{dL}{dz}\frac{dz}{dw_2} = (a - y)x_2$$<br>$$\frac{dL}{db} = \frac{dL}{dz}\frac{dz}{db} = a - y$$<br>怎么样? 是不是很简单呢? 这里我们所有的计算都是针对一个训练样本的. 当然我们不可能只有一个样本, 那么对于整个训练集, 我们应该怎么做呢? 其实很简单, 我们只需要将$J(w, b)$拆开来写就很清晰.<br>$$J(w, b) = \frac{1}{m}(L(a^{(1)}, y^{(1)}) + L(a^{(2)}, y^{(2)}) + … + L(a^{(m)}, y^{m)}))$$<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1279.png?imageMogr/v2/thumbnail/!35p" alt=""><br>对于每一个样本都有一个对应的$dz^{(i)}$, 而对于$dw, db$来说是对于所有求平均.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1280.png?imageMogr/v2/thumbnail/!35p" alt=""></p>
<h1 id="三-向量化"><a href="#三-向量化" class="headerlink" title="三. 向量化"></a>三. 向量化</h1><p>如果用上一节的伪代码来实现梯度计算的话, 效率会非常低. 向量化就是用来解决计算效率问题. 在Andrew机器学习的课程中, 其实已经提到了这个技术, 当时的作业好像并没有强制要求使用向量化. 这次的深度学习系列课程作业, 一律要求使用向量化来实现代码. 配合强大的Numpy, 向量化其实很简单. 来看一个例子:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">a = np.random.rand(<span class="number">1000000</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">b = np.random.rand(<span class="number">1000000</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">tic = time.time()</span></pre></td></tr><tr><td class="code"><pre><span class="line">c = np.dot(a, b)</span></pre></td></tr><tr><td class="code"><pre><span class="line">toc = time.time()</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">print(c)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(<span class="string">'Vectorized version:&#123;&#125;ms'</span>.format(<span class="number">1000</span>*(toc-tic)))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">c = <span class="number">0</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">tic = time.time()</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000000</span>):</span></pre></td></tr><tr><td class="code"><pre><span class="line">    c += a[i] * b[i]</span></pre></td></tr><tr><td class="code"><pre><span class="line">toc = time.time()</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">print(c)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(<span class="string">'For loop:&#123;&#125;ms'</span>.format(<span class="number">1000</span>*(toc-tic)))</span></pre></td></tr></table></figure>
<p>上面代码输出为:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">250187.092541</span></pre></td></tr><tr><td class="code"><pre><span class="line">Vectorized version:1.1589527130126953ms</span></pre></td></tr><tr><td class="code"><pre><span class="line">250187.092541</span></pre></td></tr><tr><td class="code"><pre><span class="line">For loop:424.5340824127197ms</span></pre></td></tr></table></figure>
<p>两个版本效率上差了400多倍. 神经网络本身计算就比较复杂, 加之深度学习训练样本往往都很大, 效率尤为重要. 任何时候都要尽可能避免使用for循环.<br>首先我们进行第一步优化, 将$w$写成向量的形式. $dw=np.zeros((n_x, 1))$, 这样就省去了内层关于$w$的循环.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1281.png?imageMogr/v2/thumbnail/!65p" alt=""><br>接下来我们来看看如何优化关于m个训练样本的循环. 回顾下第一节中所说的$X$:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1270.png?imageMogr/v2/thumbnail/!35p" alt=""><br>将$X$用如上的矩阵表达后, 通过$W^T+b$也就得到了$z$的向量化表达. $a$的向量化表达也就是$z$每个元素进行$\sigma$操作了. 简单吧. 想要把握住向量化一定要清楚每个变量的维度(即python代码里ndarray的shape), 那些是矩阵操作, 那些是element-wise操作等等. 把握住上面的之后, 在代码实现里还要注意哪里会产生’broadcasting’. 例如这里的$b$实际上是一个scalar, 但在进行$W^T+b$操作的时候, $b$被numpy自动broadcasting成和$W^T$维度一样的横向量.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1283.png?imageMogr/v2/thumbnail/!35p" alt=""><br>接下来我们看一下梯度的向量化. 前面我们知道$dz^{(1)}, dz^{(2)}, …, dz^{(m)}$, 这样得到$dZ$. $A, Y$的向量化前面已知了. 这样关于$z$的梯度如下所示. 有了$dZ$之后$db$就很简单了, 它是所有$dZ$中元素的均值. 在python中的代码表示为<code>np.mean(dZ)</code> 或者 <code>1/m * np.sum(a)</code>. $dW$可以通过观察向量的维度得到. $X$为$(n, m)$, $dZ$为$(1,m)$, 而$dW$的维度和$W$的维度一样为$(n,1)$, 这样就得到了$dW=\frac{1}{m}XdZ^T$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1284.png?imageMogr/v2/thumbnail/!35p" alt=""><br>通过上面的努力, 我们将之前for循环的版本改成了完全向量化的表示, 这样向量化实现的代码效率会大大提高. (注意: ppt里的<code>for iter in range(1000)</code> 是迭代次数, 这个循环是不可避免的)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1285.png?imageMogr/v2/thumbnail/!35p" alt=""><br>本周课程剩下部分四个视频分别讲解Broadcasting, Numpy Vector, Jupyter Notebook以及Logistic Regression的概率解释. 如果对于Numpy以及Jupyter Notebook不熟悉的同学需要好好看看这三个视频(配合课后作业相信可以很快上手), 这里我就不做笔记了. 对于最后一个视频, 如果学过Andrew机器学习课程那么也就可以跳过, 相信大家手推Logistic Regression的cost function都没问题.</p>
<h1 id="四-使用Python实现Logistic-Regression进行猫咪识别"><a href="#四-使用Python实现Logistic-Regression进行猫咪识别" class="headerlink" title="四. 使用Python实现Logistic Regression进行猫咪识别"></a>四. 使用Python实现Logistic Regression进行猫咪识别</h1><p>完成本周内容以及课后作业后, 我们应该可以使用Python+Numpy实现一个完整的Logistic Regression, 可以用于任何二分类任务. 以下为参考代码, 也可这里<a href="https://github.com/daniellaah/deeplearning.ai-notes-code/tree/master/Neural%20Networks%20and%20Deep%20Learning/week2" target="_blank" rel="noopener">Github</a>下载.  </p>
<p>LogisticRegression.py:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span>+np.exp(-z))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span><span class="params">()</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">pass</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__parameters_initializer</span><span class="params">(self, input_size)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># initial parameters with zeros</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        w = np.zeros((input_size, <span class="number">1</span>), dtype=float)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        b = <span class="number">0.0</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> w, b</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__forward_propagation</span><span class="params">(self, X)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = X.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        A = sigmoid(np.dot(self.w.T, X) + self.b)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> A</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__compute_cost</span><span class="params">(self, A, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = A.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        cost = -np.sum(Y*np.log(A) + (<span class="number">1</span>-Y)*(np.log(<span class="number">1</span>-A))) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> cost</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost_function</span><span class="params">(self, X, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># use the result from forward propagation and the label Y to compute cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        A = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        cost = self.__compute_cost(A, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> cost</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__backward_propagation</span><span class="params">(self, A, X, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        m = X.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># backward propagation computes gradients</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        dw = np.dot(X, (A-Y).T) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        db = np.sum(A-Y) / m</span></pre></td></tr><tr><td class="code"><pre><span class="line">        grads = &#123;<span class="string">"dw"</span>: dw, <span class="string">"db"</span>: db&#125;</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> grads</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__update_parameters</span><span class="params">(self, grads, learning_rate)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.w -= learning_rate * grads[<span class="string">'dw'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.b -= learning_rate * grads[<span class="string">'db'</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, Y, num_iterations, learning_rate, print_cost=False, print_num=<span class="number">100</span>)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        self.w, self.b = self.__parameters_initializer(X.shape[<span class="number">0</span>])</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># forward_propagation</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            A = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># compute cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            cost = self.__compute_cost(A, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># backward_propagation</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            grads = self.__backward_propagation(A, X, Y)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            dw = grads[<span class="string">"dw"</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            db = grads[<span class="string">"db"</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># update parameters</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            self.__update_parameters(grads, learning_rate)</span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="comment"># print cost</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">            <span class="keyword">if</span> i % print_num == <span class="number">0</span> <span class="keyword">and</span> print_cost:</span></pre></td></tr><tr><td class="code"><pre><span class="line">                <span class="keyword">print</span> (<span class="string">"Cost after iteration &#123;&#125;: &#123;:.6f&#125;"</span>.format(i, cost))</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> self</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict_prob</span><span class="params">(self, X)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="comment"># result of forward_propagation is the probability</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        A = self.__forward_propagation(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> A</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, X, threshold=<span class="number">0.5</span>)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        pred_prob = self.predict_prob(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        threshold_func = np.vectorize(<span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x &gt; threshold <span class="keyword">else</span> <span class="number">0</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        Y_prediction = threshold_func(pred_prob)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> Y_prediction</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy_score</span><span class="params">(self, X, Y)</span>:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">        pred = self.predict(X)</span></pre></td></tr><tr><td class="code"><pre><span class="line">        <span class="keyword">return</span> len(Y[pred == Y]) / Y.shape[<span class="number">1</span>]</span></pre></td></tr></table></figure>
<p>main.py:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> h5py</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> ndimage</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> lr_utils <span class="keyword">import</span> load_dataset</span></pre></td></tr><tr><td class="code"><pre><span class="line">%matplotlib inline</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Loading the data (cat/non-cat)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ### (≈ 3 lines of code)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">m_train = train_set_x_orig.shape[<span class="number">0</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">m_test = test_set_x_orig.shape[<span class="number">0</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line">num_px = train_set_x_orig.shape[<span class="number">1</span>]</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment">### END CODE HERE ###</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"Number of training examples: m_train = "</span> + str(m_train))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"Number of testing examples: m_test = "</span> + str(m_test))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"Height/Width of each image: num_px = "</span> + str(num_px))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"Each image is of size: ("</span> + str(num_px) + <span class="string">", "</span> + str(num_px) + <span class="string">", 3)"</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"train_set_x shape: "</span> + str(train_set_x_orig.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"train_set_y shape: "</span> + str(train_set_y.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"test_set_x shape: "</span> + str(test_set_x_orig.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"test_set_y shape: "</span> + str(test_set_y.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Reshape the training and test examples</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span></pre></td></tr><tr><td class="code"><pre><span class="line">test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment">### END CODE HERE ###</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"train_set_x_flatten shape: "</span> + str(train_set_x_flatten.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"train_set_y shape: "</span> + str(train_set_y.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"test_set_x_flatten shape: "</span> + str(test_set_x_flatten.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"test_set_y shape: "</span> + str(test_set_y.shape))</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">print</span> (<span class="string">"sanity check after reshaping: "</span> + str(train_set_x_flatten[<span class="number">0</span>:<span class="number">5</span>,<span class="number">0</span>]))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">X_train = train_set_x_flatten/<span class="number">255</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">y_train = train_set_y</span></pre></td></tr><tr><td class="code"><pre><span class="line">X_test = test_set_x_flatten/<span class="number">255</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">y_test = test_set_y</span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Please note that the above code is from the programming assignment</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> LogisticRegression</span></pre></td></tr><tr><td class="code"><pre><span class="line">num_iter = <span class="number">2001</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">learning_rate = <span class="number">0.005</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">clf = LogisticRegression().fit(X_train, y_train, num_iter, learning_rate, <span class="literal">True</span>, <span class="number">500</span>)</span></pre></td></tr><tr><td class="code"><pre><span class="line">train_acc = clf.accuracy_score(X_train, y_train)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(<span class="string">'training acc: &#123;&#125;'</span>.format(train_acc))</span></pre></td></tr><tr><td class="code"><pre><span class="line">test_acc = clf.accuracy_score(X_test, y_test)</span></pre></td></tr><tr><td class="code"><pre><span class="line">print(<span class="string">'testing acc: &#123;&#125;'</span>.format(test_acc))</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># output:</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 0: 0.693147</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 500: 0.303273</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1000: 0.214820</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 1500: 0.166521</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># Cost after iteration 2000: 0.135608</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># training acc: 0.9904306220095693</span></span></pre></td></tr><tr><td class="code"><pre><span class="line"><span class="comment"># testing acc: 0.7</span></span></pre></td></tr></table></figure>
<h1 id="五-本周内容回顾"><a href="#五-本周内容回顾" class="headerlink" title="五. 本周内容回顾"></a>五. 本周内容回顾</h1><p>通过本周内容的学习, 我们:</p>
<ul>
<li>了解了深度学习系列课程中使用到的各种符号,</li>
<li>回顾了Logistic Regression,</li>
<li>掌握了loss和cost的区别与联系,</li>
<li>重新认识了前向反向传播, 即计算图,</li>
<li>学习了深度学习中必要的求导知识,</li>
<li>熟悉了Numpy, Jupyter Notebook的使用</li>
<li>掌握了使用Python以神经网络的方式实现Logistic Regression模型, 并使用强大的Numpy来向量化.</li>
</ul>
<p>相关链接: </p>
<ul>
<li><a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">Andrew Ng - deeplearning.ai</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
<li><a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome" target="_blank" rel="noopener">Coursera - Neural Networks and Deep Learning</a></li>
<li><a href="http://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank" rel="noopener">网易微专业 - 深度学习工程师</a></li>
</ul>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning.ai 专项课程一第一周</title>
    <url>/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week1.html</url>
    <content><![CDATA[<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/andrewng-deeplearningai.jpeg" alt=""><br>这是Andrew Ng在Coursera上的深度学习专项课程中第一课Neural Networks and Deep Learning第一周Introduction to deep learning的学习笔记.</p>
<a id="more"></a>
<hr>
<p>本周主要是介绍性的内容, 直接进入下一周的内容吧. <a href="">deeplearning.ai 专项课程第一课第二周</a><br>相关链接: </p>
<ul>
<li><a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">Andrew Ng - deeplearning.ai</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera - Deep Learning Specialization</a></li>
<li><a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome" target="_blank" rel="noopener">Coursera - Neural Networks and Deep Learning</a></li>
<li><a href="http://mooc.study.163.com/smartSpec/detail/1001319001.htm" target="_blank" rel="noopener">网易微专业 - 深度学习工程师</a></li>
</ul>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>deeplearning.ai 深度学习专项课程笔记 - 目录</title>
    <url>/2017/deeplearning.ai-toc.html</url>
    <content><![CDATA[<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_1263.png" alt=""><br>这里会记录我在学习深度学习系列课程中的学习笔记. 我在Github上开了一个<a href="https://github.com/daniellaah/deeplearning.ai-step-by-step-guide" target="_blank" rel="noopener">repo</a>用于分享学习心得, 代码等. 觉得好的话帮忙给个start啦.</p>
<a id="more"></a>
<hr>
<h2 id="课程相关链接"><a href="#课程相关链接" class="headerlink" title="课程相关链接:"></a>课程相关链接:</h2><ul>
<li><a href="https://www.deeplearning.ai/" target="_blank" rel="noopener">deeplearning.ai</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Deep Learning Specialization</a><h2 id="Neural-Networks-and-Deep-Learning"><a href="#Neural-Networks-and-Deep-Learning" class="headerlink" title="Neural Networks and Deep Learning"></a>Neural Networks and Deep Learning</h2></li>
<li><a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week1.html">Week 1: Introduction to deep learning</a></li>
<li><a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week2.html">Week 2: Neural Networks Basics</a></li>
<li><a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week3.html">Week 3: Shallow neural networks</a></li>
<li><a href="http://daniellaah.github.io/2017/deeplearning-ai-Neural-Networks-and-Deep-Learning-week4.html">Week 4: Deep Neural Networks</a></li>
</ul>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Neural Network</tag>
        <tag>Deep Learning</tag>
        <tag>deeplearning.ai</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机总结(上)</title>
    <url>/2017/Support-Vector-Machines-sumup.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/lo_llbs1rs0-jan-senderek.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>支持向量机是一种二类分类模型. 它的基本模型是定义在特征空间上的间隔最大的线性分类器. 间隔最大使它有别与感知机, 核技巧使它成为实质上的非线性分类器. 统计学习方法有三要素, 对于支持向量机来说, 学习策略就是间隔最大化, 而优化方法就是求解凸二次规划的最优算法.<br>支持向量机学习方法包含构建由简至繁的模型: 线性可分支持向量机, 线性支持向量机, 非线性支持向量机.</p>
<table>
<thead>
<tr>
<th align="center">数据</th>
<th align="center">策略</th>
<th align="center">结果</th>
</tr>
</thead>
<tbody><tr>
<td align="center">线性可分</td>
<td align="center">硬间隔最大化</td>
<td align="center">线性可分支持向量机/硬间隔支持向量机</td>
</tr>
<tr>
<td align="center">近似线性可分</td>
<td align="center">软间隔最大化</td>
<td align="center">线性支持向量机/软间隔支持向量机</td>
</tr>
<tr>
<td align="center">线性不可分</td>
<td align="center">软间隔最大化</td>
<td align="center">非线性支持向量机</td>
</tr>
<tr>
<td align="center">核函数表示将输入从输入空间映射到特征空间得到的特征向量之间的内积. 通过核函数, 可以从输入空间学习非线性支持向量机, 其等价于在特征空间中学习线性支持向量机. 这样的方法称为核技巧.</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<a id="more"></a>
<hr>
<h2 id="一-线性可分支持向量机与硬间隔最大化"><a href="#一-线性可分支持向量机与硬间隔最大化" class="headerlink" title="一. 线性可分支持向量机与硬间隔最大化"></a>一. 线性可分支持向量机与硬间隔最大化</h2><p>如下图所示的线性可分分类问题, 在感知机的策略是误分类最小化来求得分离超平面, 通过这个策略可以得到无穷多个解. 例如下图三个解都有可能是感知机得到的结果, 直观上看上去前两个得到的分类超平面都离样本点比较近, 第三个分类超平面离正负样本都比较远. 我们会觉得第三个分类超平面是比较好的, 因为离超平面越远就认为他被分类正确的确信程度越高. 那么有没有办法可以直接找到像第三个分类超平面那样的分类器? 当然有, 这就是线性可分支持向量机.<br>在支持向量机的世界里, 这个距离叫做间隔, 而对于线性可分问题, 间隔又叫做硬间隔. 不同于感知机, 支持向量机的策略就是要使这个硬间隔最大化, 通过这种策略学习到的分类超平面是唯一的. ((截图来自<a href="https://youtu.be/8hak0XngnV0?t=2m56s" target="_blank" rel="noopener">林轩田-机器学习技法-Youtube</a>))<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_746.png" alt=""><br>上面我们提到过, 一个点距离分离超平面的远近可以表示分类预测的确信程度. 在超平面$w\cdot x + b=0$确定的情况, $|w\cdot x + b|$能够相对地表示$x$距离超平面的远近. 而$w\cdot x+b$的符号与类标记$y$的符号是否一致能够表示分类是否正确.<br>所以可用向量$y(w\cdot x+b)$来表示分类的正确性及确信度, 这就是函数间隔. 但是对$w,b$成比例地改变可以对函数间隔进行任意的缩放(并不影响超平面本身), 所以需要几何间隔$\gamma_i=y_i\left(\frac{w}{\Vert w\Vert}\cdot x+ \frac{b}{\Vert w\Vert}\right)$. 对于一个数据集的函数间隔和几何间隔分别定义为所有样本对超平面的函数间隔和几何间隔的最小值. 几何间隔与函数间隔的关系为:<br>$$\gamma_{i}=\frac{\hat{\gamma}_{i}}{\Vert w\Vert}.$$<br>间隔最大化的直观解释是: 对训练数据集找到几何间隔最大的超平面意味着以充分大的确信度对训练数据进行分类, 也就是说, 不仅将正负实例点分开, 而且对最难分的实例点(离超平面最近的点)也有足够大的确信度将它们分开. 这样的超平面应该对未知的新实例有很好的分类预测能力.<br>下面就开始推导如何用约束优化问题来表示如何求一个几何间隔最大分离超平面.<br>首先, 我们想要几何间隔最大:<br>$$<br>\begin{align}<br>\max_{w,b} &amp;\quad \gamma \<br>\<br>s.t. &amp;\quad y_{i}(\frac{w}{\Vert w\Vert}\cdot x_i+ \frac{b}{\Vert w\Vert})\ge\gamma, \quad i=1,2,…,N \<br>\end{align}<br>$$<br>利用几何间隔和函数间隔的关系, 我们可以将上式改写为:<br>$$<br>\begin{align}<br>\max_{w,b} &amp;\quad \frac{\hat{\gamma}}{\Vert w\Vert} \<br>\<br>s.t. &amp;\quad y_{i}({w}\cdot x_i+ {b})\ge\hat{\gamma}, \quad i=1,2,…,N \<br>\end{align}<br>$$<br>前面我们也提到了, 可以在不改变分类超平面本身的情况下对函数间隔进行缩放,  那么这里可以直接令$\hat{\gamma}=1$, 并且最大化$\frac{1}{\Vert w\Vert}$和最小化$\frac12\Vert w\Vert^2$是等价的. 如此, 我们得到了最终的优化问题:<br>$$<br>\begin{align}<br>\min_{w,b} &amp;\quad {\frac12}||w||^2  \<br>\<br>s.t. &amp;\quad y_{i}(w\cdot x_{i}+b)-1\ge =0<br>\end{align}<br>$$<br>为了求解上述最优化问题, 我们将它作为原始最优化问题, 应用拉格朗日对偶性, 通过求解对偶问题得到原始问题的最优解. 这样做有两个优点, 一是对偶问题往往更容易求解; 二是自然引入核函数, 进而推广到非线性分类问题.<br>首先建立拉格朗日函数. 对每一个不等式约束引进拉格朗日乘子$\alpha_i\ge 0, i=1,2,…,N$, 约束为:<br>$$-y_{i}(w^Tx_{i}+b)+1\le0.$$<br>得到拉格朗日函数:<br>$$\mathcal{L}(w,b,\alpha)=\frac12\Vert w \Vert^2 - \sum_{i=1}^N\alpha_i\left[y_{i}(w\cdot x_{i}+b)-1\right]$$<br>根据拉格朗日对偶性, 原始问题的对偶问题是极大极小问题:<br>$$\max_{\alpha}\min_{w,b}\mathcal{L}(w,b,\alpha)$$<br>所以, 为了得到对偶问题的解, 需要先求$\mathcal{L}(w,b,\alpha)$对$w,b$的极小, 再求对$\alpha$的极大.<br>首先, 求$\mathcal{L}(w,b,\alpha)$关于$w,b$的最小值. 令偏导为0:<br>$$<br>\frac{\partial\mathcal{L}}{\partial w}=w-\sum_{i=1}^n\alpha_iy_{i}x_{i}=0, \<br>\frac{\partial\mathcal{L}}{\partial b}=0-\sum_{i=1}^n\alpha_iy_{i}=0.<br>$$<br>可得:<br>$$<br>w=\sum_{i=1}^n\alpha_iy_{i}x_{i}, \<br>\sum_{i=1}^m\alpha_iy_{i}=0.<br>$$<br>再将求得的$w$带回$\mathcal{L}(w,b,\alpha)$可得到$\mathop\min_{w,b}\mathcal{L}(w,b,\alpha)$:<br>$$<br>\begin{align}<br>&amp; \mathop\min_{w,b}\mathcal{L}(w,b,\alpha)  \\<br>\<br>&amp; =\frac12(\sum_i^n\alpha_iy_ix_i)(\sum_j^n\alpha_jy_jx_j) - (\sum_i^n\alpha_iy_ix_i)(\sum_j^n\alpha_jy_jx_j)+(\sum_i^n\alpha_iy_ib) + \sum_i^n\alpha_i \<br>\<br>&amp; = -\frac12(\sum_i^n\alpha_iy_ix_i)(\sum_j^n\alpha_jy_jx_j) + b\sum_i^n\alpha_iy_i + \sum_i^n\alpha_i \<br>\<br>&amp; = \sum_i^n\alpha_i  - \frac12\sum_i^n\sum_j^n\alpha_i\alpha_jy_iy_jx_i^Tx_j \<br>\<br>&amp; = \sum_i^n\alpha_i  - \frac12\sum_i^n\sum_j^n\alpha_i\alpha_jy_iy_j\langle x_i,x_j\rangle<br>\end{align}<br>$$<br>有了$\mathop\min_{w,b}\mathcal{L}(w,b,\alpha)$, 我们便可进行极大操作, 即:<br>$$<br>\begin{align}<br>\max_{\alpha} &amp; \quad W(\alpha)=\sum_i^n\alpha_i  - \frac12\sum_i^n\sum_j^n\alpha_i\alpha_jy_iy_j\langle x_i,x_j\rangle \<br>\<br>\text{s.t.} &amp; \quad \alpha_i\ge 0, i=1,…,n \<br>\<br>&amp; \quad \sum_{i=1}^n\alpha_iy_i=0<br>\end{align}<br>$$<br>这就是我们最终的优化目标, 这样线性可分支持向量机就只剩下如何求解这个最优化问题了.</p>
<h2 id="二-线性支持向量机与软间隔最大化"><a href="#二-线性支持向量机与软间隔最大化" class="headerlink" title="二. 线性支持向量机与软间隔最大化"></a>二. 线性支持向量机与软间隔最大化</h2>]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(十) - Learning Theory</title>
    <url>/2017/CS229-ML-Notes-Lecture-9.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/lo_llbs1rs0-jan-senderek.jpg?imageMogr2/thumbnail/!50p" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a></p>
<a id="more"></a>
<hr>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(九)-SVM之SMO算法</title>
    <url>/2016/CS229-ML-Notes-Lecture-8-2.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/lo_llbs1rs0-jan-senderek.jpg?imageMogr2/thumbnail/!50p" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a><br>相关阅读:</p>
<ol>
<li><a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">支持向量机系列-pluskid</a>(强烈推荐)</li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988415.html" target="_blank" rel="noopener">支持向量机(四)-JerryLead</a>(强烈推荐)</li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html" target="_blank" rel="noopener">支持向量机(五)-JerryLead</a>(强烈推荐)</li>
<li><a href="http://logos.name/archives/304" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记五：支持向量机 Support Vector Machines</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9798843" target="_blank" rel="noopener">核技法、软间隔分类器、SMO算法——斯坦福ML公开课笔记8</a></li>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记</a><a id="more"></a>
</li>
</ol>
<hr>
<p>接上篇: <a href="http://daniellaah.github.io/2016/CS229-Machine-Learning-Notes-Lecture-8-1.html">CS229机器学习笔记(七)-SVM之软间隔</a></p>
<p>在将SMO之前, 我们先来看看什么是坐标上升法(coordinate ascent).</p>
<h1 id="坐标上升"><a href="#坐标上升" class="headerlink" title="坐标上升"></a>坐标上升</h1><p>假设我们有如下的优化问题:<br>$$\mathop{max}_\alpha W(\alpha_1, \alpha_2, … , \alpha_m).$$<br>先撇开SVM不谈, 这里的$W$是$\alpha_i$的一个函数. 我们前面已经看过了两种优化算法, 一种是梯度下降(gradient descent), 另一种是牛顿方法(Newton’s method). 现在我们所要说的是第三种优化算法, 坐标上升法(coordinate ascent):<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_765.png" alt=""><br>上面是该算法的过程, 在内循环中, 每次固定除了第i个$\alpha$, 即,将$W$看成只关于第$i$个$\alpha$的函数. 然后对第$i$个$\alpha$进行优化, 然后依次对下一个$\alpha$进行优化:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_766.png" alt=""><br>这里提一点, 优化$\alpha$的顺序是可以改变的, 取决于你觉得下一次优化哪一个$\alpha$会带来最大的进步.<br>相对其他优化算法来讲, 坐标上升需要更多的迭代次数来收敛. 但它的优点就是在于内循环的计算非常简单.</p>
<h1 id="序列最小优化算法"><a href="#序列最小优化算法" class="headerlink" title="序列最小优化算法"></a>序列最小优化算法</h1><p>SVM终于接近尾声了…<br>前面有一个问题一直没有解决, 就是如何求解这个优化问题:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_763.png" alt=""><br>这一节的标题序列最小优化算法(Sequential minimal optimazation)就是用来解决这个优化问题的. 刚才讲的coordinate ascend现在自然要用到啦.<br>在刚才讲的coordinate ascend中, 我们每次固定除了某一个变量之外的所有变量, 将优化目标看成仅仅是这一个没有固定变量的函数, 再对该变量进行优化. 在SVM中, 好像也可以直接这么用. 但是别忘了, SVM的优化是有约束条件的:<br>$$\sum_{i=1}^m\alpha_iy^{(i)}=0.$$<br>有这个约束条件的存在, 我们就不可能改变其中一个而固定其他所有. 那该怎么办?<br>很简单, 在SVM中, 我们每次改变两个$\alpha$, 固定其他所有的. 这个算法就叫SMO(sequential minimal optimazation)算法, 其中minimal指的就是每次改变2个$\alpha$. 具体算法的过程如下:<br>1.选择两个变量$\alpha_i$和$\alpha_j$,<br>2.固定其他所有变量, 将$W(\alpha)$看成仅是关于$\alpha_i$和$\alpha_j$的函数对$W(\alpha)$进行优化<br>下面我们使用$\alpha_1$和$\alpha_2$做一个具体的例子来看看.<br>由$\sum_{i=1}^m\alpha_iy^{(i)}=0$, 我们可以得到:<br>$$\alpha_1y^{(1)}+\alpha_2y^{(2)}=-\sum_{i=3}^m\alpha_iy^{(i)}.$$<br>我们令:<br>$$-\sum_{i=3}^m\alpha_iy^{(i)}=\zeta$$<br>即:<br>$$\alpha_1y^{(1)}+\alpha_2y^{(2)}=\zeta$$<br>我们可以用下图画出$\alpha_1$和$\alpha_2$的约束(注意不要忘了$0\le\alpha_i\le C$):<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_767.png" alt=""><br>由$\alpha_1y^{(1)}+\alpha_2y^{(2)}=\zeta$我们可以得到:<br>$$\alpha_1 = \frac{\zeta-\alpha_2y^{(2)}}{y^{(1)}}.$$<br>这个时候, $W$就可以写成:<br>$$W(\alpha)=W(\frac{\zeta-\alpha_2y^{(2)}}{y^{(1)}}, \alpha_2, …, \alpha_m).$$<br>前面也说了$W(\alpha)$是一个二次函数, 我们现在把$W$看成仅仅是关于$\alpha_2$的函数的话, $W$就变成了关于$\alpha_2$的一元二次函数, 这个时候求最值就很简单了. </p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>CS229</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(八)-SVM之软间隔</title>
    <url>/2016/CS229-ML-Notes-Lecture-8-1.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/s2du5grogtc-martin-ezequiel-sanchez.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a><br>相关阅读:</p>
<ol>
<li><a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">支持向量机系列-pluskid</a>(强烈推荐)</li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988415.html" target="_blank" rel="noopener">支持向量机(四)-JerryLead</a>(强烈推荐)</li>
<li><a href="http://logos.name/archives/304" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记五：支持向量机 Support Vector Machines</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9798843" target="_blank" rel="noopener">核技法、软间隔分类器、SMO算法——斯坦福ML公开课笔记8</a></li>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记</a><a id="more"></a>
</li>
</ol>
<hr>
<p>接上篇: <a href="http://daniellaah.github.io/2016/CS229-Machine-Learning-Notes-Lecture-8.html">CS229机器学习笔记(七)-SVM之Kernels</a></p>
<h1 id="软间隔分类器"><a href="#软间隔分类器" class="headerlink" title="软间隔分类器"></a>软间隔分类器</h1><p>软间隔分类器(soft margin classifier)可以解决两种情况.<br>前面我们都假定数据是线性可分的, 但实际上数据即使映射到了高维也不一定是线性可分. 这个时候就要对超平面进行一个调整, 即这里所说的软间隔.<br>另一种情况是即使数据是线性可分的,  但数据中可能存在噪点. 而如果按照前面那种常规处理的话, 这些噪点会对我们的结果造成很大的影响.这个时候也是需要使用软间隔来尽可能减少噪点对我们的影响.<br>如下图所示, 如果数据是线性可分并且不存在噪点的话, 我们可以找到一个完美的分类超平面:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_759.png" alt=""><br>但是, 如果数据中出现了一个噪点并且仍然是线性可分, 如果我们还是按照之前的办法处理, 那么我们就会得到如下的分类超平面, 这明显是不合理的.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_760.png" alt=""><br>现在我们对原来的优化做一个处理:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_761.png" alt=""><br>我们在限制条件中添加了一个非负的$\xi$, 这样我们就允许某些点的函数间隔小于一甚至是在对方的区域. 当然, 我们不能只在限制条件中加上$\xi$, 还要在优化目标中对$\xi$进行惩罚, 使得所有$\xi$的和尽可能小.<br>有了这个优化目标后, 我们按照之前学的拉格朗日对偶的知识来求解.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_762.png" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_763.png" alt=""><br>我们发现, $(\alpha)$和原来唯一的区别就在于多了一个$\alpha_i\le C$这个限制条件. (这里需要注意的是$b^\ast$的公式也有变化, 后面再说)KKT对偶互补条件为:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_764.png" alt=""><br>现在唯一的问题就是如何解决$W(\alpha)$了, 相关的内容放在下一篇进行介绍.</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>CS229</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(七)-SVM之Kernels</title>
    <url>/2016/CS229-ML-Notes-Lecture-8.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/wazehlrp98s-jamison-mcandie.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a><br>相关阅读:</p>
<ol>
<li><a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">支持向量机系列-pluskid</a>(强烈推荐)</li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/18/1988406.html" target="_blank" rel="noopener">支持向量机(三)核函数-JerryLead</a>(强烈推荐)</li>
<li><a href="http://logos.name/archives/304" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记五：支持向量机 Support Vector Machines</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9798843" target="_blank" rel="noopener">核技法、软间隔分类器、SMO算法——斯坦福ML公开课笔记8</a></li>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记</a><a id="more"></a>
</li>
</ol>
<hr>
<p>接上篇: <a href="http://daniellaah.github.io/2016/CS229-Machine-Learning-Notes-Lecture-7.html">CS229机器学习笔记(六)-SVM之拉格朗日对偶, 最优间隔分类器</a></p>
<h1 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h1><p>在我们讨论线性回归的时候, 提到过<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes-Week-2-Linear-Regression-with-Multiple-Variables.html">polynomial regression</a>. 假设$x$是房子的面积, 我们使用三个特征$x, x^2, x^3$来构造一个三次多项式. 这里有两个概念要区分一下. 这里房子的面积$x$叫做属性(attribute), 我们通过这个$x$映射得到的$x, x^2, x^3$叫做特征(feature). 我们使用$\phi$来表示这种从属性到特征的特征映射(feature mapping). 例如, 在这个例子中:<br>$$\phi(x) = \begin{bmatrix}  x \\ x^2 \\ x^3 \end{bmatrix}$$<br>那么在SVM中, 我们该如何使用这种特征映射呢? 很简单, 通过上一讲的知识, 我们应该知道只需要将所有出现$\langle x^{(i)}, x^{(j)}\rangle$替换为$\langle\phi(x^{(i)}), \phi(x^{(j)})\rangle$就可以了.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_897.png" alt=""><br>看上去好像我们既在SVM中使用了特征映射, 又解决了数据在低维空间中线性不可分的情况. 但是, 这里有个问题. 如果我们通过特征映射得到的$\phi(x)$是一个很高维甚至是无穷维的, 那么计算$\langle\phi(x^{(i)}), \phi(x^{(j)})\rangle$就不是那么现实了. 这里我们就要引出一个叫kernels的概念.<br>假设$x, z\in \mathbb{R}^n$, $K(x,z)=(x^Tz)^2.$, 展开$K(x,z)$:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_755.png" alt=""><br>展开后我们发现, $K(x,z)$还可以写成$K(x,z)=\phi(x)^T\phi(z)$, 其中:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_756.png" alt=""><br>在这个例子中, 映射后特征的内积和原始特征的内积的平方是等价的. 也就是说, 我们只需要计算原始特征的内积再进行平方就可以了, 并不需要先得到映射后的特征再计算映射后特征的内积. 计算原始特征内积的时间复杂度为$\mathcal{O}(n)$, 而计算映射特征$\phi(x)$的时间复杂度为$\mathcal{O}(x^2)$.<br>我们再来看另一个kernels:<br>$$<br>\begin{align}<br>K(x,z) &amp; =(x^Tz+c)^2 \<br>&amp; = \sum_{i,j=1}^n(x_ix_j)(z_iz_j) + \sum_{i=1}^n(\sqrt{2c}x_i)(\sqrt{2c}x_j)+c^2.<br>\end{align}<br>$$<br>对应的映射函数$(n=3)$为:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_757.png" alt=""><br>更广泛的来说, 我们有:<br>$$K(x,z)=(x^Tz+c)^d$$<br>这个kernel将n维的特征映射为${ {n+d} \choose d }$维.<br>以上是举几个kernel的例子, 如果我们有一个新的问题我们该如何构造一个kernel? 假设我们有映射后的特征向量$\phi(x)$和$\phi(z)$, kernel就是用来计算它们两之间的内积. 如果$\phi(x)$和$\phi(z)$相似的话, 即这两个向量的夹角很小, 那么这个内积就会很大; 相反地, 如果它们差别很大, 那么这个内积就会很小.<br>所以, 我们可以这样想kernels, 当$x$和$z$相似时, $K(x,z)$很大. 反之, 当$x$和$z$不同时, $K(x,z)$很小.<br>我们再来看一个kernel:<br>$$K(x,z)=exp\left(-\frac{||x-z||^2}{2\sigma^2}\right).$$<br>思考一下, 这个kernel应该挺符合上面的想法吧. 这个kernel长得像高斯分布, 我们一般叫他高斯kernel, 也可以叫Radial basis funtction kernel, 简称RBF核.</p>
<h1 id="kernels的有效性"><a href="#kernels的有效性" class="headerlink" title="kernels的有效性"></a>kernels的有效性</h1><p>上一节提到了一些核函数, 这里我们提一个问题, 我们该如何确定这个核函数是有效的, 也即:是否存在$\phi$, 使得$K(x,z)=\langle\phi(x)\phi(z)\rangle$?<br>假设我们有核K和m个训练样本$\lbrace x^{(1)},x^{(2)}, …,x^{(m)}\rbrace$, 定义一个$m\times m$的矩阵$K$, $K_{ij}=K(x^{(i)}, x^{(j)})$.<br>如果$K$是一个有效的kernel, 那么一定有:<br>$$K_{ij}=K(x^{(i)}, x^{(j)})=\phi(x^{(i)})^T\phi(x^{(j)})=\phi(x^{(j)})^T\phi(x^{(i)})=K(x^{(j)}, x^{(i)})=K_{ji}$$<br>即$K$是对称阵.现我们用$\phi_k(x)$表示向量$\phi(x)$的第k个元素, 对任意的向量$z$都有:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_758.png" alt=""><br>从上面的证明我们可以得到, 如果$K$是一个有效的kernel, 那么对于在训练集上的核矩阵$K$一定是半正定的. 事实上, 这不仅仅是个必要条件, 它也是充分条件. 有效核也叫作Mercer Kernel. </p>
<blockquote>
<p>Mercer 定理: </p>
</blockquote>
<p>函数$K$是$\mathbb{R}^n\times\mathbb{R}^n\to\mathbb{R}$上的映射. 如果$K$是一个有效的(Mercer)Kernel, 那么当且仅当对于任意$\lbrace x^{(1)},…,x^{(m)}\rbrace, (m\lt\infty)$, 相应的kernel matrix是半正定的.</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>CS229</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(六)-SVM之拉格朗日对偶, 最优间隔分类器</title>
    <url>/2016/CS229-ML-Notes-Lecture-7.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/photo-1420768255295-e871cbf6eb81.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a><br>参考资料: <a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">《统计学习方法》</a><br>参考阅读:</p>
<ol>
<li><a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">支持向量机系列-pluskid</a>(强烈推荐)</li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982639.html" target="_blank" rel="noopener">支持向量机SVM（一）</a>(强烈推荐)</li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982684.html" target="_blank" rel="noopener">支持向量机SVM（二）</a>(强烈推荐)</li>
<li><a href="http://logos.name/archives/304" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记五：支持向量机 Support Vector Machines</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9774135" target="_blank" rel="noopener">最优间隔分类、原始/对偶问题、SVM对偶—斯坦福ML公开课笔记7</a></li>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记</a><a id="more"></a>
</li>
</ol>
<hr>
<p>接上篇: <a href="http://daniellaah.github.io/2016/CS229-Machine-Learning-Notes-Lecture-6.html">CS229机器学习笔记(五)-SVM之函数间隔, 几何间隔</a><br>支持向量机学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面. 对线性可分的训练数据集而言, 线性可分分离超平面有无穷多个(等价于感知机), 但是几何间隔最大的分离超平面是唯一的. 这里的间隔最大化又称为硬间隔最大化(与将要讨论的训练数据集近似线性可分时的软间隔最大化相对应)</p>
<h2 id="一-间隔最大化"><a href="#一-间隔最大化" class="headerlink" title="一. 间隔最大化"></a>一. 间隔最大化</h2><p>通过上一篇的讲解, 我们知道我们想要找到一个超平面, 使得离超平面最近的点的几何间隔越大越好.该如何找到这样的超平面呢? 这个问题可用如下的优化问题表示：<br>$$<br>\begin{align}<br>\max_{w,b} &amp;\quad \gamma \<br>\<br>s.t. &amp;\quad y_{i}(\frac{w}{\Vert w\Vert}\cdot x_i+ \frac{b}{\Vert w\Vert})\ge\gamma, \quad i=1,2,…,N \<br>\end{align}<br>$$<br>即我们希望最大化超平面$(w,b)$关于训练数据集的几何间隔$\gamma$, 约束条件表示的是超平面$(w,b)$关于每个训练样本点的几何间隔至少是$\gamma$<br>考虑几何间隔和函数间隔的关系式, 可将这个问题改写为<br>$$<br>\begin{align}<br>\max_{w,b} &amp;\quad \frac{\hat{\gamma}}{\Vert w\Vert} \<br>\<br>s.t. &amp;\quad y_{i}({w}\cdot x_i+ {b})\ge\hat{\gamma}, \quad i=1,2,…,N \<br>\end{align}<br>$$<br>函数间隔$\hat{\gamma}$的取值并不影响最优化问题的解. 事实上, 假设将$w$和$b$按比例改变为$\lambda w和\lambda b$, 这时函数间隔成为$\lambda\hat{\gamma}$. 函数间隔的这一改变对上面最优化问题的不等式约束没有影响, 对目标函数的优化也没有影响, 也就是说, 它产生一个等价的最优化问题. 这样, 就可以取$\gamma＝1$. 将$\gamma＝1$代入上面的最优化问题, 注意到最大化$\frac{1}{\Vert w\Vert}$和最小化$\frac{1}{2}\Vert w\Vert^2$是等价的, 于是就得到下面的线性可分支持向量机学习的最优化问题<br>$$<br>\begin{align}<br>\min_{w,b} &amp;\quad {\frac12}||w||^2  \<br>\<br>s.t. &amp;\quad y_{i}(w\cdot x_{i}+b)-1\ge =0<br>\end{align}<br>$$<br>这个时候我们的问题就转化成了在线性约束下的二次规划. 可以使用二次规划的软件来解决这个优化问题, 然后我们就可以得到我们的最优间隔分类器.<br>实际上, 我们有更好的办法去解这个优化问题. 但在这之前, 我们需要补充一下其他的相关知识.</p>
<h2 id="二-拉格朗日对偶"><a href="#二-拉格朗日对偶" class="headerlink" title="二. 拉格朗日对偶"></a>二. 拉格朗日对偶</h2><p>在约束最优化问题中, 常常利用拉格朗日对偶性(Lagrange duality)将原始问题转换为对偶问题, 通过解对偶问题而得到原始问题的解. 该方法应用在许多统计学习方法中, 例如, 最大熵模型与支持向量机. </p>
<h3 id="2-1-原始问题"><a href="#2-1-原始问题" class="headerlink" title="2.1 原始问题"></a>2.1 原始问题</h3><p>$$<br>\begin{align}<br>\min_{w} &amp; \quad f(w) \<br>\<br>{s.t.} &amp;\quad h_i(w)=0, \quad i=1,\cdots,l<br>\end{align}<br>$$<br>我们使用拉格朗日乘子法, 将问题转化为:<br>$$\mathcal{L}(w,\beta)=f(w)+\sum_{i=1}^l\beta_ih_i(w)$$<br>其中, $\beta_i$为拉格朗日乘子(Lagrange Multipliers). 然后令偏导为0来解得$w,\beta$.<br>$$<br>\begin{align}<br>\frac{\partial\mathcal{L}}{\partial w_i} &amp; = 0 \\<br>\<br>\frac{\partial\mathcal{L}}{\partial \beta_i} &amp; = 0<br>\end{align}<br>$$<br>这个问题的更加广泛的形式为(既存在等式约束又存在不等式约束):<br>$$<br>\begin{align}<br>\min_{w}&amp;\quad f(w) \\<br>\<br>\mathrm{s.t.} &amp; \quad g_i(w)\leq 0,\quad i=1,\cdots ,k \<br>\<br>&amp; \quad h_i(w)=0,\quad i=1,\cdots,l<br>\end{align}<br>$$<br>我们定义广义拉格朗日公式(generalized Lagrangian)为:<br>$$<br>\mathcal{L}(w,\alpha,\beta)=f(w)+\sum_{i=1}^k\alpha_ig_i(w)+\sum_{i=1}^l\beta_ih_i(w).<br>$$<br>其中, $\alpha_i, \beta_i$为拉格朗日乘子. 现在我们定义:<br>$$<br>\theta_{\mathcal{P}}(w)=\operatorname*\max_{\alpha,\beta:\alpha_i\geq 0}\mathcal{L}(w,\alpha,\beta)<br>$$<br>其中下标$\mathcal{P}$代表”primal”. 若约束条件得不到满足的时候($g_i(w)\gt0$或$h_i(w)\ne0$), 则可令$\alpha_i$为无穷大或$\beta_i$为无穷大使得$\theta_{\mathcal{P}}(w)=\infty$. 而当约束条件满足时, $\theta_{\mathcal{P}}(w)=f(w)$. 所以有:<br>$$<br>\theta_{\mathcal{P}}=\begin{cases}f(w) &amp; w\text{ 满足原始问题的约束} \\<br>\<br>\infty &amp;\text{其他}\end{cases}<br>$$<br>即对于满足原始约束的w来说, $\theta_{\mathcal{p}}$与原始问题中的目标函数相同. 对于违反原始约束的w来说, $\theta_{\mathcal{p}}=\infty$. 因此, 如果考虑最小化：<br>$$<br>\min_{w}\theta_{\mathcal{P}}(w)=\min_{w}\max_{\alpha,\beta:\alpha_i\geq 0}\mathcal{L}(w,\alpha,\beta)<br>$$<br>它是与原始最优化问题等价的, 即它们有相同的解. 问题$\min_{w}\max_{\alpha,\beta:\alpha_i\geq 0}\mathcal{L}(w,\alpha,\beta)=\min_w\theta_{\mathcal{p}}(w)$称为广义拉格朗日函数的极小极大问题. 这样一来我们就把原始最优化问题表示为广义拉格朗日函数的极小极大问题. 为了后面使用方便, 我们定义原始问题的最优值<br>$$p^\ast=\min_w\theta_{\mathcal{p}}(w)$$<br>称为原始问题的值.</p>
<h3 id="2-2-对偶问题"><a href="#2-2-对偶问题" class="headerlink" title="2.2 对偶问题"></a>2.2 对偶问题</h3><p>现在, 我们看一下另外一个问题:<br>$$\theta_{\mathcal{D}}(\alpha,\beta)=\min_{w}\mathcal{L}(w,\alpha,\beta)$$<br>其中下标$\mathcal{D}$代表对偶(“Dual”). 在原始问题中, 我们是先最大化关于$\alpha, \beta$的函数, 再最小化关于$w$的函数; 而这里的对偶问题, 我们先最小化关于$w$的函数, 再最大化关于$\alpha, \beta$的函数:<br>$$<br>\max_{\alpha,\beta:\alpha_i\ge0}\theta_{\mathcal{D}}(\alpha,\beta)=\max_{\alpha,\beta:\alpha_i\ge0}\min_{w}\mathcal{L}(w,\alpha,\beta)<br>$$<br>它们唯一的区别就在于min和max的顺序不同. 我们令$d^{\ast}=\max_{\alpha,\beta:\alpha_i\ge0}\min_{w}\mathcal{L}(w,\alpha,\beta)$, 并且对于任意函数都有$minmax\le maxmin$, 所以我们可以得到:<br>$$d^{\ast}=\max_{\alpha,\beta:\alpha_i\ge0}\min_{w}\mathcal{L}(w,\alpha,\beta)\le\min_{w}\max_{\alpha,\beta:\alpha_i\geq 0}\mathcal{L}(w,\alpha,\beta)=p^{\ast}$$<br>也就是说, 在某种情况下,会有$d^\ast=p^\ast$, 这个时候我们就可把求原始问题转化成求对偶问题.假设$f$和$g_i$是凸函数, $h$是仿射的. 并且存在$w$是的对于所有的$i$能够使$g_i(w)&lt;0$.<br>在上述假设条件下, 一定存在$w^{\ast}, {\alpha}^{\ast}, {\beta}^{\ast}$, 使得$w^{\ast}$是原始问题的解, $ {\alpha}^{\ast}, {\beta}^{\ast}$是对偶问题的解.并且还有$p^{\ast}=d^{\ast}=\mathcal{L}(w^{\ast}, {\alpha}^{\ast}, {\beta}^{\ast})$.<br>$w^{\ast}, {\alpha}^{\ast}, {\beta}^{\ast}$满足KKT条件(Karush-Kuhn-Tucker conditions):<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_751.png" alt=""><br>如果存在满足KKT条件的$w^{\ast}, {\alpha}^{\ast}, {\beta}^{\ast}$, 则原始问题与对偶问题一定有解. (5)式又称为KKT对偶互补条件(KKT dual complementarity condition), 这个条件表明如果$\alpha^\ast\gt0$, 那么就有$g_i(w^\ast)=0$. 即约束条件$g_i(w^\ast)≤0$“激活”, w处于可行域的边界上. 而其他位于可行域内部$g_i(w^\ast)\lt0$的点都不起约束作用, 对应的$\alpha^\ast=0$.</p>
<h2 id="三-最优间隔分类器"><a href="#三-最优间隔分类器" class="headerlink" title="三. 最优间隔分类器"></a>三. 最优间隔分类器</h2><p>有了上面的知识之后, 我们再回到SVM的问题:<br>$$\min_{\gamma, w,b}{\frac12}||w||^2\quad s.t. \quad y^{(i)}(w^Tx^{(i)}+b)\ge1.$$<br>这看上去好像就是上一节讲的拉格朗日对偶问题, 只不过这里没有等式约束只有不等式约束. 我们将不等式约束改成我们熟悉的样子:<br>$$g_i(w)=-y^{(i)}(w^Tx^{(i)}+b)+1\le0.$$<br>从上一节讨论的KKT条件可知, 只有当训练样本的函数间隔为1时($g_i(w)=0$), 它前面的系数$\alpha_i\gt0$. 对于其他的训练样本, 前面的系数$\alpha_i=0$.<br>考虑下图, 最大间隔分类超平面为实线:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_752.png" alt=""><br>其中一个正样本和两个负样本正好在平行于分类超平面的虚线上, 只有这三个样本对应的$\alpha_i\lt0$, 其它样本对应的$\alpha_i=0$. 这三个样本就叫做支持向量(这也就是支持向量机名字的由来).从这里我们可以看出, 支持向量的个数远远小于训练集的大小.<br>我们构造拉格朗日函数:<br>$$\mathcal{L}(w, b, \alpha)=\frac12||w||^2-\sum_{i=1}^m\alpha_i[y^{(i)}(w^Tx^{(i)}+b)-1].$$<br>下面的任务就是求解对偶问题了. 根据上一节的知识, 我们有:<br>$$d^\ast=\mathop\max_{\alpha:\alpha_i\ge0}\theta_\mathcal{D}(\alpha)=\mathop\max_{\alpha:\alpha_i\ge0}\mathop\min_{w,b}\mathcal{L}(w,b,\alpha).$$<br>首先, 求$\mathcal{L}(w,b,\alpha)$关于$w,b$的最小值. 令偏导为0:<br>$$<br>\frac{\partial\mathcal{L}}{\partial w}=w-\sum_{i=1}^m\alpha_iy^{(i)}x^{(i)}=0, \<br>\frac{\partial\mathcal{L}}{\partial b}=0-\sum_{i=1}^m\alpha_iy^{(i)}=0.<br>$$<br>可得:<br>$$<br>w=\sum_{i=1}^m\alpha_iy^{(i)}x^{(i)}, \<br>\sum_{i=1}^m\alpha_iy^{(i)}=0.<br>$$<br>再将求得的$w$带回$\mathcal{L}(w,b,\alpha)$可得到$\mathop\min_{w,b}\mathcal{L}(w,b,\alpha)$:</p>
<p>$$<br>\begin{align}<br>&amp; \mathop\min_{w,b}\mathcal{L}(w,b,\alpha)  \\<br>&amp; =\frac12(\sum_i^m\alpha_iy_ix_i)(\sum_j^m\alpha_jy_jx_j) - (\sum_i^m\alpha_iy_ix_i)(\sum_j^m\alpha_jy_jx_j)+(\sum_i^m\alpha_iy_ib) + \sum_i^m\alpha_i \<br>&amp; = -\frac12(\sum_i^m\alpha_iy_ix_i)(\sum_j^m\alpha_jy_jx_j) + b\sum_i^m\alpha_iy_i + \sum_i^m\alpha_i \<br>&amp; = \sum_i^m\alpha_i  - \frac12\sum_i^m\sum_j^m\alpha_i\alpha_jy_iy_jx_i^Tx_j \<br>&amp; = \sum_i^m\alpha_i  - \frac12\sum_i^m\sum_j^m\alpha_i\alpha_jy_iy_j\langle x_i,x_j\rangle<br>\end{align}<br>$$<br>有了$\mathop\min_{w,b}\mathcal{L}(w,b,\alpha)$, 我们便可进行max操作, 即:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_753.png" alt=""><br>可以证明该优化问题满足KKT条件(证明可见<a href="http://blog.csdn.net/stdcoutzyx/article/details/9774135" target="_blank" rel="noopener">张雨石的博客</a>).求得$\alpha_i^\ast$之后(如何求解后面再讲), 可通过$w=\sum_{i=1}^m\alpha_iy^{(i)}x^{(i)}$求得$w^\ast$, 最后通过下式求得$b^\ast$:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_754.png" alt=""><br>当我们求出了所有的参数, 我们就可以通过计算$w^Tx+b$来进行分类了:<br>$$\begin{align} w^Tx+b &amp; = {\left(\sum_i^m\alpha_iy_ix_i\right)}^Tx+b \\ &amp; = \sum_i^m\alpha_iy_i\langle x_i,x \rangle +b\end{align}.$$<br>通过上式我们发现, 现在新来一个数据, 我们只需要计算它与训练样本的内积即可. 并且通过前面的KKT条件我们知道, 只有除了支持向量的那些样本, 都有$\alpha_i=0$. 所以, 我们只需要将新样本与支持向量进行内积即可计算出$w^Tx+b$. </p>
<blockquote>
<p>在决定分离超平面时只有支持向量起作用, 而其他实例点并不起作用. 如果移动支持向量将改变所求的解；但是如果在间隔边界以外移动其他实例点, 甚至去掉这些点, 则解是不会改变的. 由于支持向量在确定分离超平面中起着决定性作用, 所以将这种分类模型称为支持向量机. 支持向量的个数一般很少, 所以支持向量机由很少的“重要的”训练样本确定. </p>
</blockquote>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>CS229</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(五)-SVM之函数间隔, 几何间隔</title>
    <url>/2016/CS229-ML-Notes-Lecture-6.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/photo-1414115880398-afebc3d95efc.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a><br>参考资料: <a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">《统计学习方法》</a><br>参考阅读:</p>
<ol>
<li><a href="http://blog.pluskid.org/?page_id=683" target="_blank" rel="noopener">支持向量机系列-pluskid</a></li>
<li><a href="http://www.cnblogs.com/jerrylead/archive/2011/03/13/1982639.html" target="_blank" rel="noopener">支持向量机SVM（一）</a></li>
<li><a href="http://logos.name/archives/304" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记五：支持向量机 Support Vector Machines</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9722701" target="_blank" rel="noopener">NB多项式模型、神经网络、SVM初步—斯坦福ML公开课笔记6</a></li>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记</a><a id="more"></a>
</li>
</ol>
<hr>
<h1 id="一-从Logistic-Regression到SVM"><a href="#一-从Logistic-Regression到SVM" class="headerlink" title="一. 从Logistic Regression到SVM"></a>一. 从Logistic Regression到SVM</h1><h2 id="1-1-想法"><a href="#1-1-想法" class="headerlink" title="1.1 想法"></a>1.1 想法</h2><p>在logistic regression中, sigmoid函数图像如下:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_690.png" alt=""><br>它的输出$h_\theta(x)$是$p(y=1|x)$. 在logistic中, 我们通过计算$\theta^Tx$来预测新的数据:<br>$$\text{predict} \quad  “1” \quad \text{iff} \quad \theta^Tx\ge0, \<br>\text{predict} \quad  “0”  \quad  \text{iff}  \quad  \theta^Tx\lt0.$$<br>其中iff代表当且仅当. 若$\theta^Tx$越大, 则$h_\theta(x)=p(y=1|x;w,b)$越大, 即我们非常”确信”它的标签为”1”. 所以:<br>$$ \text{If} \quad \theta^Tx\gg0,\quad \text{very “confident” that} \quad y=1, \<br> \text{If} \quad \theta^Tx\ll0,\quad \text{very “confident” that} \quad y=0.$$<br>如果在我们的训练集中, 对于所有的预测结果为”1”的样本都有$\theta^Tx\gg0$, 对于所有的预测结果为”0”的样本都有$\theta^Tx\ll0$, 那便是极好的. 用数学语言表达为:<br>$$\text{if} \quad \forall i \quad \text{s.t.} \quad y^{(i)}=1, \text{have} \quad \theta^Tx\gg0, \<br>\text{if}  \quad \forall i  \quad\text{s.t.}  \quad y^{(i)}=0, \text{have} \quad \theta^Tx\ll0,$$<br>举个例子, 假设我们有下面这个分类器, 我们观察其中三个点A, B, C. 我们可以比较确定地认为A的标签为”X”. 而对于C来说, 我们就不能非常确定它的标签是”X”, 因为它离决策边界太近了. 这个决策边界只要有一点点变化就可能导致C分到不同的类中. 对于B的确信程度介于A和C之间.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_747.png" alt=""><br>即我们不仅仅要求分类器能正确的分类, 更进一步我们要求$\theta^Tx\ll0$或$\theta^Tx\gg0$. 即, 我们想要得到一种决策边界, 使得所有的样本都尽量远离这个边界. (下图截图自<a href="https://youtu.be/8hak0XngnV0?t=2m56s" target="_blank" rel="noopener">林轩田-机器学习技法</a>), 下面三个决策边界中, 你认为哪一个最好?<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_746.png" alt=""><br>这个时候你也许会问, 这个离决策边界的距离到底指的是什么, 应该怎样表达他们. 这里就会引出”函数间隔”和”几何间隔”的概念.<br>不过为了使后面一系列的推导的方便, 我们先稍微修改一下原先的(logistic regression中的)一些记号.<br>注: 在接下来的讲解中, 我们默认数据是线性可分的(后面我们会讨论线性不可分的情况). </p>
<h2 id="1-2-SVM中的符号说明"><a href="#1-2-SVM中的符号说明" class="headerlink" title="1.2 SVM中的符号说明"></a>1.2 SVM中的符号说明</h2><p>1.在logstic中我们用0,1代表两个类, 现在我们改用-1,+1, 即$y\in \lbrace-1, +1\rbrace$;<br>2.在logistic中, 我们的$g$是sigmoid函数, 现在改为:<br>$$g(z)=\begin{cases} 1, \quad z\ge0 \\ -1, \quad \text{otherwise} \end{cases} $$<br>3.在logistic中, 我们的假设函数为$h_\theta(x)$, 现在改为, $h_{w,b}(x)=g(w^Tx+b)$, 其中$w$相当于${\begin{bmatrix} \theta_1 \theta_2 … \theta_n \end{bmatrix}}^T$, $b$相当于$\theta_0$.<br>符号弄清楚了之后, 我们可以研究SVM了. 首先, 我们要介绍一个概念: 函数间隔(functional margin).</p>
<h1 id="二-函数间隔和几何间隔"><a href="#二-函数间隔和几何间隔" class="headerlink" title="二. 函数间隔和几何间隔"></a>二. 函数间隔和几何间隔</h1><h2 id="2-1-函数间隔"><a href="#2-1-函数间隔" class="headerlink" title="2.1 函数间隔"></a>2.1 函数间隔</h2><p>对于一个训练样本$(x^{(i)}, y^{(i)})$, 我们定义它到超平面$(w,b)$的函数间隔为: $$\hat{\gamma}=y^{(i)}(w^Tx^{(i)}+b).$$<br>我们希望函数间隔越大越好, 即:<br>$$\text{if} \quad y^{(i)}=1, \text{want} \quad w^Tx^{(i)}+b\gg0, \<br>\text{if} \quad y^{(i)}=-1, \text{want} \quad w^Tx^{(i)}+b\ll0.$$<br>并且有, 若$y^{(i)}(w^Tx^{(i)}+b)&gt;0$, 则样本$(x^{(i)}, y^{(i)})$分类正确. </p>
<p id="#normalization">函数间隔越大, 代表我们对于分类的结果非常确定. 我们希望函数间隔越大越好. 看上去好像没什么毛病, 但这里的确有一个问题, 就是其实我们可以在不改变这个超平面的情况下可以让函数间隔任意大, 为什么? 只要我们成比增加w,b就可以达到这个目的了. 例如, 我们将$w$变为$2w$, $b$变为$2b$, 那么我们的函数间隔将会是原来的两倍, 但是超平面$wTx+b=0$和超平面$2w^Tx+2b=0$是一回事. 为了解决这个问题, 我们就需要加上一些限制条件(后面会讲).</p>
对于整个训练集, 我们的函数间隔定义为
$$\hat{\gamma}=\min\_i\hat{\gamma}^{(i)}.$$ 
也就是说, 对于整个训练集来说, 函数间隔为所有样本中函数间隔最小的那个函数间隔.
## 2.2 几何间隔
如下图所示, 决策边界为$w^Tx+b=0$, 我们可以证明$w$是垂直于这个决策边界(超平面)的(证明可见: [林轩田-机器学习技法](https://youtu.be/lHo9GcIURRs?t=4m28s)).对于训练样本A$(x^{(i)},y^{(i)})$, 它到超平面$w^Tx+b=0$的几何距离为$\gamma^{(i)}$. 由于BA方向上的单位向量可表示为$\frac{w}{||w||}$. 则B(A在超平面上的投影)可表示为($\overrightarrow{OB}=\overrightarrow{OA} - \overrightarrow{BA}$):
$$x^{(i)}-\gamma^{(i)}\cdot\frac{w}{\Vert w\Vert}.$$
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_748.png)
而B又在超平面上, 所以我们将这个点带回超平面得到:
$$w^T(x^{(i)}-\gamma^{(i)}\cdot\frac{w}{\Vert w\Vert})+b=0.$$
通过上式解出$\gamma$: 
$$w^Tx^{(i)}-\gamma^{(i)}\frac{w^Tw}{||w||}+b=0, \\\
w^Tx^{(i)}+b=\gamma^{(i)}||w||, \\\
\gamma^{(i)}=(\frac{w}{\Vert w\Vert})^Tx^{(i)}+\frac{b}{\Vert w\Vert}.$$
加上前面的$y^{(i)}$于是我们就得到了几何间隔: 
$$\gamma^{(i)}=y^{(i)}(\frac{w^T}{\Vert w\Vert}x^{(i)}+\frac{b}{\Vert w\Vert}).$$
我们发现当$||w||=1$时, 几何间隔就是函数间隔.这个时候, 如果任意放大$||w||$, 几何间隔是不会改变的, 因为$||w||$也会随着被放大. 几何间隔与函数间隔的关系为: 
$$\gamma^{(i)}=\frac{\hat{\gamma}^{(i)}}{\Vert w\Vert}.$$
对于所有的训练样本, 我们的几何间隔为:
$$\gamma=\min\_i\gamma^{(i)}.$$
视频到这里后面还有一点点的内容放到下篇一起讲.

]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>CS229</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(四)-生成学习算法, 朴素贝叶斯, 多项式事件模型</title>
    <url>/2016/CS229-ML-Notes-Lecture-5-6.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/c5928e75-429e-44ff-9315-c4aa81351ed3.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a></p>
<a id="more"></a>
<hr>
<h1 id="生成学习算法"><a href="#生成学习算法" class="headerlink" title="生成学习算法"></a>生成学习算法</h1><p>前面讲的Logistic回归是一种判别学习算法(Discriminative Learning Algorithm), 我们是直接找出一条决策边界. 直接学习$p(y|x)$或者直接学习$h_\theta(x)\in \lbrace0,1\rbrace$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/logisticregression1.jpg" alt=""><br>而在生成学习算法中(Generative Learning Algorithm), 我们学习在给定label下特征的分布以及label本身的分布. 即学习$p(x|y)$和$p(y)$. 由贝叶斯公式我们有:<br>$$p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x)}$$<br>由全概率公式我们可以得到:<br>$$p(x)=p(y=0|x)p(y=0)+p(y=1|x)p(y=1)$$<br>从这里我们就可以看出来，判别算法是直接对$p(y|x)$进行建模而生成算法是对$p(x|y)$和$p(y)$建模，然后得到$p(y|x)$. </p>
<h2 id="高斯判别分析"><a href="#高斯判别分析" class="headerlink" title="高斯判别分析"></a>高斯判别分析</h2><p>这一节我们来具体地学习一个生成学习算法，它就是Gaussian Discriminant Analysis(GDA).<br>首先，我们假设$x\in R^n$且$x$是一个连续值, $p(x|y)$是一个高斯分布(多变量高斯分布, 如果不熟悉多变量高斯分布可以参考<a href="http://cs229.stanford.edu/notes/cs229-notes2.pdf" target="_blank" rel="noopener">lecture notes2</a>).<br>$$p(x|y;\mu, \Sigma)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac12(x-\mu)^T\Sigma^{-1}(x-\mu))$$<br>下面具体看看GDA模型:<br>$$y\sim Bernoulli(\phi),$$ $$x|y=0\sim N(\mu_0, \Sigma),$$ $$x|y=1\sim N(\mu_1, \Sigma).$$<br>即:<br>$$y=\phi^y(1-\phi)^{1-y},$$<br>$$p(x|y=0)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac12(x-\mu_0)^T\Sigma^{-1}(x-\mu_0)),$$<br>$$p(x|y=1)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac12(x-\mu_1)^T\Sigma^{-1}(x-\mu_1)),$$<br>参数为$\phi, \mu_0,\mu_1,\Sigma$, log似然估计为:<br><font size='4'><br>$$<br>\begin{align}<br>l(\phi, \mu_0,\mu_1,\Sigma) &amp; = log\prod_{i=1}^mp(x^{(i)},y^{(i)};\phi, \mu_0,\mu_1,\Sigma) \<br>&amp; = log\prod_{i=1}^mp(x^{(i)}|y^{(i)}; \mu_0,\mu_1,\Sigma)p(y^{(i)};\phi).<br> \end{align}<br>$$<br></font><br>注意: 其中第一个等式右边是一个联合似然(joint likelihood), 回顾一下之前讲的logistic模型中，我们的似然函数如下:$l(\theta) = log\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta).$它是一个条件似然.<br>我们$\max l$ w.r.t $(\phi, \mu_0,\mu_1,\Sigma)$, 得到:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_728.png" alt=""><br>最后，我们便可以通过下式进行预测:<br>$$<br>\begin{align}<br>arg\max_yp(y|x) &amp; = arg\max_y\frac{p(x|y)p(y)}{p(x)} \<br>&amp; = arg\max_y p(x|y)p(y)<br>\end{align}<br>$$</p>
<h2 id="GDA模型和logistic模型"><a href="#GDA模型和logistic模型" class="headerlink" title="GDA模型和logistic模型"></a>GDA模型和logistic模型</h2><p>如下图所示，我们画出了正样本和负样本特征的分布(高斯分布):<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_729.png" alt=""><br>然后，我们想要画出$p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x)}$的图:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/gda_logistic.jpg" alt=""><br>这个时候我们会发现，画出的图形就是sigmoid函数. 也就是说，在GDA的假设下($x|y\sim N(\mu, \Sigma)$), 我们计算得到的$p(y=1|x)$就是我们在logistic regression中用的sigmoid函数.  但是反过来不成立，即$p(y=1|x)$是一个sigmoid函数不能推出$x|y\sim N(\mu, \Sigma)$. 这里非常有趣的是，如果我们的假设是$x|y$不仅仅是高斯分布只要是属于指数分布族任何一种，我们都可以推导出$p(y=1|x)$是一个sigmoid函数.<br>通过以上我们可以知道GDA使用了更强的假设($x|y$是高斯分布), 如果假设成立或者近似成立的话，那么GDA就相对于logistic而言使用了更多的信息，那么它的预测结果也会更好. 但如果这个假设不成立的话，那么logistic会表现的更好。例如, 如果$x|y$实际上是poisson分布, 但我们还是按照GDA假设他是高斯分布，这样的话GDA的表现就不如logistic.<br> generative learning algorithm有一个好处就是它只需要更少的数据, 因为他用了更强的假设; 而logistic没有这个假设，所以需要更多的数据，但是它要更加的robust. </p>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><p>朴素贝叶斯(Naive Bayes)是另一种Generative learning algorithm. 这里使用垃圾邮件的例子来说明. </p>
<h2 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h2><p>$y\in \lbrace0,1\rbrace$代表正常邮件和垃圾邮件, 首先我们需要解决的是，邮件该用什么形式来表现. 我们有一个词典，如果一个邮件中出现了这个单词，我们就在相应的位置用1表示:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_730.png" alt=""><br>现在我们要对$p(x|y)$进行建模, $x\in {\lbrace0,1\rbrace}^n, n=50000$(字典里有50000个单词). 这样我们的$x$就有$2^{50000}$中表示. 我们就需要$2^{50000}-1$个参数, 这肯定是不现实的. 所以在朴素贝叶斯中, 我们又做了一个更加强的假设: $x_{i}$条件独立于给定的$y$. 即知道了一个单词在某一种邮件中出现了不会影响其他单词在这个邮件中出现的概率. 用公式表示就是:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_731.png" alt=""><br>于是, 模型的参数为:<br>$$\phi_{i|y=1}=p(x_i|y=1),$$ $$\phi_{i|y=0}=p(x_i|y=0),$$ $$\phi_y=p(y=1).$$<br>联合似然函数为:<br>$$\mathcal{L}(\phi_y,\phi_{i|y=0},\phi_{i|y=1})=\prod_{i=1}^mp(x^{(i)},y^{(i)})$$<br>最大似然估计:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_732.png" alt=""><br>当我们得到这些参数之后, 就可以对新的数据进行预测:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_733.png" alt=""></p>
<h2 id="拉普拉斯平滑"><a href="#拉普拉斯平滑" class="headerlink" title="拉普拉斯平滑"></a>拉普拉斯平滑</h2><p>还是上面垃圾邮件分类的例子，假设我们现在有一封新的邮件，它包含了”nips”这个单词. 但在这之前, 我们没有一封邮件(不管是垃圾还是正常邮件)是包含了这个单词的. 假设”nips”在字典中是第35000个, 那么我们的朴素贝叶斯的两个参数如下:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_734.png" alt=""><br>因此, 在我们做预测的时候, 我们会得到如下结果:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_735.png" alt=""><br>这显然是不合理的. 不能因为一件事情从来没有观测到就说它出现的概率为0.<br>所以这里我们引入了拉普拉斯平滑处理的概念. 假设一个随机变量可取值$\lbrace1,2,…,k\rbrace$, 参数为$\phi_i=p(z=i)$. 给定m个独立的观测值$\lbrace z^{(1)},z^{(2)},…,z^{(m)}\rbrace$, 最大似然估计为:<br>$$\phi_j=\frac{\sum_{i=1}^m1\lbrace z^{(i)}=j\rbrace}{m}$$<br>为了不让$\phi_j$有可能等于0, 我们做一个拉普拉斯平滑, 即, 将最大似然估计改为:<br>$$\phi_j=\frac{\sum_{i=1}^m1\lbrace z^{(i)}=j\rbrace+1}{m+k}$$<br>这不仅解决了$\phi_j$可能等于0的问题, 而且保证了$\sum_{j=1}^k\phi_j$仍然等于1.<br>再回到朴素贝叶斯分类器, 使用了Laplace Smoothing之后的最大似然估计为:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_736.png" alt=""></p>
<h1 id="多项式事件模型"><a href="#多项式事件模型" class="headerlink" title="多项式事件模型"></a>多项式事件模型</h1><p>我们前面讲的朴素贝叶斯模型可以解决很多分类问题, 在文本分类下, 它又叫做多元伯努利事件模型(Multi-variate Bernoulli Event Model). 这一节我们来讲一个专门为文本分类设计的模型, 它就叫做多项式事件模型(Multinomial Event Model).<br>在Multi-variate Bernoulli Event Model中, 我们的邮件用如下形式表示:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_730.png" alt=""><br>在Multinomial Event Model中, 我们使用另一种形式来表示, 将第i个邮件用一个向量表示:<br>$$(x_1^{(i)},x_2^{(i)},…,x_{n_i}^{(i)})$$<br>其中$n_i$表示第i封邮件的单词的个数, $x_j$表示第$j$个单词在字典中的索引, 例如字典有50000个单词的话, 那么$x_j\in \lbrace 1,2,…,50000\rbrace$.<br>现在, 我们模型的参数为:<br>$$\phi_{k|y=1}=p(x_j=k|y=1),$$ $$\phi_{k|y=0}=p(x_j=k|y=0),$$ $$\phi_y=p(y=1).$$<br>log似然函数为:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_739.png" alt=""><br>最大似然估计为:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_737.png" alt=""><br>若使用Laplace Smoothing则最大似然估计为:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_738.png" alt=""><br>其中$|V|$为字典中单词的个数. </p>
<p>视频中的神经网络部分可以参考:<br>1.<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes-Week-4-Neural-Networks-Representation.html">我的机器学习笔记(九) - 神经网络(上)</a><br>2.<a href="http://daniellaah.github.io/2016/Machine-Learning-Andrew-Ng-My-Notes-Week-5-Neural-Networks-Learning.html">我的机器学习笔记(九) - 神经网络(下)</a></p>
<p>参考: </p>
<ol>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记-子实</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9285001" target="_blank" rel="noopener">生成学习、高斯判别、朴素贝叶斯—斯坦福ML公开课笔记5</a></li>
<li><a href="http://logos.name/archives/260" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记四：GDA、朴素贝叶斯、多项事件模型</a></li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>CS229</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(三)-指数分布族, 广义线性模型</title>
    <url>/2016/CS229-ML-Notes-Lecture-1-4-%E4%B8%8B.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/photo-1468956332313-2dcf1542828f.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a></p>
<a id="more"></a>
<hr>
<h1 id="一-指数分布族"><a href="#一-指数分布族" class="headerlink" title="一. 指数分布族"></a>一. 指数分布族</h1><p>在讲广义线性模型之前，我们需要先介绍一下什么是指数分布族(exponential family). 一类分布如果属于指数分布族，那么它就可以写成如下形式:<br>$$p(y;\eta)=b(y)exp(\eta^TT(y)-a(\eta))$$<br>其中$\eta$叫做natrual parameter, $T(y)$叫做sufficient statistic, $a(\eta)$叫做log partition function. 当我们选定T,a,b的时候，我们就得到了参数为$\eta$的分布族，不同的$\eta$会得到(属于这个分布族的)不同的分布。<br>现在证明Bernoulli分布和Gaussian分布都是属于指数分布族。</p>
<h2 id="二-Bernoulli-Distribution"><a href="#二-Bernoulli-Distribution" class="headerlink" title="二. Bernoulli Distribution"></a>二. Bernoulli Distribution</h2><p>先来看一下伯努利分布：<br>$$<br>\begin{align}<br>p(y;\phi) &amp; = \phi^y(1-\phi)^{1-y} \<br>&amp; = exp(log(\phi^y(1-\phi)^{1-y}) \<br>&amp; = exp(log(\phi^y)+log((1-\phi)^{1-y})) \<br>&amp; = exp(ylog(\phi) + (1-y)log(1-\phi)) \<br>&amp; = exp(ylog(\frac{\phi}{1-\phi})+log(1-\phi)) \<br>\end{align}<br>$$<br>其中，<br>$$\eta=log(\frac{\phi}{1-\phi}).$$</p>
<p id="bernoulli">可推出，</p>
$$\phi=\frac{1}{1+e^{-\eta}}$$
这里$\phi$和sigmoid函数长得是有多像！(考虑一下上一篇中我们做出的假设)
将它与指数分布族的形式对应起来得：
$$T(y)=y,$$ $$a(\eta)=-log(1-\phi)=log(1+e^\eta),$$ $$b(y)=1.$$
## 三. Gaussian Distribution
再来看一下高斯分布。还记得之前我们通过概率的角度来解释最小二乘吗？当时我们有一个结论是，$\sigma^2$的值不影响我们最终的代价函数。所以这里为了计算的方便，我们令$\sigma^2=1$.
$$
\begin{align}
p(y;\mu) & = \frac{1}{\sqrt{2\pi}}exp(-\frac{(y-\mu^2)}{2}) \\\
& = \frac{1}{\sqrt{2\pi}}exp(-\frac12y^2+y\mu-\frac12\mu^2) \\\
& = \frac{1}{\sqrt{2\pi}}exp(-\frac12y^2)exp(y\mu-\frac12\mu^2) \\\
\end{align}
$$
<p id="gaussian">将结果与指数分布族的形式对应得到：</p>
$$\eta=\mu,$$ $$T(y)=y,$$ $$b(y)=\frac{1}{\sqrt{2\pi}}exp(-\frac12y^2),$$ $$a(\eta)=\frac12\mu^2=\frac12\eta^2.$$
事实上，除了伯努利分布和高斯分布，有很多分布都是属于指数分布族. 具体可见[张雨石的博客](http://blog.csdn.net/stdcoutzyx/article/details/9207047)指数分布族部分. 
# 四. 广义线性模型
在构造广义线性模型之前，我们需要对给定x的y的条件概率做出以下三个假设: 
1.$y|x;\theta\sim$指数分布族$(\eta)$. 给定$x$和$\theta$, y的分布服从参数为$\eta$的指数分布族中的某个分布, 
2.给定$x$, 我们的目标是预测$T(y)$的期望，即$E[T(y)|x]$,
3.$\eta$和$x$成线性关系, 即$\eta=\theta^Tx$.
下面我们看看如何通过这三个假设推导出最小二乘模型和logistic模型.
## 五. 最小二乘模型
推导过程如下:
$$
\begin{align}
h\_\theta(x) & = E[y|x;\theta] \\\
& = \mu \\\
& = \eta \\\
& = \theta^Tx. 
\end{align}
$$
解释: 
1.第一个等号因为假设2,
2.第二个等号因为$y|x;\theta\sim N(\mu,\sigma^2)$，它的期望就是$\mu$,
3.第三个等号因为<a href="#gaussian">上面</a>推导的高斯分布的指数分布族的形式,
4.第四个等号因为假设3.
## 六. Logistic模型
推导过程如下:
$$
\begin{align}
h\_\theta(x) & = E[y|x;\theta] \\\
& = \phi \\\
& = \frac1{1+e^{-\eta}}\\\
& = \frac1{1+e^{-\theta^Tx}}. 
\end{align}
$$
解释: 
1.第一个等号因为假设2,
2.第二个等号因为$y|x;\theta\sim Bernoulli(\phi)$，它的期望就是$\phi$,
3.第三个等号因为<a href="#bernoulli">上面</a>推导的伯努利分布的指数分布族的形式,
4.第四个等号因为假设3.
# 七. Softmax Regression
多项式分布也属于指数分布族，由他推导出的广义线性模型可以解决多分类的问题，它是logistic模型的一个扩展。
设$y\in \lbrace1,2,...,k\rbrace$, 参数为:$\phi\_1,\phi\_2,...,\phi\_k$, $P(y=i)=\phi\_i$.这样写的话，其实我们的参数是冗余的，因为所有概率的和应该等于1. 所以有$\phi\_k = 1 - (\phi\_1+\phi\_2+...+\phi\_{k-1})$.
为了使多项式分布能写成指数分布族的形式，我们定义$T(y)\in R^{k-1}$: 
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_719.png)
这里我们再引入indicator function:
$$1(True)=1,$$ $$1(False)=0$$
由此可得到：
$$(T(y))\_i=1\lbrace y=i\rbrace$$
下面我们就可以证明多项式分布是属于指数分布族，以下是推导过程：
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_720.png)
其中：
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_721.png)
由:
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_722.png)
可做如下推导：
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_723.png)
即:
$$\phi\_k=\frac{1}{\sum_{i=1}^{k}e^{\eta\_i}}$$
将上式再带回到(7)中可得:
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_724.png)
这个函数就叫做softmax函数. 
下面我们看如何推导出softmax regression:
首先我们有:
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_725.png)
根据广义线性模型的三个假设，我们就得到了$h\_\theta(x)$:
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_726.png)
log likelihood如下:
![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_727.png)

<p>参考:</p>
<ol>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记-子实</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9207047" target="_blank" rel="noopener">牛顿方法、指数分布族、广义线性模型—斯坦福ML公开课笔记4</a></li>
<li><a href="http://logos.name/archives/187" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记二：GLM广义线性模型与Logistic回归</a></li>
<li><a href="http://logos.name/archives/236" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记三：感知机、Softmax回归</a></li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(二) - Logistic回归, 牛顿方法</title>
    <url>/2016/CS229-ML-Notes-Lecture-1-4-%E4%B8%AD.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/creative-designer-photographer-workspace-picjumbo-com.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a></p>
<a id="more"></a>
<hr>
<h1 id="一-对数几率回归"><a href="#一-对数几率回归" class="headerlink" title="一. 对数几率回归"></a>一. 对数几率回归</h1><p>对数几率回归英文叫logistic regression，虽然它叫regression但它是用来解决分类问题的。有很多地方翻译成逻辑回归或者逻辑斯蒂回归。在周志华老师的<a href="https://book.douban.com/subject/26708119/" target="_blank" rel="noopener">《机器学习》</a>中翻译成对数几率回归，这里我也使用这种翻译。对数几率回归的假设函数为：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_688.png" alt=""><br>其中：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_689.png" id="sigmoid"><br>叫做logistic函数或者sigmoid函数。它的函数图像如下：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_690.png" alt=""><br>那么对于对数几率回归我们应该使用什么样的策略来得到$\theta$(我们的代价函数应该是怎样的)?还是按照之前线性回归的思路，我们求出$\theta$的最大似然估计.在这之前我们先推导一下sigmoid函数的导数(后面要用到).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_691.png" alt=""><br>首先，我们做如下假设：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_693.png" alt=""><br>上面两个式子可以用下面一个式子表达：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_694.png" alt=""><br>假设所有的样本都是独立的，所以有：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_695.png" alt=""><br>这样我们就得到了似然函数，max似然函数等价于，先取个log，再max。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_696.png" alt=""><br>同样地，先不管求和符号，对log likelihood求导(这里就需要用到前面的sigmoid函数的求导)：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_697.png" alt=""><br>我们的更新规则是：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_699.png" alt=""><br>带入之后我们就得到了stocasitic gradient ascent(注意，这里是梯度上升，因为我们在求最大值)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_700.png" alt=""><br>这个式子是不是很熟悉？没错，这个和前面讲的最小二乘的规则看上去一模一样，唯一不同的是这里的$h_\theta(x{(i)})$不一样。其实这并不是巧合，下一篇我们就会讲到GLM广义线性模型。</p>
<h1 id="二-感知器学习算法"><a href="#二-感知器学习算法" class="headerlink" title="二. 感知器学习算法"></a>二. 感知器学习算法</h1><p>还记得什么是sigmoid函数吗？它长这样<a href="#sigmoid">Sigmoid Function</a>. 现在我们做如下改变：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_701.png" alt=""><br>让它的输出只能是0或1.更新规则还是如下：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_702.png" alt=""><br>这样我们就得到了感知器学习算法。现在先了解一下即可，后面讲到人工神经网络的时候，我们会详细地介绍。</p>
<h1 id="三-牛顿方法"><a href="#三-牛顿方法" class="headerlink" title="三. 牛顿方法"></a>三. 牛顿方法</h1><p>回到刚才的logistic regression, 我们在$\max_{\theta}l(\theta)$的时候用的是梯度下降. 其实还有另一种方法求$\max_{\theta}l(\theta)$. 那就是Newton’s Method. 它的思想是这样的, 我们需要求一个函数等于0时候的x的值:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_705.png" alt=""><br>首先随机选一个点，求出在改点切线，然后令切线等于0，得到新的x。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_705_1.png" alt=""><br>然后在重复前面的步骤进行迭代。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_706.png" alt=""><br>即更新规则为：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_707.png" alt=""><br>在对数几率回归中，我们是求似然函数的最大值，即导数为0的点。所以，我们把这里的$f(x)$替换为$l’(\theta)$，即得到了牛顿法更新规则：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_708.png" alt=""><br>若$\theta$为向量，则规则变为：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_709.png" alt=""><br>其中，H叫做Hessian矩阵：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_710.png" alt=""><br>牛顿方法通常要比BGD收敛的要快，但是牛顿方法每迭代一次需要消耗更多的计算资源，因为他需要计算Hessian矩阵的逆。所以当n不是很大时，总的来说还是牛顿方法要快一点。<br>关于牛顿法的更新规则，lecture slides里问了一个问题：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_711.png" alt=""><br>如果要求最小值的话，导函数应该是如下所示，此时应该是向右移动，不过此时的斜率是负的，所以更新规则并不需要改变。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/newton'smethod2.jpg" alt=""></p>
<p>参考:</p>
<ol>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记-子实</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9207047" target="_blank" rel="noopener">牛顿方法、指数分布族、广义线性模型—斯坦福ML公开课笔记4</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9113681" target="_blank" rel="noopener">局部加权回归、逻辑斯蒂回归、感知器算法—斯坦福ML公开课笔记3</a></li>
<li><a href="http://logos.name/archives/187" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记二：GLM广义线性模型与Logistic回归</a></li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS229机器学习笔记(一) - 梯度下降, 正规方程, 局部加权</title>
    <url>/2016/CS229-ML-Notes-Lecture-1-4-%E4%B8%8A.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/luxury-silver-pen-with-a-business-diary-picjumbo-com.jpg" alt=""><br>课程信息:  <a href="http://cs229.stanford.edu" target="_blank" rel="noopener">主页</a>　<a href="https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599" target="_blank" rel="noopener">Youtube</a></p>
<a id="more"></a>
<hr>
<p>先下载了第一个<a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf" target="_blank" rel="noopener">Lecture Notes</a>，对应第一个到第四个视频.由于已经有前面Coursera上Machine Learning的基础，所以在这里会省略一部分内容.</p>
<h1 id="一-LMS-算法"><a href="#一-LMS-算法" class="headerlink" title="一. LMS 算法"></a>一. LMS 算法</h1><p>在线性回归中，我们的代价函数为$J(\theta)=1/2\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2$，然后使用梯度下降算法来找到$\theta$，$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)$.现在我们就要解出等式右边的偏导项.首先假设我们只有一个训练样本，这样我们就可以忽略求和符号。<br>$$<br>\begin{align}<br>\frac{\partial}{\partial\theta_j}J(\theta) &amp; = \frac{\partial}{\partial\theta_j}\frac12(h_\theta(x)-y)^2 \<br>&amp; = (h_\theta(x)-y)\frac{\partial}{\partial\theta_j}(h_\theta(x)-y) \<br>&amp; = (h_\theta(x)-y)\frac{\partial}{\partial\theta_j}(\sum_{i=0}^{n}\theta_ix_i-y) \<br>&amp; = (h_\theta(x)-y)x_j<br>\end{align}<br>$$<br>这样我们就得到了$\theta$的更新规则：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_665.png" alt=""><br>这个规则就叫做LMS(Least Mean Squares)update Rule，也叫Widrow-Hoff learning rule.<br>上面是假设我们只有一个样本时的情况，当我们有很多样本时，我们可以对上述规则进行两种修改.第一种叫做BGD(Batch Gradient Descent)，第二种叫做SGD(Stochastic Gradient Descent).</p>
<h2 id="二-Batch-Gradient-Descent"><a href="#二-Batch-Gradient-Descent" class="headerlink" title="二. Batch Gradient Descent"></a>二. Batch Gradient Descent</h2><p>BGD每”走一步”都会考虑到所有的样本：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_666.png" alt=""><br>需要注意的是，通常来说梯度下降可能会得到一个局部最优解，但是对于我们现在考虑的线性回归来说，BGD总是会收敛到全局最优解(因为代价函数是一个凸函数)，当然了，前提是学习率$\alpha$不能太大。</p>
<h2 id="三-Stochastic-Gradient-Descent"><a href="#三-Stochastic-Gradient-Descent" class="headerlink" title="三. Stochastic Gradient Descent"></a>三. Stochastic Gradient Descent</h2><p>在SGD(SGD也叫作incremental gradient descent)中，我们每次只考虑一个训练样本：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_667.png" alt=""><br>在BGD中，因为我们每次需要考虑所有的样本，所以当数据量很大时，我们每走一步都要进行大量的运算，而SGD不会。所以，在实践中，如果训练集很大，我们会优先选择SGD。</p>
<h2 id="四-正规方程"><a href="#四-正规方程" class="headerlink" title="四. 正规方程"></a>四. 正规方程</h2><p>在梯度下降中，我们是不断迭代更新来得到最优解。我们有另一种方法可以一次性求出最优解。<br>首先介绍一些符号，我们用$X$来表示训练样本：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_668.png" alt=""><br>用$\vec{y}$表示目标值：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_669.png" alt=""><br>用向量表示的代价函数如下：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_713.png" alt=""><br>正规方程的推导如下：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_672.png" alt=""><br>然后得到：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_673.png" alt=""><br>这里我跳过了很多步骤，因为lecture notes里面写的很详细，还有矩阵的求导以及一些性质等等。或者也可以学习一下<a href="http://blog.csdn.net/stdcoutzyx/article/details/9101621" target="_blank" rel="noopener">这篇博客</a>。<br>这里想强调一下，Andrew在上课的时候说了，光看没用，你看着别人推导每一步你都觉得很合理，自己一定要盖住答案推导一遍，包括一些直接给的性质最好能自己证明一下。所以，既然选择学这门课，所有的内容一定要自己推导一遍！自己推导一遍！自己推导一遍！<br>好了，下面给出矩阵的一些性质以及部分性质的证明来解决上面正规方程中的一些疑惑(在Coursera课程中，正规方程的结果是直接给出的)<br><font size='4'>性质1:   $$trAB = trBA$$</font><br>证明(写Mathjax公式太费时间了，所以索性直接手写一遍扫描上来。如果有写错的或者写得不清楚的地方，欢迎在下面留言)：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/matrix_trace_1-1.jpg" alt=""><br>由性质1可以得到:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_674.png" alt=""><br><font size='4'>性质2:   $$trA = trA^T$$</font><br><font size='4'>性质3:   $$tr(A+B) = tr(B+A)$$</font><br><font size='4'>性质4:   $$tr(aA) = a(trA)$$</font><br>性质2-4都很容易能看出。下面给出一些有关矩阵求导的一些性质：<br><font size='4'>性质5:   $$\nabla_A trAB = B^T$$</font><br><font size='4'>性质6:   $$\nabla_{A^T} f(A) = (\nabla_Af(A))^T$$</font><br><font size='4'>性质7:   $$\nabla_A trABA^TC = CAB + C^TAB^T$$</font><br><font size='4'>性质8:   $$\nabla_A |A| = |A|(A^{-1})^T$$</font><br>下面给出性质5的证明：<br>在性质1的证明中，我们得到：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_676.png" alt=""><br>所以，<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/matrix_trace_derivative_4.jpg" alt=""><br>性质6比较容易看出，下面是性质7的证明，其中主要用到的就是性质2和乘法求导法则：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/matrix_trace_7.jpg" alt=""><br>上面的性质搞定之后，是时候自己推导一波正规方程了：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/normal_equation.jpg" alt=""><br>拓展阅读: <a href="https://zhuanlan.zhihu.com/p/22757336" target="_blank" rel="noopener">掰开揉碎推导Normal Equation</a>, 强烈推荐！</p>
<h1 id="五-最小二乘法的概率解释"><a href="#五-最小二乘法的概率解释" class="headerlink" title="五. 最小二乘法的概率解释"></a>五. 最小二乘法的概率解释</h1><p>前面我们已经知道了，我们的代价函数为：<br>$$J(\theta) = \frac12(h_\theta(x)-y)^2$$<br>为什么要这样定义代价函数，有没有什么依据呢？这一节我们就从概率的角度来解释这个问题.<br>假设目标变量遵循以下等式：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_678.png" alt=""><br>其中$\epsilon^{(i)}$是一个误差项，并且独立同分布(IID, idependently and identically distributed)于均值为0方差为$\sigma$的高斯分布，即，$\epsilon^{(i)}\sim\mathcal{N}(0, \sigma^2)$:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_679.png" alt=""><br>于是，<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_680.png" alt=""><br>上式代表了参数为$\theta$，在给定$x^{(i)}$的条件下，$y^{(i)}$的概率分布.用向量的形式表示为$p(\vec{y}|X;\theta)$.当我们把上式看成是$\theta$的函数时，它就成了似然函数：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_681.png" alt=""><br>之前我们假设误差项是独立的，所以有：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_682.png" alt=""><br>现在我们有了关于$y^{(i)}$，$x^{(i)}$的概率模型，那么我们该如何选择参数$\theta$?根据极大似然估计，我们应该选择让似然函数最大的那个$\theta$，即$max L(\theta)$. 等价于$max l(\theta)$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_683.png" alt=""><br>也就是min下面这一项：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_684.png" alt=""><br>这样，我们就得到了之前的代价函数。也就是说，在我们的假设下，最小方差回归就是要找到$\theta$的最大似然估计.这里需要注意一下，我们最终选择$\theta$不受$\sigma$的影响.</p>
<h1 id="六-局部加权线性回归"><a href="#六-局部加权线性回归" class="headerlink" title="六. 局部加权线性回归"></a>六. 局部加权线性回归</h1><p>如下图，最左边我们使用的是$y=\theta_0+\theta_1x$去拟合数据得到的结合。类似的第二个是使用$y=\theta_0+\theta_1x+\theta_2x^2$，最右边使用$y=\sum_{j=0}^5\theta_jx^j$拟合数据。看上去像是增加越多的特征，拟合的越好。但这其中就有欠拟合和过拟合的问题。所以特征的选择对于学习算法来说非常重要.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_718.png" alt=""><br>这一节主要简要的讨论一下LWR(Locally weighted linear regression)，它可以让特征的选择不是那么重要(前提是有足够大的训练集).<br>前面讲的现行回归是一种参数方法，计算出$\theta$之后，只要将新的数据带入即可进行预测。而局部加权线性回归(Locally weighted linear regression)，是一种非参数的方法。在每次预测一个值的时候，都需要重新计算代价函数，它的代价函数为：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_686.png" alt=""><br>其中，$w^{(i)}$为权重，要预测的点为$x^{i}$，离该点距离越远的数据的权重越小，反之越大：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_687.png" alt=""><br>$\tau$叫做bandwidth，它控制着数据的权重下降的速度，$\tau$越小权重下降的速度越快。</p>
<p>参考:</p>
<ol>
<li><a href="https://github.com/zlotus/notes-LSJU-machine-learning" target="_blank" rel="noopener">机器学习笔记-子实</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9101621" target="_blank" rel="noopener">线性规划、梯度下降、正规方程组——斯坦福ML公开课笔记1-2</a></li>
<li><a href="http://blog.csdn.net/stdcoutzyx/article/details/9113681" target="_blank" rel="noopener">局部加权回归、逻辑斯蒂回归、感知器算法—斯坦福ML公开课笔记3</a></li>
<li><a href="http://logos.name/archives/148" target="_blank" rel="noopener">斯坦福CS229机器学习课程笔记一：线性回归与梯度下降算法</a></li>
</ol>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十八) - Photo OCR</title>
    <url>/2016/Coursera-ML-Notes-Week-11-Application-Example-Photo-OCR.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_365.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/11" target="_blank" rel="noopener">Application Example Photo OCR</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture18.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture18.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-Photo-OCR"><a href="#一-Photo-OCR" class="headerlink" title="一. Photo OCR"></a>一. Photo OCR</h2><h3 id="1-1-Problem-Description-and-Pipeline"><a href="#1-1-Problem-Description-and-Pipeline" class="headerlink" title="1.1 Problem Description and Pipeline"></a>1.1 Problem Description and Pipeline</h3><p>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_366.png?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_367.png?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_368.png?imageMogr2/thumbnail/!75p" alt=""></p>
<h3 id="1-2-Sliding-Windows"><a href="#1-2-Sliding-Windows" class="headerlink" title="1.2 Sliding Windows"></a>1.2 Sliding Windows</h3><p>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_06.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_07.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_08.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_09.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_10.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_11.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_12.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_13.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_14.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_15.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_16.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<h3 id="1-3-Getting-Lots-of-Data-and-Artificial-Data"><a href="#1-3-Getting-Lots-of-Data-and-Artificial-Data" class="headerlink" title="1.3 Getting Lots of Data and Artificial Data"></a>1.3 Getting Lots of Data and Artificial Data</h3><p>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_18.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_19.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_20.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_21.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_22.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_23.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_24.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_25.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<h3 id="1-4-Ceiling-Analysis-What-Part-of-the-Pipeline-to-Work-on-Next"><a href="#1-4-Ceiling-Analysis-What-Part-of-the-Pipeline-to-Work-on-Next" class="headerlink" title="1.4 Ceiling Analysis: What Part of the Pipeline to Work on Next"></a>1.4 Ceiling Analysis: What Part of the Pipeline to Work on Next</h3><p>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_27.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_28.jpg?imageMogr2/thumbnail/!75p" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/PhotoOCR_29.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十七) - 大规模机器学习</title>
    <url>/2016/Coursera-ML-Notes-Week-10-Large-Scale-Machine-Learning.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_346.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/10" target="_blank" rel="noopener">Large Scale Machine Learning</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Large_Scale_Machine_Learning" target="_blank" rel="noopener">Large Scale Machine Learning</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture17.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture17.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-Gradient-Descent-with-Large-Datasets"><a href="#一-Gradient-Descent-with-Large-Datasets" class="headerlink" title="一. Gradient Descent with Large Datasets"></a>一. Gradient Descent with Large Datasets</h2><h3 id="1-1-Learning-with-Large-Datasets"><a href="#1-1-Learning-with-Large-Datasets" class="headerlink" title="1.1 Learning with Large Datasets"></a>1.1 Learning with Large Datasets</h3><p>　　在使用大量的数据之前, 我们应该现画出学习曲线, 这样可以帮助我们判断使用大量的数据是否会对我们的学习算法有帮助.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_348.png" alt=""></p>
<h3 id="1-2-Stochastic-Gradient-Descent"><a href="#1-2-Stochastic-Gradient-Descent" class="headerlink" title="1.2 Stochastic Gradient Descent"></a>1.2 Stochastic Gradient Descent</h3><p>　　回顾一下线性回归和梯度下降.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_349.png" alt=""><br>　　当数据量非常大的时候, 计算消耗就会很大, 这种将所有样本一起计算的梯度下降称为”Batch gradient descent”.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_350.png" alt=""><br>　　下面是Batch gradient descent与Stochastic gradient descent的对比.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_351.png" alt=""><br>　　Stochastic gradient descent最终会在最小值附近徘徊.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_352.png" alt="">　　</p>
<h3 id="1-3-Mini-Batch-Gradient-Descent"><a href="#1-3-Mini-Batch-Gradient-Descent" class="headerlink" title="1.3 Mini-Batch Gradient Descent"></a>1.3 Mini-Batch Gradient Descent</h3><p>　　Mini-Batch gradient descent是相当于介于Batch gradient descent和Stochastic gradient descent之间的梯度下降.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_353.png" alt="">　<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_354.png" alt="">　</p>
<h3 id="1-4-Stochastic-Gradient-Descent-Convergence"><a href="#1-4-Stochastic-Gradient-Descent-Convergence" class="headerlink" title="1.4 Stochastic Gradient Descent Convergence"></a>1.4 Stochastic Gradient Descent Convergence</h3><p>　　在Stochastic gradient descent中, 我们可以绘出每1000个迭代之后cost的平均图形, 用来检查算法是否正确运行.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_355.png" alt="">　<br>　　下面是几种可能出现的情况.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_356.png" alt="">　<br>　　如果想要得到最小值, 可以逐渐地减小$\alpha$.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_357.png" alt="">　</p>
<h2 id="二-Advanced-Topics"><a href="#二-Advanced-Topics" class="headerlink" title="二. Advanced Topics"></a>二. Advanced Topics</h2><h3 id="2-1-Online-Learning"><a href="#2-1-Online-Learning" class="headerlink" title="2.1 Online Learning"></a>2.1 Online Learning</h3><p>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_359.png" alt="">　<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_360.png" alt="">　</p>
<h3 id="2-2-Map-Reduce-and-Data-Parallelism"><a href="#2-2-Map-Reduce-and-Data-Parallelism" class="headerlink" title="2.2 Map Reduce and Data Parallelism"></a>2.2 Map Reduce and Data Parallelism</h3><p>　　<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_361.png" alt="">　<br>　　<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_364.png" alt="">　<br>　　<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_362.png" alt="">　<br>　　<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_363.png" alt="">　</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十六) - 推荐系统</title>
    <url>/2016/Coursera-ML-Notes-Week-9-Recommender-Systems.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_326.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/9" target="_blank" rel="noopener">Recommender Systems</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Recommender_Systems" target="_blank" rel="noopener">Recommender Systems</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture16.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture16.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-Predicting-Movie-Ratings"><a href="#一-Predicting-Movie-Ratings" class="headerlink" title="一. Predicting Movie Ratings"></a>一. Predicting Movie Ratings</h2><h3 id="1-1-Problem-Formulation"><a href="#1-1-Problem-Formulation" class="headerlink" title="1.1 Problem Formulation"></a>1.1 Problem Formulation</h3><p>　　下图是四位用户对于五部电影的评分（若用户没有评分, 则用❓表示）. 一些符号如下图右下角所示.  推荐系统就是通过已知的评分来判断未知的评分.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_327.png" alt=""></p>
<h3 id="1-2-Content-Based-Recommendations"><a href="#1-2-Content-Based-Recommendations" class="headerlink" title="1.2 Content Based Recommendations"></a>1.2 Content Based Recommendations</h3><p>　　假设每一部电影都对应一个特征向量, 如下图$x_1$, $x_2$所示. 对于第$j$个用户, 我们通过学习得到参数$\theta$. 这样, 这个用户对于第$i$电影的评分就可以$(\theta^{(j)})^Tx^{(i)}$用来估计.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_345.png" alt=""><br>　　用公式化表示为：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_330.png" alt=""><br>　　优化目标为：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_331.png" alt=""><br>　　使用梯度下降来得到最优解（和线性回归相似）.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_332.png" alt=""><br>　　这一种推荐系统是基于内容的, 在这个例子中, 我们使用一个特征向量来表示一部电影. 但是通常情况下, 我们没有这样的向量或者很难得到这样的向量. 这个时候我们就需要不是基于内容的推荐系统. </p>
<h2 id="二-Collaborative-Filtering"><a href="#二-Collaborative-Filtering" class="headerlink" title="二. Collaborative Filtering"></a>二. Collaborative Filtering</h2><h3 id="2-1-Collaborative-Filtering"><a href="#2-1-Collaborative-Filtering" class="headerlink" title="2.1 Collaborative Filtering"></a>2.1 Collaborative Filtering</h3><p>　　假设我们知道用户对于不同种类电影的喜好（$\theta^{(j)}$）以及对各个电影的评分, 我们就大致可以得到各个电影的特征向量（$x$）.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_334.png" alt=""><br>　　下面是上述问题的公式化表达：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_335.png" alt=""><br>　　协同过滤：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_336.png" alt=""></p>
<h3 id="2-2-Collaborative-Filtering-Algorithm"><a href="#2-2-Collaborative-Filtering-Algorithm" class="headerlink" title="2.2 Collaborative Filtering Algorithm"></a>2.2 Collaborative Filtering Algorithm</h3><p>　　协同过滤的优化目标：　　<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_338.png" alt=""><br>　　协同过滤算法：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_339.png" alt=""></p>
<h2 id="三-Low-Rank-Matrix-Factorization"><a href="#三-Low-Rank-Matrix-Factorization" class="headerlink" title="三. Low Rank Matrix Factorization"></a>三. Low Rank Matrix Factorization</h2><h3 id="3-1-Vectorization-Low-Rank-Matrix-Factorization"><a href="#3-1-Vectorization-Low-Rank-Matrix-Factorization" class="headerlink" title="3.1 Vectorization: Low Rank Matrix Factorization"></a>3.1 Vectorization: Low Rank Matrix Factorization</h3><p>　　协同过滤算法矩阵化：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_340.png" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_341.png" alt=""><br>　　使用该算法后, 可以利用得到的特征向量来计算相似的电影.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_342.png" alt=""></p>
<h3 id="3-2-Implementation-Detail-Mean-Normalization"><a href="#3-2-Implementation-Detail-Mean-Normalization" class="headerlink" title="3.2 Implementation Detail: Mean Normalization"></a>3.2 Implementation Detail: Mean Normalization</h3><p>　　假设我们有一个用户Eve, 他没有对任何电影进行评分. 这个时候, 我们运行完算法之后会得到$\theta^{(5)}= \begin{bmatrix} 0 \\ 0  \end{bmatrix}$. 这时在对Eve对电影的评分进行预测的话, 会得到所有的评分都是0. 这显然不太合理.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_343.png" alt=""><br>　　我们需要进行 Mean Normalizaion处理, 如下图所示. 然后对于第$j$个用户在第$i$个电影的评分用$(\theta^{(j)})(x^{(i)})+\mu_i$来预测.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_344.png" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十五) - 异常检测</title>
    <url>/2016/Coursera-ML-Notes-Week-9-Anomaly-Detection.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_303.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/9" target="_blank" rel="noopener">Anomaly Detection</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Anomaly_Detection" target="_blank" rel="noopener">Anomaly Detection</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture15.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture15.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-概率密度估计"><a href="#一-概率密度估计" class="headerlink" title="一. 概率密度估计"></a>一. 概率密度估计</h2><h3 id="1-1-异常检测"><a href="#1-1-异常检测" class="headerlink" title="1.1 异常检测"></a>1.1 异常检测</h3><p>对于飞机引擎有特征$x_1$, $x_2$…, 数据集如下所示. 对于一个新的引擎, 我们希望知道它是否是存在异常, 例如下图所示, 有一个可能是正常的引擎, 有一个引擎可能是异常的.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_304.png" alt=""><br>对于$x_{test}$, 若$p(x_{test})&lt;\epsilon$, 则为异常；若$p(x_{test}) \ge \epsilon$, 则为非异常.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_305.png" alt=""><br>下面是几个异常检测的应用, 1.监测用户异常行为2.工业制造（飞机引擎）3.监测工作异常的计算机<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_306.png" alt=""></p>
<h3 id="1-2-高斯分布"><a href="#1-2-高斯分布" class="headerlink" title="1.2 高斯分布"></a>1.2 高斯分布</h3><p>下图为高斯分布的图形及表达式.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_307.png" alt=""><br>下面几个图形展示了$\mu$和$\sigma$对高斯分布图形的影响.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_308.png" alt=""><br>我们假设一个数据集服从高斯分布, 那么$\mu$和$\sigma$可通过如下公式得出：$\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}$, $\sigma^2=\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)^2$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_309.png" alt="">　　</p>
<h3 id="1-3-异常检测算法"><a href="#1-3-异常检测算法" class="headerlink" title="1.3 异常检测算法"></a>1.3 异常检测算法</h3><p>对于n维的特征向量, 通过如下公式计算$p(x)$：<font size='4'><br>$$\begin{align}<br>p(x) &amp; =p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma_2^2)p(x_3;\mu_3,\sigma_3^2)…p(x_n;\mu_n,\sigma_n^2) \<br>\<br> &amp; = \Pi_{j=1}^np(x_j;\mu_j,\sigma_j^2)<br>\end{align}$$</font><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_310.png" alt=""><br>下图展示了异常检测算法的流程:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_311.png" alt=""><br>举例：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_312.png" alt=""></p>
<h2 id="二-开发异常检测系统"><a href="#二-开发异常检测系统" class="headerlink" title="二. 开发异常检测系统"></a>二. 开发异常检测系统</h2><h3 id="2-1-开发与评估"><a href="#2-1-开发与评估" class="headerlink" title="2.1 开发与评估"></a>2.1 开发与评估</h3><p>在开发学习算法的时候, 我们希望有一种评估这个算法的方式. 为了能够评价一个异常检测系统, 我们假设我们有一些含标签的数据(如果正常, 则$y=0$；如果异常$y=1$).<br>因为我们要通过训练集来做概率密度估计, 所以认定训练集都是非异常的样本.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_313.png" alt=""><br>下面举个例子. 假设我们有10000个正常的引擎, 20个异常的. 将10000个正常中的6000个作为训练集, 2000个作为交叉验证集, 2000个作为测试集; 再将一半异常的放入交叉验证集, 另一半放入测试集. 下图展示了这种分配数据集的方法, 还有一种方法如下图alternative所示, 不推荐这种方法.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_314.png" alt=""><br>下图展示了一些可以用来评估算法的方式, 前面已经讲过这些内容, 这里就不再赘述. 我们可以利用交叉验证集来选取一个合适的$\epsilon$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_315.png" alt=""></p>
<h3 id="2-2-异常检测-vs-监督学习"><a href="#2-2-异常检测-vs-监督学习" class="headerlink" title="2.2 异常检测 vs 监督学习"></a>2.2 异常检测 vs 监督学习</h3><p>上一小节我们学习了异常检测算法, 它是一种无监督学习算法, 但是这个算法中的数据集似乎是有标签的(“异常”, “非异常”), 那么我们为什么不直接使用一种监督学习的方法呢? 这一节我们就来看看异常检测算法和监督学习算法的对比.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_316.png" alt=""><br>一些异常检测与监督学习应用的例子:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_317.png" alt=""></p>
<h3 id="2-3-特征选择"><a href="#2-3-特征选择" class="headerlink" title="2.3 特征选择"></a>2.3 特征选择</h3><p>当描绘出特征的分布图的时候, 如果近似高斯分布就可以直接使用异常检测. 如果不是高斯分布, 则对特征进行某个数学变换也可以得到近似高斯分布. 如下图所示. 　　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_318.png" alt=""><br>某些情况下, 在评估异常检测系统的时候, 我们发现对于一个异常点x它的$p(x)$比较大, 这个时候我们就需要对这个点进行分析, 然后总结出一个新的特征 . 如下图所示, 一开始这个点的分布在下左图, 看上去像一个非异常点；分析并加入新的特征之后, 这个点的分布在下右图, 这个时候我们的异常检测系统就可以判断该点为异常点.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_319.png" alt=""><br>下面举个例子, 我们想要监测计算机是否正常工作. 特征如下图所示. 假设CPU负载和网络流量成线性关系, 如果想要监测某台计算机是否卡在一个死循环中, 我们可以加入$x_5$或$x_6$这样的特征. 正常情况下, 这个特征的值应该保持不大不小, 若某台计算机进入了死循环, 那么它的CPU负载应该很大, 但是网络流量很小, 这个时候这个特征的值就会变的很大. 异常检测系统就很容易监测出这样的情况.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_320.png" alt=""></p>
<h2 id="三-Multivariate-Gaussian-Distribution-Optional"><a href="#三-Multivariate-Gaussian-Distribution-Optional" class="headerlink" title="三. Multivariate Gaussian Distribution (Optional)"></a>三. Multivariate Gaussian Distribution (Optional)</h2><h3 id="3-1-Multivariate-Gaussian-Distribution"><a href="#3-1-Multivariate-Gaussian-Distribution" class="headerlink" title="3.1 Multivariate Gaussian Distribution"></a>3.1 Multivariate Gaussian Distribution</h3><h3 id="3-2-Anomaly-Detection-using-the-Multivariate-Gaussian-Distribution"><a href="#3-2-Anomaly-Detection-using-the-Multivariate-Gaussian-Distribution" class="headerlink" title="3.2 Anomaly Detection using the Multivariate Gaussian Distribution"></a>3.2 Anomaly Detection using the Multivariate Gaussian Distribution</h3><p>　　</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十三) - 非监督学习</title>
    <url>/2016/Coursera-ML-Notes-Week-8-Unsupervised-Learning.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_259.png" alt=""></p>
<ul>
<li>课程地址:：<a href="https://www.coursera.org/learn/machine-learning/home/week/8" target="_blank" rel="noopener">Unsupervised Learning</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Clustering" target="_blank" rel="noopener">Unsupervised Learning</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture13.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture13.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-聚类"><a href="#一-聚类" class="headerlink" title="一. 聚类"></a>一. 聚类</h2><p>在监督学习中, 我们的训练集包含标签, 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_260.png" alt=""><br>在无监督学习中, 训练集不含标签, 我们使用聚类算法来寻找数据集包含的特定结构. 如下图所示, 数据集可以分为两个不同的簇.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_261.png" alt=""><br>下图为聚类的一些应用.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_262.png" alt=""></p>
<h2 id="二-K-均值算法"><a href="#二-K-均值算法" class="headerlink" title="二. K-均值算法"></a>二. K-均值算法</h2><h3 id="2-1-K-均值算法"><a href="#2-1-K-均值算法" class="headerlink" title="2.1 K-均值算法"></a>2.1 K-均值算法</h3><p>这一节我们来介绍k-means算法, 如下图所示, 假设我们想要把下图中的无标签数据分为两个簇. 首先, 我们随机选取两个点作为cluster centroids, 然后计算出这些数据离这两个cluster centroids的距离, 它们离哪个cluster centroid近, 就将它们分配到哪个cluster centroid；（此时数据分为了两块, 我们将它们分别用红色和蓝色标记）我们将红色的cluster centroid移动到所有红色数据的均值的点, 将蓝色的cluster centroid移动到所有蓝色数据的均值的点. 最后重复上面两个步骤, 知道cluster centroid不能再移动为止.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_263.png" alt=""><br>整个过程如下图所示：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/clustering.gif" alt=""><br>下面是k-means算法的通用描述.<br>输入为K和数据集, 注意这里不再需要添加$x_0=1$这一项.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_265.png" alt=""><br>首先随机初始化K个 cluster centroid, 记作$\mu_K$.<br>Cluster assignment: 遍历所有数据, 若第$i$个数据离第$k$个cluster centroid最近, 则记为：$c^{(i)}=k$.<br>Move centroid: 将第$k$个簇的均值赋值给$\mu_k$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_266.png" alt=""><br>对于没有明显区分的数据我们也可以使用k-means算法.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_267.png" alt=""></p>
<h3 id="2-2-代价函数"><a href="#2-2-代价函数" class="headerlink" title="2.2 代价函数"></a>2.2 代价函数</h3><p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_268.png" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_269.png" alt=""></p>
<h3 id="2-3-随机初始化"><a href="#2-3-随机初始化" class="headerlink" title="2.3 随机初始化"></a>2.3 随机初始化</h3><p>下图说明了该如何随机地选取cluster centroid.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_270.png" alt=""><br>随机初始化可能导致算法得到一个local optima, 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_271.png" alt=""><br>为了解决上述问题, 我们需要随机初始化多次, 然后计算出每次$J$的值, 最后得到一个更好的最优解.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_272.png" alt=""></p>
<h3 id="2-4-K的选择"><a href="#2-4-K的选择" class="headerlink" title="2.4 K的选择"></a>2.4 K的选择</h3><p>观察如下数据集, 它们应该分为几个簇呢？有的人会说两个, 也有的说四个. 这一节, 我们来讲该如何选择簇数.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_273.png" alt=""><br>我们使用Elbow method, 即描绘出$J$关于K的图像, 然后找到”elbow”的位置, 这个位置对应的点就是应该选择的簇数. 如下左图所示. 但是, 我们经常会的到如下右图所示的样子, 它没有一个明显的”elbow”, 这样选择就比较困难了.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_274.png" alt=""><br>另一种选择K的方法, 就是根据我们特定的目标去选. 例如, 在给T恤标尺码的时候, 如果我们想要分成三个尺码S, M, L, 那么我们就应该选择K＝3；如果我们想要分成5个尺码XS, S, M, L, XL那么我们就应该选择K＝5.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_275.png" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Unsupervised Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十四) - 数据降维</title>
    <url>/2016/Coursera-ML-Notes-Week-8-Dimensionality-Reduction.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_276.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/8" target="_blank" rel="noopener">Dimensionality Reduction</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Dimensionality_Reduction" target="_blank" rel="noopener">wiki</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture14.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture14.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-数据降维"><a href="#一-数据降维" class="headerlink" title="一. 数据降维"></a>一. 数据降维</h2><p>对于如下图所示的二维特征, 我们可以找到一条直线, 将所有的点投射到这条直线上, 这样就将二维的数据降到了一维, 得到一个新的特征$z_1$. 降维不仅可以让我们节省空间, 更重要的是可以让学习算法运行的更快.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_278.png" alt=""><br>同样的, 可以将三维数据降到二维数据.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_279.png" alt=""><br>降维也可以更好地可视化数据. 如下图的例子, 这里一共有6个特征, 该如何更好地展示这些数据？<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_280.png" alt=""><br>上面的数据不利于我们对数据进行可视化, 但是通过降维之后, 我们得到如下的数据,<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_281.png" alt=""><br>这样就可以轻松地描绘出这些数据了.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_282.png" alt=""></p>
<h2 id="二-PCA"><a href="#二-PCA" class="headerlink" title="二. PCA"></a>二. PCA</h2><h3 id="2-1-什么是PCA"><a href="#2-1-什么是PCA" class="headerlink" title="2.1 什么是PCA"></a>2.1 什么是PCA</h3><p>PCA(主成分分析, Principal components analysis)是用来对数据降维的非监督学习算法. 假设我们有如下图所示的数据, 我们希望将数据降到一维, 那么PCA是如何找到那条合适的直线？<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_300.png" alt=""><br>也许下面红色的线比较适合, 因为每个点投影到这条直线的距离都非常小.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_301.png" alt=""><br>相反地, 每个点投影到下图中的粉色线的距离都非常大.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_302.png" alt=""><br>PCA就是找到一条直线, 使得每个样本到这条直线的投影距离(或者叫投射误差)最小.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_284.png" alt=""><br>通过上面的内容也许会让我们想到线性会对, 但PCA和线性回归是完全不同的两个算法. 在线性回归中(下左图), 我们想要的是能够拟合数据的一条直线, 最小化的是两点之间$y$的差；而在PCA中我们最小化的是点到直线的距离(注意下右图中点垂直于线的距离). 并且, 在线性回归中, 有一个标签$y$；而在PCA中所有的都是特征.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_285.png" alt="">　　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_286.png" alt=""></p>
<h3 id="2-2-PCA算法"><a href="#2-2-PCA算法" class="headerlink" title="2.2  PCA算法"></a>2.2  PCA算法</h3><p>在使用PCA之前, 我们需要对数据进行feature scaling/mean normalization处理.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_287.png" alt=""><br>在PCA中, 我们需要计算的就是向量$u$和新的特征$z$. 　　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_288.png" alt=""><br>首先我们需要计算出矩阵$\Sigma$, 然后使用奇异值分解(sigular value decomposition)来计算$[U, S, V]$. 我们需要的就是$n \times n$的矩阵$U$, 如果我们需要将数据从n维降到k维, 取U的前k列, 记为$U_{reduce}$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_289.png" alt=""><br>最后通过如下的方法得到$z$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_290.png" alt=""><br>下图是对PCA的总结.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_291.png" alt=""></p>
<h2 id="三-使用PCA"><a href="#三-使用PCA" class="headerlink" title="三. 使用PCA"></a>三. 使用PCA</h2><h3 id="3-1-恢复原数据"><a href="#3-1-恢复原数据" class="headerlink" title="3.1 恢复原数据"></a>3.1 恢复原数据</h3><p>数据降维候, 我们可以通过$X_{approx}^{(1)}=U_{reduce}.z^{(1)}$来的得到原始数据的近似值.<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_292.png" alt=""></p>
<h3 id="3-2-选择合适的维度"><a href="#3-2-选择合适的维度" class="headerlink" title="3.2 选择合适的维度"></a>3.2 选择合适的维度</h3><p>那么该如何选择k的值？一般选择一个最小的k并且满足下图中的公式.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_293.png" alt=""><br>我们可以使用下左图中的算法来选择k的值, 但是这样做效率太低；更好的选择是使用下右图中的方法, 在调用一次SVD之后, 我们只需要找到一个最小的k并且满足$\frac{\sum_{i=1}^kS_{ii}}{\sum_{i=1}^nS_{ii}} ge 0.99$即可.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_294.png" alt=""><br>即：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_295.png" alt=""></p>
<h3 id="3-3-PCA总结"><a href="#3-3-PCA总结" class="headerlink" title="3.3 PCA总结"></a>3.3 PCA总结</h3><p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_296.png" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_297.png" alt=""><br>注意, 不要使用PCA来解决过拟合的问题.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_298.png" alt=""><br>在使用PCA之前应该考虑先使用原始数据, 如果使用原始数据不能达到效果, 再考虑使用PCA.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_299.png" alt="">
　　</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十二) - SVM</title>
    <url>/2016/Coursera-ML-Notes-Week-7-Support-Vector-Machines.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_217.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/7" target="_blank" rel="noopener">Support Vector Machines</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Support_Vector_Machines_(SVMs)" target="_blank" rel="noopener">Support Vector Machines</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture12.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture12.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-支持向量机"><a href="#一-支持向量机" class="headerlink" title="一. 支持向量机"></a>一. 支持向量机</h2><h3 id="1-1-代价函数"><a href="#1-1-代价函数" class="headerlink" title="1.1 代价函数"></a>1.1 代价函数</h3><p>我们先来回顾一下logistic regression, 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_218.png" alt=""><br>在logistic regression中, $Cost\left(h_\theta(x),y\right)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))$, 我们将<font size='5'>$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$</font>代入得如下图所示的式子, 当$y=1$的时候, 式子的后半部分为0；当$y=0$的时候, 式子的前半部分为0.<br>当$y=1$的时候, 我们可以将式子的前半部分看成关于z的函数, 并将它描绘出来, 如下图左下细线所示. 如果我们将这个图形稍改变一下变成蓝色线的样子, 这个就是SVM的cost term.<br>当$y=0$的时候, 类似, 如图右下所示. 我们把左边的叫做$Cost_1(z)$, 右边的叫做$Cost_0(z)$<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_219.png" alt=""><br>下面我们看一下, SVM中的cost function是什么样的. 如下图所示, 我们将logistic regression中的两个部分用$Cost_1(z)$和$Cost_1(z)$替换, 并且去掉$1 \over m$常数项.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_222.png" alt=""><br>最后再去掉$\lambda$并加上常数项$C$, 这样我们就得到了SVM的cost function：<font size='4'>$$\mathop{min}\limits_{\theta} C\sum_{i=1}^m \begin{bmatrix} y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})\end{bmatrix} + \frac{1}{2}\sum_{i=1}^n\theta_j^2$$</font>　　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_223.png" alt=""></p>
<h3 id="1-2-最大间隔"><a href="#1-2-最大间隔" class="headerlink" title="1.2 最大间隔"></a>1.2 最大间隔</h3><p>在SVM中, 当y＝1的时候, 我们希望$\theta^Tx\ge1$而不是$\theta^Tx\ge0$；当y＝0的时候, 我们希望$\theta^Tx\le-1$而不是$\theta^Tx\lt0$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_224.png" alt=""><br>现在假设C是一个非常大的数例如$100,000$, 我们看看SVM会有什么结果. 在C非常大的情况下, 我们想要最小化代价函数, 那么就得有第一项为0. 而想要第一项为0, 我们需要保证当y＝1的时候$\theta^Tx\ge1$或者当y＝0的时候$\theta^Tx\le－1$. 在此约束下, 我们的优化问题就变成了<br>$$\mathop{min}\limits_{\theta}\frac{1}{2}\sum_{i=1}^n\theta_j^2 \quad s.t.<br>\begin{cases}<br>\theta^Tx\ge1 \quad \text{if} \quad y^{(i)}=1\<br>\<br>\theta^Tx\le-1 \quad \text{if} \quad y^{(i)}=0<br>\end{cases}$$<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_225.png" alt=""><br>在解决上述优化问题时(暂时先不考虑如何解决的), 我们会发现, SVM会选择一个具有最大间隔的decision boundary如下图中的黑线所示, 而不是绿线或者粉线.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_228.png" alt=""><br>当C非常大的时候, SVM容易收到异常点的影响. 如下图所示, 对于该数据集, SVM会得到黑色线所示的decision boundary.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_230.png" alt="">　　<br>但是当出现异常点的时候, decision boundary会变成下图所示的粉色线. 但是如果C不是非常大的话, 在有异常点的情况下我们还是会得到大概黑色线所示的decision boundary.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_229.png" alt="">　　<br>如果数据集不是线性可分的, 如下图所示, SVM也可以恰当的将它们分开.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_231.png" alt="">　</p>
<h3 id="1-3-数学意义"><a href="#1-3-数学意义" class="headerlink" title="1.3 数学意义"></a>1.3 数学意义</h3><p>这节主要讲为什么当C非常大时SVM会有最大margin的decision boundary的数学证明. 具体内容见视频.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_232.png" alt="">　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_233.png" alt="">　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_235.png" alt="">　</p>
<h2 id="二-核函数"><a href="#二-核函数" class="headerlink" title="二. 核函数"></a>二. 核函数</h2><p>假设我们有一个如下图所示训练集, 我们希望拟合一个非线性的决策边界. 我们可以构造如下的一个多项式, 然后我们使用$f$来代替多项式中的特征变量, 如下图蓝色字所示. 这时候的问题是, 我们不知道这些特征变量是否是适合的特征变量. 那么有没有更好的选择呢？<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_236.png" alt=""><br>这里有构造$f_1$, $f_2$, $f_3$的方法. 如下图所示, 我们现人工地选择三个不同的点, 用$l^{(1)}$, $l^{(2)}$, $l^{(3)}$来表示. 给定x, 我们如下图所示定义$f_1$, $f_2$, $f_3$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_237.png" alt=""><br>我们以$l_1$为例, 如下图所示, 当$x$离$l_1$很近很近的时候$f_1\approx1$；当$x$离$l_1$较远的时候$f_1\approx0$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_247.png" alt=""><br>我们把$f_1$看成是关于$x$的函数, 这样描绘出$f_1$的图形如下图所示. 当$\sigma$的值发生变化时, $f_1$的图形有规律的变化.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_239.png" alt=""><br>假设我们现在已经训练出$\theta_0=-0.5$, $\theta_1=1$, $\theta_2=1$, $\theta_3=0$. 当x在$l^{(1)}$附近时, 计算可知应该预测$y=1$, 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_248.png" alt=""><br>当x离的都比较远的时候（如下图所示）, 计算可知应该预测$y=0$. 当x在$l^{(2)}$附近时, 计算可知应该预测$y=1$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_249.png" alt=""><br>当x在$l^{(1)}$或$l^{(2)}$附近时, 都应该预测$y=1$. 决策边界如下图所示：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_250.png" alt=""><br>那么应该如何选取$l$？<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_241.png" alt=""><br>假设给定m个训练样例, 我们直接将这些点作为$l^{(1)}$, $l^{(2)}$, … , $l^{(m)}$.<br>给定一个训练样例$x^{(i)}$, 我们需要计算出所有的$f_1^{(i)}$, $f_2^{(i)}$, … , $f_m^{(i)}$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_242.png" alt=""><br>最后我们通过如下训练来得到最优的$\theta$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_243.png" alt=""><br>关于$C$和$\sigma$的值对于bias和variance的影响如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_244.png" alt=""></p>
<h2 id="三-使用SVM"><a href="#三-使用SVM" class="headerlink" title="三. 使用SVM"></a>三. 使用SVM</h2><p>当我们使用SVM软件包的时候我们需要选择合适的参数.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_251.png" alt="">　　<br>需要注意的是, 在使用Gaussian核函数之前需要进行feature scaling.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_253.png" alt="">　　<br>其他的核函数.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_254.png" alt="">　　<br>多种分类的情况.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_255.png" alt="">　　<br>logistic regression和SVM适用情况对比.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_257.png" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>SVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十一) - 机器学习系统设计</title>
    <url>/2016/Coursera-ML-Notes-Week-6-Machine-Learning-System-Design.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_201.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/6" target="_blank" rel="noopener">Machine Learning System Design</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Machine_Learning_System_Design" target="_blank" rel="noopener">Machine Learning System Design</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture11.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture11.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>
</li>
</ul>
<hr>
<h2 id="一-构建垃圾邮件分类器"><a href="#一-构建垃圾邮件分类器" class="headerlink" title="一. 构建垃圾邮件分类器"></a>一. 构建垃圾邮件分类器</h2><h3 id="1-1-垃圾邮件分类器"><a href="#1-1-垃圾邮件分类器" class="headerlink" title="1.1 垃圾邮件分类器"></a>1.1 垃圾邮件分类器</h3><p>假设我们需要设计一个垃圾邮件分类器. 如下图所示, 左边为垃圾邮件, 右边为正常邮件.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_202.png" alt=""><br>如下图所示, 我们可以选择100个单词来表示是否是垃圾邮件. 例如, 含有”deal”, “buy”, “discount”等表示垃圾邮件, 含有”andrew”, “now”等表示正常邮件. 特征向量可以用下图左侧蓝色部分表示, 如果出现某个单词, 对应的位置就是1, 否则为0（注：在实际中, 我们使用训练集中最多出现的n个单词(10,000-50,000个)而不是人工选择100个单词）.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_203.png" alt=""><br>现在问题来了, 如何利用你的时间来使得你的分类器的效果最好？下图展示了一些idea.<br>1.使用”honeypot”项目来搜集大量数据（垃圾邮件）<br>2.研究基于邮件路由信息的特征<br>3.研究邮件本身的内容, 例如”dicount”和”dicounts”是否应该看成同一个单词, “deal”和”Dealer”是否应该看成同一个单词；以及标点符号的特征.<br>4.设计高级算法来检测有拼写错误的单词（例如 m0rtgage, med1cine, w4tches.)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_204.png" alt="">　　</p>
<h3 id="1-2-误差分析"><a href="#1-2-误差分析" class="headerlink" title="1.2 误差分析"></a>1.2 误差分析</h3><p>这一节课介绍Error Analysis的概念, 可以帮助我们做出更好的抉择.<br>以下是比较推荐的做法：<br>1.快速实现一个较简单的算法并使用 cross-validation测试.<br>2.描绘出learning curves, 然后决定是需要更多数据还是更多特征等等.<br>3.错误分析：人工地检查算法在cross validation set上出现错误的样例, 找出这些样例中的一些有规律的特征.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_205.png" alt="">　　<br>假设我们在cross validation set中有500样例, 其中100个在我们的算法分类时出现了错误. 我们可以人工地将它们基于邮件的类型来分类. 例如, 我们发现这100个分类错误的邮件中有12个是有关药物的, 有4个是有关假货的, 有53个是关于窃取密码的还有31个是其他的, 这个时候我们就应该多关注关于窃取密码的邮件, 看看能不能从其中发现更好的特征. 再例如, 我们发现这100个分类错误的邮件中有5个有故意的拼写错误, 有16个包含不正常的邮件路由还有32个包含不正常的标点符号的使用等等. 这个时候, 我们应该考虑拼写错误可能对正确分类的影响不大, 我们应该把重点放在不正常的标点符号的使用.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_206.png" alt="">　　<br>最后, 我们应该确保我们对与算法有一种数值评估的方式, 也就是可以用一个数字来表示我们的算法的准确性或者误差. 这个就叫做numerical evaluation, 我们这里先来看一个例子.<br>我们现在考虑要不要把”discount”, “discounts”, “discounted”, “discounting”看成一个单词, 可以使用”stemming”软件来处理自然语言, 并把他们看成同一个单词, 但是这样也可能出错, 例如”universe”和”university”. 我们需要一种数字评估的方式来判断用”stemming”和不用”stemming”的区别. 例如我们可以计算用”stemming”的cross validation error和不用”stemming”时候的cross validation error. 假设用”stemming”的cross validation error为5%而不用”stemming”时候的cross validation error为3%, 这就可能说明使用”stemming”是一个不错的方法, 因为它比较大的降低了分类误差.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_207.png" alt="">　　</p>
<h2 id="二-处理不均衡数据"><a href="#二-处理不均衡数据" class="headerlink" title="二. 处理不均衡数据"></a>二. 处理不均衡数据</h2><h3 id="2-1-准确率和召回率"><a href="#2-1-准确率和召回率" class="headerlink" title="2.1 准确率和召回率"></a>2.1 准确率和召回率</h3><p>假设我们现在训练一个logistic regression去诊断一个病人是否得了癌症, 当我们使用测试集测试的时候发现只有1%的误差. 这看上去我们的模型非常准确. 但是实际上, 只有0.5%的病人是得了癌症的, 这个时候, 1%的误差就不代表这个模型很准确了. 例如, 如下图左下角的代码, 我们不管输入的x是什么, 都直接预测y=0(即不是癌症). 即使这种预测, 也能够有99.5%的准确率. 产生这个的原因就是因为y=1和y=0数量相差非常大, 我们把它叫做skewed classes(一个分类的数量远大于另一个分类的数量).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_208.png" alt="">　　<br>对于skewed classes, 我们就需要另一种方法来判断模型的好坏, 这个方法就是计算准确率(Precision)/召回率(Recall). 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_209.png" alt="">　　</p>
<h3 id="2-2-text-F-1-text-Score"><a href="#2-2-text-F-1-text-Score" class="headerlink" title="2.2 $\text{F}_1 \text{Score}$"></a>2.2 $\text{F}_1 \text{Score}$</h3><p>正常情况下, 当$h_x(\theta) \ge 0.5$的时候我们预测$y=1$, 当$h_x(\theta) \lt 0.5$的时候我们预测$y=0$. 现在假设我们想要预测结果为$y=1$的时候有很高的置信度, 这个时候我们可以阈值从0.5改成0.7或0.9. 这个时候我们的模型就具有一个高precision低recall. 或者我们想要避免将得癌症的患者预测为没有癌症, 这个时候我们就需要设定一个比较低的阈值例如0.3. 在这种情况下, 我们的模型就具有一个高recall低precision.<br>我们可以描绘出Precision／Recall的图形来进行一个权衡.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_210.png" alt="">　<br>现在有三个相同的算法, 但是它们的阈值不同, 对应的precision／recall如下图所示. 我们该选择哪一个?<br>之前说过如果我们只有一个值能够评估算法就好了, 但是现在我们有两个值, 我们该如何做？很自然的我们能想到的一个做法是使用平均值, 但是对于这三个算法均值最高的是算法3, 但是它的precision只有0.02. 显然, 取平均值不是个好办法.<br>这个时候引进$\text{F}_1 \text{Score}$的概念, 公式为<br>$$\text{F}_1 \text{Score}=2\frac{PR}{P+R}$$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_211.png" alt="">　　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_216.png" alt="">　</p>
<h2 id="三-数据集对模型的影响"><a href="#三-数据集对模型的影响" class="headerlink" title="三. 数据集对模型的影响"></a>三. 数据集对模型的影响</h2><p>如下图所示, Banko和Brill使用四种算法对易混词进行分类. 它们发现, 随着训练集数据的增大, 那些一开始表现地不是很好的算法在最后反而精确度较高. </p>
<blockquote>
<p>It’s not who has the best algorithm that wins. It’s who has the most data.</p>
</blockquote>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_212.png" alt="">　　<br>满足上述说法是有一定条件的, 第一个条件就是特征包含了可以准确预测结果的充足信息. 我们可以这样理解：给定特征x, 一个在和y有关的专家是否可以确信地预测y？<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_213.png" alt="">　　<br>第二个条件就是学习算法需要具有很多参数(例如, 在逻辑回归／线性回归中有很多特征, 在神经网络中有许多隐藏层), 并且训练集很大. 这样, 使用大量的数据就不太会过拟合, 从而就会有一个较小的$J_{test}(\theta)$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_214.png" alt="">　　</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(十) - 机器学习经验方法总结</title>
    <url>/2016/Coursera-ML-Notes-Week-6-Advice-for-Applying-Machine-Learning.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_177.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/6" target="_blank" rel="noopener">Advice for Applying Machine Learning</a></li>
<li>课程Wik：<a href="https://share.coursera.org/wiki/index.php/ML:Advice_for_Applying_Machine_Learning" target="_blank" rel="noopener">Advice for Applying Machine Learning</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture10.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture10.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-算法评估"><a href="#一-算法评估" class="headerlink" title="一. 算法评估"></a>一. 算法评估</h2><h3 id="1-1-问题引入"><a href="#1-1-问题引入" class="headerlink" title="1.1 问题引入"></a>1.1 问题引入</h3><p>假设我们现在正在研究预测房价问题, 当我们测试假设函数的时候, 我们发现其中存在着很大的误差. 那么我们下一步应该如和去debugg我们的学习算法？<br>我们可以从如下几个角度去考虑去提升我们的算法:</p>
<ul>
<li>使用更多的训练样例</li>
<li>减少特征数</li>
<li>增加特征数</li>
<li>增加多项式特征</li>
<li>减小$\lambda$的值</li>
<li>增加$\lambda$的值</li>
</ul>
<p>但是, 并不是每一种方法都是有效的, 那么我们该如何知道哪里出了问题呢?　　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_178.png" alt=""></p>
<h3 id="1-2-模型评估"><a href="#1-2-模型评估" class="headerlink" title="1.2 模型评估"></a>1.2 模型评估</h3><p>为了能有效地评估我们的模型, 先要将数据集分成两个部分, 第一部分为训练集(training set), 第二部分为测试集(test set). 注意, 在数据集分割的时候, 最好先打乱数据的顺序, 以免数据集本身的顺序对我们的评估造成影响. 通常, 我们将元数据的70%作为训练集, 30%作为测试集.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_181.png" alt="">　　<br>对于线性回归问题, 训练/测试的过程如下：<br>1.通过训练集求得$\theta$<br>2.带入测试集中计算误差(test set error)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_182.png" alt=""><br>对于logistic回归, 训练/测试的过程和线性回归类似. 只不过这里有两种计算测试集误差的方法, 一种就是使用如下图PPT所示的公式. 另一种就是计算错分类(misclassification error)的比例. 具体为计算方法为：<br>$$err(h_\theta(x),y) =<br>\begin{cases}<br>1,  \quad h_\theta(x) &gt;= 0.5, y=0 | h_\theta(x) &lt; 0.5, y=1 \<br>\<br>0, \quad h_\theta(x) &gt;= 0.5, y=1 | h_\theta(x) &lt; 0.5, y=0<br>\end{cases}$$<br>$$\text{Test error}=\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}err(h_\theta(x_{test}^{(i)}),y_{test}^{(i)})$$<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_183.png" alt="">　</p>
<h3 id="1-3-模型选择-训练-测试-验证集"><a href="#1-3-模型选择-训练-测试-验证集" class="headerlink" title="1.3 模型选择, 训练/测试/验证集"></a>1.3 模型选择, 训练/测试/验证集</h3><p>一个能对数据非常好地拟合的模型并不一定可以有效的泛化, 我们已经看过了过拟合的例子, 如下图所示. 那么, 我们应该用什么来表示一个模型对未来数据的泛化能力呢?<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_184_0.png" alt="">　<br>你也许会想模型在测试集上的误差应该可以表示这个模型的泛化能力. 这样真的好吗? 我们来看一个例子.<br>假设我们现在有10个待选择的模型如下图所示, 为了选出最好的模型, 我们不妨设参数$d$为模型最高阶的阶数, 例如, $d=1$时它是一个一次式,  $d=2$时它是一个二次式等等. 我们按照上一节的测试集方法, 首先在训练集上得到每个模型的参数$\Theta^{(1)}, \Theta^{(2)}, …, \Theta^{(10)}$, 然后使用这些参数来计算对应模型在测试集上的误差$J_{test}(\Theta^{(1)}), J_{test}(\Theta^{(2)}),…,J_{test}(\Theta^{(10)})$. 通过比较后发现, J_{test}(\Theta^{(5)})最小, 所以我们选择这个模型, 并且以J_{test}(\Theta^{(5)})来代表该模型对未知数据的泛化能力. 现在想想, 用测试集误差来代表该模型对未知数据的泛化能力是不公平的. 因为, 这个测试集误差是我们通过对比选择出来的, 它在这个测试集上肯定是最优的, 相当于我们已经看到了这些数据, 用它来代表对未知数据的泛化能力显然不行.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_185.png" alt="">　<br>为了解决上述问题, 我们重新将数据分成训练集(Training set), 交叉验证集(Cross Validation set)和测试集(Test set)三部分, 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_186.png" alt="">　<br>然后计算Traning error, Cross Validation error和Test error, 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_187.png" alt="">　<br>最后, 我们用交叉验证集来选择模型, 如下图所示, 假设我们选择了第四个模型. 然后计算出测试集误差, 这个时候这个测试集误差就可以代表这个模型在新的样例下的适应程度了.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_188.png" alt="">　</p>
<h2 id="二-偏差与方差"><a href="#二-偏差与方差" class="headerlink" title="二. 偏差与方差"></a>二. 偏差与方差</h2><h3 id="2-1-判断偏差与方差"><a href="#2-1-判断偏差与方差" class="headerlink" title="2.1 判断偏差与方差"></a>2.1 判断偏差与方差</h3><p>对于一个模型, 我们如何判断它存在bias还是variance呢?<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_189.png" alt="">　<br>下面我们看一下训练误差和验证误差关于d的图像. 当d比较大的时候(模型非常复杂), 此时可能过拟合了, 这个时候训练误差很小, 验证误差很大；当d比较小的时候(模型比较简单), 模型在训练集和验证集上表现的都比较差. 只有在中间某个位置的时候, 模型在训练集和验证集上都会有很好的表现.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_190.png" alt=""><br>如下图所示, cross validation error较大时为图中最左和最右两种情况. 左边这种情况叫做Bias右边这种情况叫做Variance.<br>$$\text{Bias(underfit)}: \begin{cases} J_{train}(\theta)值较大 \\<br>J_{cv}(\theta) \approx J_{train}(\theta) \end{cases}$$<br>$$\text{Variance(overfit)}: \begin{cases} J_{train}(\theta)值较小 \\<br>J_{cv}(\theta) &gt;&gt; J_{train}(\theta) \end{cases}$$<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_191.png" alt="">　　</p>
<h3 id="2-2-正则化"><a href="#2-2-正则化" class="headerlink" title="2.2 正则化"></a>2.2 正则化</h3><p>假设我们的模型是一个高阶多项式, 我们想使用正则化来避免过拟合. 当$\lambda$选择不同值的时候有不同的效果, 如下图所示. 我们可以把$\lambda$看成正则化的强度, 当$\lambda$很大时, 正则化过强, 就会导致模型变得简单即产生bias; 当$\lambda$很小时, 正则化过弱, 就可能会导致variance.那么问题来了, 我们应该如何选择$\lambda$的值?<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_192.png" alt="">　<br>我们如下定义$J(\theta)$, $J_{train}(\theta)$, $J_{cv}(\theta)$, $J_{test}(\theta)$, 注意只有$J(\theta)$带正则化项.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_193.png" alt="">　　<br>还是按照原来的套路, 我们先选定12个$\lambda$的值如下图所示, 然后分别训练得到相应的$\Theta$, 在使用这12个$\Theta$计算得到12个$J_{cv}(\Theta)$, 然后选择最小的$J_{cv}(\Theta)$对应的$\lambda$. 例如$J_{cv}(\Theta^{(5)})$是最小的, 那么我们就选择第5个$\lambda$, 并计算出$J_{test}(\Theta^{(5)})$来代表这个模型的泛化能力.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_194.png" alt="">　　<br>下面我们来看看, $\lambda$值的变化对$J_{train}(\theta)$和$J_{cv}(\theta)$的影响. 如果$\lambda$很小, 即几乎没有使用正则化, 那么就会出现过拟合；如果$\lambda$很大, 则会出现high bias问题（underfitting）. 这里的图形都是比较理想化的, 在真实的数据中所画出的图形可能比这个要乱并且有噪声, 但大概都可以看出一个趋势, 这样可以帮助你选出验证误差最小的那个点.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_195.png" alt="">　　</p>
<h3 id="2-3-学习曲线"><a href="#2-3-学习曲线" class="headerlink" title="2.3 学习曲线"></a>2.3 学习曲线</h3><p>学习曲线(Learning Curves)可以帮助我们判断模我们的型到底出现了什么样的问题. 我们可以将$J_{train}(\theta)$和$J_{cv}(\theta)$看成关于m(训练样本的数量)的函数, 观察随着m的增加, $J_{train}(\theta)$和$J_{cv}(\theta)$的变化.<br>在下图右侧, 当m=1, 2, 3即样本的数量很少时, 模型可以很容易完全拟合这些样本, 即$J_{train}(\theta)$很小；但是随着样本数量的增加, 想要完美地拟合数据就越来越困难, 即误差会增加. 所以, $J_{train}(\theta)$的图形如下图所示.<br>我们再来看$J_{cv}(\theta)$, 只有当我们有大量的数据时, 我们得到的模型才能更好地泛化, $J_{cv}(\theta)$的图形如下图$J_{cv}(\theta)$所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_196.png" alt="">　　<br>知道了学习曲线之后, 我们可以利用它来帮助我们判断增加训练样本的数量会不会对我们的模型有帮助.<br>现在假设我们的模型存在high bias问题, 即欠拟合. 我们的假设函数如下图右侧所示. 因为我们的模型较为简单, 根本就不能很好的描述数据的规律, 所以不论实在训练集上还是在交叉验证集上的误差都比较大, 并且这个时候增加更多的训练样本对我们的模型不会有任何帮助.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_197.png" alt="">　　<br>现在我们看看另一种情况. 现在假设我们的模型存在high variance问题, 即过拟合. 我们的假设函数如下图右侧所示. 当m较小时, 假设函数可以完全地拟合训练集, 当m越来越大, 想要完全拟合就会困难一些, 但仍然可以很好地拟合, 所以如下图左侧$J_{train}(\theta)$所示. 因为在high variance的时候, 假设函数处于过拟合, 所以$J_{cv}(\theta)$一直都比较大. 但是持续增大样本的数量时, $J_{cv}(\theta)$会一直减小. 如下图左侧所示. 结论：如果学习算法存在high variance问题, 增加训练数据很有可能会有帮助.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_198.png" alt="">　　</p>
<h2 id="三-总结"><a href="#三-总结" class="headerlink" title="三. 总结"></a>三. 总结</h2><table>
<thead>
<tr>
<th align="center">方案</th>
<th align="center">可以解决的问题</th>
</tr>
</thead>
<tbody><tr>
<td align="center">搜集更多的数据</td>
<td align="center">high variance</td>
</tr>
<tr>
<td align="center">使用更少的特征</td>
<td align="center">high variance</td>
</tr>
<tr>
<td align="center">增加额外的特征</td>
<td align="center">high bias</td>
</tr>
<tr>
<td align="center">增加多项式特征</td>
<td align="center">high bias</td>
</tr>
<tr>
<td align="center">减小$\lambda$的值</td>
<td align="center">high bias</td>
</tr>
<tr>
<td align="center">增加$\lambda$的值</td>
<td align="center">high variance</td>
</tr>
<tr>
<td align="center"><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_199.png" alt=""></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">最后我们再来看看神经网络中的bias和variance问题. 如下图所示, 在”较小”的神经网络中, 虽然计算资源消耗较小, 但是容易出现欠拟合的问题. 在”较大”的神经网络中, 会消耗比较大的计算资源, 也会出现过拟合的问题, 但是我们可以使用regularization来解决这个问题, 这样的神经网络比”较小”的神经网络要更有效.</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_200.png" alt=""></td>
<td align="center"></td>
</tr>
</tbody></table>
<p>更多关于bias和variance问题, 请参考:</p>
<ul>
<li><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener">Understanding the Bias-Variance Tradeoff</a></li>
<li><a href="http://blog.csdn.net/abcjennifer/article/details/7797502" target="_blank" rel="noopener">Stanford机器学习—第六讲. 怎样选择机器学习方法、系统</a></li>
</ul>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(九) - 神经网络(下)</title>
    <url>/2016/Coursera-ML-Notes-Week-5-Neural-Networks-Learning.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_150.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/5" target="_blank" rel="noopener">Neural Networks:Learning</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Neural_Networks:_Learning" target="_blank" rel="noopener">Neural Networks:Learning</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture9.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture9.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-代价函数"><a href="#一-代价函数" class="headerlink" title="一. 代价函数"></a>一. 代价函数</h2><p>在神经网络中我们使用L来表示总的层数, 例如下图中L=4; 使用$s_l$表示在第$l$层中unit的个数(不包括bias unit), 如下图中$s_1=3$, $s_2=5$, $s_3=5$, $s_L=4$. 对于一个分类问题要么是二分类(Binary classification)要么是多分类(Multi-class classification). 对于二分类问题, 神经网络只需要一个输出单元; 而对于多分类问题, 需要K个输出单元, 其中K为类的个数.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_151.png" alt=""><br>这里我们按照多分类对代价函数进行描述. 下图为神经网络的代价函数与logistic回归的代价函数的对比. 对于前半部分, 因为神经网络中有K个输出, 所以先要对这K个输出的损失求和; 对于后半部分, 因为每一层(除了输出层)都有一个$\Theta$, 所以正则化项要将这些权重都包括进来(当然, 不需要包括bias unit的权重).<br>如下图所示, $h_\Theta(x)$是一个K维的向量, 即$h_\Theta(x) \in \rm I\!R^K$, 我们用$(h_\Theta(x))_i$来表示第$i$个输出值.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_152.png" alt=""><br>下面这段文字是这个<a href="https://share.coursera.org/wiki/index.php/ML:Neural_Networks:_Learning" target="_blank" rel="noopener">课程wiki</a>对于神经网络代价函数的解释.</p>
<blockquote>
<ul>
<li>the double sum simply adds up the logistic regression costs calculated for each cell in the output layer; </li>
<li>the triple sum simply adds up the squares of all the individual Θs in the entire network;</li>
<li>the i in the triple sum does not refer to training example i.   </li>
</ul>
</blockquote>
<h2 id="二-逆-反向传播算法"><a href="#二-逆-反向传播算法" class="headerlink" title="二. 逆/反向传播算法"></a>二. 逆/反向传播算法</h2><p>知道了代价函数之后, 我们还是按照套路来求代价函数的最优解. 同样地, 我们希望使用梯度下降来找到最优解. 想要使用梯度下降当然需要求出”梯度”即偏导项<font size='4'>$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)$</font>. 而计算这个偏导项的过程就叫做逆传播算法或者叫反向传播算法.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_153.png" alt=""><br>首先我们根据前向传播算法来得到$a^{(1)}$, $a^{(2)}$, $a^{(3)}$, $a^{(4)}$和$z^{(2)}$, $z^{(3)}$, $z^{(4)}$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_154.png" alt=""><br>在逆传播算法中我们定义每层的误差<br>$$\delta^{(l)}=\frac{\partial}{\partial z^{(l)}}J(\Theta)$$<br>$\delta_j^{(l)}$表示第$l$层第$j$个节点的误差. 为了求出偏导项<font size='4'>$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)$</font>, 我们首先要求每一层的$\delta$(不包括第一层, 因为第一层是输入层). 首先, 对于输出层即第4层(这里我们不考虑正则化):</p>
<p>$$\begin{align}<br>\delta_j^{(4)} &amp; = \frac{\partial}{\partial z_i^{(4)}}J(\Theta) \<br>\<br>&amp; = \frac{\partial J(\Theta)}{\partial a_i^{(4)}}\frac{\partial a_i^{(4)}}{\partial z_i^{(4)}} \<br>\<br>&amp; = -\frac{\partial}{\partial a_i^{(4)}}\sum_{k=1}^K\left[y_kloga_k^{(4)}+(1-y_k)log(1-a_k^{(4)})\right]g’(z_i^{(4)})  \<br>\<br>&amp; = -\frac{\partial}{\partial a_i^{(4)}}\left[y_iloga_i^{(4)}+(1-y_i)log(1-a_i^{(4)})\right]g(z_i^{(4)})(1-g(z_i^{(4)}))  \<br>\<br>&amp; = \left(\frac{1-y_i}{1-a_i^{(4)}}-\frac{y_i}{a_i^{(4)}}\right)a_i^{(4)}(1-a_i^{(4)}) \<br>\<br>&amp; = (1-y_i)a_i^{(4)} - y_i(1-a_i^{(4)}) \<br>\<br>&amp; = a_i^{(4)} - y_i<br>\<br>\end{align}$$<br>(关于g’(z_i^{(4)})的证明见本文最后的补充材料其中$a_j^{(4)}$就是$(h_\Theta(x))_j$, $j$就是输出单元的个数, 用向量化的表示为：$\delta^{(4)}=a^{(4)}-y$. 对于剩下每层的$\delta_i^{(l)}$如下:  </p>
<p>$$\begin{align}<br>\delta_i^{(l)} &amp; = \frac{\partial}{\partial z_i^{(l)}}J(\Theta) \<br>\<br>&amp; = \sum_{j=1}^{S_j}\frac{\partial J(\Theta)}{\partial z_j^{(l+1)}}\cdot\frac{\partial z_j^{(l+1)}}{\partial a_i^{(l)}}\cdot\frac{\partial a_i^{(l)}}{\partial z_i^{(l)}} \<br>\<br>&amp; = \sum_{j=1}^{S_j}\delta_j^{(l+1)}\cdot\Theta_{ij}^{(l)}\cdot g’(z_i^{(l)}) \<br>\<br>&amp; = g’(z_i^{(l)})\sum_{j=1}^{S_j}\delta_j^{(l+1)}\cdot\Theta_{ij}^{(l)}<br>\end{align}$$<br>写成向量的形式即为:<br>$$\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})$$<br>求出来所有的$\delta$之后, 可以很容易得到<font size='4'>$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=a_i^{(l)}\delta_j^{(l+1)}$</font>, 这就是我们要求的偏导项(忽略正则化).<br> <img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_155.png" alt=""><br>上面所有的推导都是基于一个样本的, 现在假设有$m$个样本, 我们可以使用BGD来求解最优值. 假设我们有一个训练集如下图所示, 对于所有的$l,i,j$我们先令$\Delta_{ij}^{(l)}=0$, 然后对于每一个样本, 都进行如下图所示的计算并使用$\Delta_{ij}^{(l)}$进行累加. 其中$\Delta_{ij}^{(l)}:=\Delta_{ij}^{(l)}+a_j^{(l)}\delta_i^{(l+1)}$用向量的表示形式为：$\Delta^{(l)}:=\Delta^{(l)}+\delta^{(l+1)}(a^{(l)})^T$. 最后, 计算出$D_{ij}^{(l)}$如下图所示(注意,ppt上有个小错误, 根据我们的代价函数应该是$D_{ij}^{(l)}:=\frac{1}{m}(\Delta_{ij}^{(l)}+\lambda\Theta_{ij}^{(l)})$).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_156.png" alt=""><br>关于BP算法, 可以参考Caltech的<a href="https://www.youtube.com/watch?v=Ih5Mr93E-2c&t=3013s&index=10&list=PLD63A284B7615313A" target="_blank" rel="noopener">Learning from Data</a>.</p>
<h2 id="三-参数调整"><a href="#三-参数调整" class="headerlink" title="三. 参数调整"></a>三. 参数调整</h2><p>为了使用高级优化算法, 这一节我们讲如何调整参数. 在神经网络中, 参数$\Theta^{(j)}$是一个矩阵, 而在之前利用高级优化算法的课程中, 我们知道$\theta$是一个向量, 这个时候就需要对$\Theta$进行Unrolling.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_161.png" alt=""><br>如下图所示的神经网络中, (ppt中出现了一些错误, 根据$\Theta_1$, $\Theta_2$, $\Theta_3$, 这个神经网络应该是有4层, 并且$s_1=10$, $s_2=10$, $s_3=10$, $s_4=1$. )$\Theta^{(1)}$, $\Theta^{(2)}$, $\Theta^{(3)}$, $D^{(1)}$, $D^{(2)}$, $D^{(3)}$如下图所示, 在Octave/Matlab中, 我们可以使用如下代码将所有对应的矩阵转化成一个向量：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">　　thetaVec = [Theta1(:); Theta2(:); Theta3(:)];</span></pre></td></tr><tr><td class="code"><pre><span class="line">　　DVec = [D1(:); D2(:); D3(:)]</span></pre></td></tr><tr><td class="code"><pre><span class="line">　　<span class="comment">%使用如下代码可以得到原来的矩阵</span></span></pre></td></tr><tr><td class="code"><pre><span class="line">　　Theta1 = <span class="built_in">reshape</span>(thetaVec(<span class="number">1</span>: <span class="number">110</span>), <span class="number">10</span>, <span class="number">11</span>);</span></pre></td></tr><tr><td class="code"><pre><span class="line">　　Theta2 = <span class="built_in">reshape</span>(thetaVec(<span class="number">111</span>: <span class="number">220</span>), <span class="number">10</span>, <span class="number">11</span>);</span></pre></td></tr><tr><td class="code"><pre><span class="line">　　Theta3 = <span class="built_in">reshape</span>(thetaVec(<span class="number">221</span>: <span class="number">231</span>), <span class="number">1</span>, <span class="number">11</span>);</span></pre></td></tr></table></figure>
<p>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_162.png" alt=""><br>　　下图为利用unrolling来使用高级优化算法的步骤：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_163.png" alt=""></p>
<h2 id="四-梯度检查"><a href="#四-梯度检查" class="headerlink" title="四. 梯度检查"></a>四. 梯度检查</h2><p>由于神经网络的复杂性, 我们在使用梯度下降或者其他的高级优化算法时可能会出现bug, 即使感觉上好像没什么问题. 那么如何能有效地检查出问题呢, 这个时候就需要使用Gradient Checking.<br>首先, 如下图所示, 我们使用如下近似：$\frac{d}{d\theta}J(\theta)\approx \frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}$, 通常我们取$\epsilon=10^{-4}$. 　　<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_164.png" alt=""><br>上面的例子中$\theta$是一个实数, 在下图中, $\theta$是一个向量, 此时是对偏导数进行数值估计.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_165.png" alt=""><br>在实际运用中, 我们使用如下代码来计算gradApprox. 然后, 我们将通过逆传播算法计算得来的DVec和gradApprox进行比较, 如果这两个值近似的话, 那么就说明我们的逆传播算法运行地没有问题.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_166.png" alt=""><br>下图描述了使用Gradient Checking时的步骤. 需要主意的是, 在得到gradApprox之后一定要即时关闭Gradient Checking, 因为它会非常大地消耗计算资源.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_167.png" alt=""></p>
<h2 id="五-随机初始化"><a href="#五-随机初始化" class="headerlink" title="五. 随机初始化"></a>五. 随机初始化</h2><p>在之前的linear regression和logistic regression中我们初始化$\theta$的值为0. 在神经网络中也可以这么初始化吗?<br>现初始化$\Theta_{ij}^{(l)}=0$, 此时会有$a_1^{(2)}=a_2^{(2)}$, $\delta_1^{(2)}=\delta_2^{(2)}$. 这样不论进行多少次更新, 永远会有$a_1^{(2)}=a_2^{(2)}$, 也就是说这两个神经元是完全等同的, 这显然不合理, 那么我们应该如何初始化参数呢?<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_169.png" alt=""><br>对于$\Theta^{(1)} \in \mathbb{R}^{10\times 11}$, 使用随机函数来进行初始化：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">Theta1 = <span class="built_in">rand</span>(<span class="number">10</span>, <span class="number">11</span>)*(<span class="number">2</span>*INIT_EPSILON) - INIT_EPSILON</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_170.png" alt=""></p>
<h2 id="六-模型选择"><a href="#六-模型选择" class="headerlink" title="六. 模型选择"></a>六. 模型选择</h2><p>神经网络有许许多多种结构, 我们应该如何选择神经网络的结构？<br>在神经网络中, 有两个是确定的, 那就是输入单元的个数和输出单元的个数. 因为前者就是特征的个数（维度）, 而后者是分类的数量. 一个合理的默认值为, 有一个隐藏层；或者有多个隐藏层, 并且这些隐藏层单元数量相等.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_171.png" alt=""></p>
<h2 id="七-总结"><a href="#七-总结" class="headerlink" title="七. 总结"></a>七. 总结</h2><p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_172.png" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_173.png" alt=""></p>
<h2 id="八-应用"><a href="#八-应用" class="headerlink" title="八. 应用"></a>八. 应用</h2><p> <a href="https://www.coursera.org/learn/machine-learning/lecture/zYS8T/autonomous-driving" target="_blank" rel="noopener">视频地址</a><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_175.png" alt=""></p>
<p>以下为补充材料:<br>$$\begin{align}<br>\frac{\partial g(z)}{\partial z} &amp; = -\left( \frac{1}{1 + e^{-z}} \right)^2\frac{\partial{}}{\partial{z}} \left(1 + e^{-z} \right) \<br>\<br>&amp; = -\left( \frac{1}{1 + e^{-z}} \right)^2e^{-z}\left(-1\right) \<br>\<br>&amp; = \left( \frac{1}{1 + e^{-z}} \right) \left( \frac{1}{1 + e^{-z}} \right)\left(e^{-z}\right) \<br>\<br>&amp; = \left( \frac{1}{1 + e^{-z}} \right) \left( \frac{e^{-z}}{1 + e^{-z}} \right) \<br>\<br>&amp; = \left( \frac{1}{1+e^{-z}}\right)\left( \frac{1+e^{-z}}{1+e^{-z}}-\frac{1}{1+e^{-z}}\right) \<br>\<br>&amp; = g(z) \left( 1 - g(z)\right) \<br>\<br>\end{align}$$</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Neural Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(八) - 神经网络(上)</title>
    <url>/2016/Coursera-ML-Notes-Week-4-Neural-Networks-Representation.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_119.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/4" target="_blank" rel="noopener">Neural Networks:Representation</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Neural_Networks:_Representation" target="_blank" rel="noopener">Neural Networks:Representation</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture8.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture8.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-为什么要用神经网络"><a href="#一-为什么要用神经网络" class="headerlink" title="一. 为什么要用神经网络"></a>一. 为什么要用神经网络</h2><p>对于下图所示的分类问题, 我们可以利用高阶项来构造我们的假设函数. 但是, 实际问题往往有很多特征. 例如在房价预测的问题中, 我们可能有100个特征, 如果想要多项式包含所有的二次项那么这个多项式会有5,000个特征(复杂度为$O(n^2)$). 这样就会带来两个问题：1.过拟合 2.消耗大量计算资源. 当然可以使用所有二次项的子集, 例如$x_1^2, x_2^2, x_3^2, …$, 但是这样可能又欠拟合. 如果想要包含所有的三次项, 那大概会有170,000个特征, 复杂度为$O(n^3)$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_120.png" alt=""><br>下面考虑一个计算机视觉的问题. 假设我们想训练一个可以识别汽车图片的分类器. 一张图片对于计算机来说就是一堆数字矩阵.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_121.png" alt=""><br>对于一个50x50的图像会有2,500个像素, 即n=2,500(如果是RGB图的话n就是7500). 如果我们想要包含所有的二次项, 那么特征就是3,000,000个.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_123.png" alt=""><br>对于这类问题使用logistic回归显然是没法解决的, 这个时候就要用到神经网络(Neural Network).</p>
<h2 id="二-神经网络结构"><a href="#二-神经网络结构" class="headerlink" title="二. 神经网络结构"></a>二. 神经网络结构</h2><p>下图为一个神经元(neuron), 它的输入为$x_1, x_2, x_3$, 有时候为了方便我们添加一个$x_0$, 叫做bias unit. 它的输出为$h(\theta)$. $\theta$也叫做weights.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_128.png" alt=""><br>下图为由多个神经元组成的神经网络. 第一层叫做输入层(input layer), 最后一层叫做输出层(output layer), 中间的叫做隐藏层(hidden layer).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_130.png" alt=""><br>注意: 如果在第$j$层有$s_j$个units, 在第$j+1$层有$s_{j+1}$个units, 那么$\Theta^{(j)}$就是一个$s_{(j+1)} \times (s_j + 1)$的矩阵. (因为前一层增加了一个bias unit)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_129.png" alt=""></p>
<h2 id="三-前向传播算法"><a href="#三-前向传播算法" class="headerlink" title="三. 前向传播算法"></a>三. 前向传播算法</h2><p>前向传播算法其实就是有输入层计算出输出的过程, 这里为了提高计算的效率, 我们使用向量化的算法. 首先我们做如下定义:<br>$z_1^{(2)}=\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3$,<br>$z_2^{(2)}=\Theta_{20}^{(1)}x_0+\Theta_{21}^{(1)}x_1+\Theta_{22}^{(1)}x_2+\Theta_{23}^{(1)}x_3$,<br>$z_3^{(2)}=\Theta_{30}^{(1)}x_0+\Theta_{31}^{(1)}x_1+\Theta_{32}^{(1)}x_2+\Theta_{33}^{(1)}x_3$,<br>$$z^{(2)} =\begin{bmatrix} z_1^{(2)} \\ z_2^{(2)} \\ z_3^{(2)} \end{bmatrix}$$<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_132.png" alt=""><br>这样$z^{(2)}$的计算就可以写成向量计算: $z^{(2)} = \Theta^{(1)}x$, 进而有$a^{(2)}=g(z^{(2)})$. 为了和后面几层的写法统一, 我们令$a^{(1)}=x$, 所以有$z^{(2)} = \Theta^{(1)}a^{(1)}$.<br>我们在隐藏层加上一个额外的$a_{(0)}^{(2)}=1$, 得到$a^{(2)}=\begin{bmatrix} a_0^{(2)} \\ a_1^{(2)} \\ a_2^{(2)} \\ a_3^{(2)} \end{bmatrix}$, 同理$z^{(3)}=\Theta^{(2)}a^{(2)}$. 最后$h_\Theta(x)=a^{(3)}=g(z^{(3)})$<br>现在我们先把刚才的神经网络的输入层遮住, 观察剩下部分的结构以及算法我们发现, 其实这一部分其实就是前面所讲的logistic回归. 不同的是, 它的输入$\alpha$是由正真的特征$x$学习得到的, 可以把$\alpha$看成新的特征, $x$看成初始特征. 这样, 神经网络就相当于通过初始特征学习到新的特征, 再通过新的特征进行logistic回归得到输出结果.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_133.png" alt=""><br>当然, 神经网络不仅仅是上面一种结构, 下图展示了另一种神经网结构.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_134.png" alt=""></p>
<h2 id="四-神经网络与逻辑运算"><a href="#四-神经网络与逻辑运算" class="headerlink" title="四. 神经网络与逻辑运算"></a>四. 神经网络与逻辑运算</h2><h3 id="4-1-逻辑与-逻辑或"><a href="#4-1-逻辑与-逻辑或" class="headerlink" title="4.1 逻辑与,逻辑或"></a>4.1 逻辑与,逻辑或</h3><p>　　逻辑与运算, 参数为-30, 20, 20. 结果如下图所示：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_136.png" alt=""><br>　　逻辑或运算, 参数为-10, 20, 20. 结果如下图所示：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_137.png" alt=""></p>
<h3 id="4-2-逻辑非"><a href="#4-2-逻辑非" class="headerlink" title="4.2 逻辑非"></a>4.2 逻辑非</h3><p>　　逻辑非运算, 参数为10, -20. 结果如下图所示：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_138.png" alt=""><br>　　将三个神经单元组成一个神经网络, 可以得到同或运算：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_139.png" alt=""></p>
<h2 id="五-多分类"><a href="#五-多分类" class="headerlink" title="五. 多分类"></a>五. 多分类</h2><p>　　下两图为多种分类问题：<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_144.png" alt=""><br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_145.png" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Neural Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(七) - 来自吴恩达的狗粮和鸡汤</title>
    <url>/2016/Coursera-ML-Notes-Week-3-chicken-soup.html</url>
    <content><![CDATA[<center>![](https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/andrewngandhiswift.jpg?imageMogr2/thumbnail/!60p)</center>
> 结婚两周年之际和Carol一起登上了八达岭，愿长城见证我们的爱情 。
> -- [AndrewNg吴恩达 ](http://weibo.com/5866810652/Dqs1UvKQd)

<a id="more"></a>

<hr>
<p>　　在第三周的课最后，Andrew教授给我们准备了一大碗鸡汤。鸡汤在7:09处：<a href="https://www.coursera.org/learn/machine-learning/lecture/4BHEy/regularized-logistic-regression" target="_blank" rel="noopener">视频</a><br>　　字幕如下:<br>　　<img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_115.png" alt=""><br>　　各位慢慢品尝。</p>
]]></content>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(六) - 正则化</title>
    <url>/2016/Coursera-ML-Notes-Week-3-Regularization.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_100.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/3" target="_blank" rel="noopener">Regularization</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Regularization" target="_blank" rel="noopener">Regularization</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture7.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture7.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-过拟合"><a href="#一-过拟合" class="headerlink" title="一. 过拟合"></a>一. 过拟合</h2><p>如下图所示, 使用三种不同的多项式作为假设函数对数据进行拟合, 从左一和右一分别为过拟合和欠拟合.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_101.png" alt=""><br>对率回归:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_102.png" alt=""><br>解决过拟合问题大致分为两种, 一种是减少特征的数量, 可以人工选择一些比较重要的特征留下, 也可以使用模型选择算法(Model selection algorithm,后面的课程会介绍)；另一种就是正则化(Regularization).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_103.png" alt=""></p>
<h2 id="二-正则化"><a href="#二-正则化" class="headerlink" title="二. 正则化"></a>二. 正则化</h2><p>如图所示的两个假设函数, 其中第二个为过拟合. 那么该如何改变代价函数能够让最中的假设函数不过拟合? 对比两个假设函数我们可以看到, 它们的区别就在于第二个多了两个高阶项. 也就是说, 我们不希望出现后面两个高阶项, 即希望$\theta_3$, $\theta_4$越小越好.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_831.png" alt=""><br>通过上面的想法, 我们把$\theta_3$, $\theta_4$放到代价函数里, 并且加上很大的权重(1000):<br>$$J(\theta)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)} )^2+1000\theta_3^2+1000\theta_4^2$$<br>现在如果要最小化代价函数, 那么最后两项也必须得最小. 这个时候, 就有$\theta_3\approx0$, $\theta_4\approx0$. 从而这个四次多项式就变成了一个二次多项式, 解决了过拟合的问题.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_104.png" alt=""><br>对于正则化的一般思路是, 减少特征的数量, 降低模型的复杂度. 所以我们要对每个参数进行惩罚, 从而得到’更简单’的并且可以防止过拟合的模型. 但是在实际问题中我们很难判断哪些特征比较重要, 所以对每一个参数(除了第一个)参数进行惩罚, 将代价函数改为:<br><font size='4'>$$J(\theta)=\frac{1}{2m}\left[\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)} )^2+\lambda\sum_{i=1}^n\theta_j^2\right]$$</font><br>其中, $\lambda\sum_{i=1}^n\theta_j^2$叫做正则化项(Regularization Term), $\lambda$叫做正则化参数(Regularization Parameter). $\lambda$的作用就是在”更好地拟合数据”和”防止过拟合”之间权衡.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_105.png" alt=""><br>如过$\lambda$过大的话, 就会导致$\theta_1$、$\theta_2$、$\theta_3$…近似于0, 这样我们的假设函数就为：$h_\theta(x)=\theta_0$. 这时就变成了欠拟合(Underfit). 所以需要选择一个合适的$\lambda$. 后面的课程会讲到自动选择合适的$\lambda$的方法.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_108.png" alt=""></p>
<h2 id="三-正则化线性回归"><a href="#三-正则化线性回归" class="headerlink" title="三. 正则化线性回归"></a>三. 正则化线性回归</h2><p>通过正则化之后的$J(\theta)$我们可以得到对应的梯度下降算法, 如下图所示. 因为我们不对$\theta_0$进行惩罚, 所以将$\theta_0$的规则单独写出来, 其余的参数更新规则如下图第三行公式. 公式前半部分$1-\alpha\frac{\lambda}{m}$是一个比1小一点点的数(教授举了个例子大概是0.99), 而公式的后半部分和没有进行正则化的梯度下降的公式的后半部分是完全一样的. 所以区别就在于前半部分会将$\theta_j$缩小(因为乘了一个小于1的数).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_112.png" alt=""><br>同样, 在正规方程中, 我们只需要在公式中加上一部分如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_110.png" alt=""><br>即:<br>$$\theta=(X^TX+\lambda\begin{bmatrix} 0&amp;0&amp;0&amp;0&amp;…&amp;0\\ 0&amp;1&amp;0&amp;0&amp;…&amp;0\\ 0&amp;0&amp;1&amp;0&amp;…&amp;0\\ 0&amp;0&amp;0&amp;1&amp;…&amp;0\\ 0&amp;0&amp;0&amp;0&amp;…&amp;0 \\ 0&amp;0&amp;0&amp;0&amp;…&amp;1 \end{bmatrix})^{-1}X^Ty$$<br>并且对于正则化后的正规方程, 只要$\lambda\gt0$, 括号里的那一项总是可逆的:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_832.png" alt=""></p>
<h2 id="四-正则化对率回归"><a href="#四-正则化对率回归" class="headerlink" title="四. 正则化对率回归"></a>四. 正则化对率回归</h2><p>类似地, 正则化逻辑回归中的代价函数和梯度下降如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_114.png" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_111.png" alt=""><br>下图是使用正则化的高级优化算法, 只需要在计算jVal时在后面加上一个正则化项以及在梯度后面减去一个$\frac{\lambda}{m}\theta_j$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_113.png" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(五) - Logistic Regression</title>
    <url>/2016/Coursera-ML-Notes-Week-3-Logistic-Regression.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_67.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/3" target="_blank" rel="noopener">Logistic Regression</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Logistic_Regression" target="_blank" rel="noopener">Logistic Regression</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture6.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture6.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-模型展示"><a href="#一-模型展示" class="headerlink" title="一. 模型展示"></a>一. 模型展示</h2><h3 id="1-1-从线性回归解到对数几率回归"><a href="#1-1-从线性回归解到对数几率回归" class="headerlink" title="1.1 从线性回归解到对数几率回归"></a>1.1 从线性回归解到对数几率回归</h3><p>前面的课程中提到了一些分类问题:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_68.png" alt=""><br>对于乳腺癌的那个例子, 数据集如下所示. 如果使用线性回归来处理这个问题, 我们可能得到这样一个假设函数:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_615.png" alt=""><br>然后我们设定一个阈值0.5, 当假设函数的输出大于这个阈值时我们预测$y=1$；当假设函数的输出小于0.5时, 我们预测$y=0$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_69.png" alt=""><br>即使我们的问题是一个分类问题, 但是对于上面这个特定的例子, 看上去使用线性回归好像还是挺合理的. 但是如果我们再增加一个数据(下图最右), 使用Linear Regression就会得到如图蓝色线所示的$h_\theta(x)$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_616.png" alt=""><br>这个结果显然是不合理的, 它有很多错误的分类. 直观上来看, 要是能得到图中垂直于横轴的(图中蓝色)线那边是极好的.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_70.png" alt=""><br>而且即使所有的训练样例的 y = 0或1, 使用线性回归得到的$h_\theta(x)$也有可能大于1或者小于0.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_617.png" alt=""><br>所以我们需要一个能更好地处理分类问题的模型, 即对数几率回归(Logistic Regression/Logit regression). (有些地方翻译成’逻辑回归’或者’逻辑斯蒂格回归’) 需要注意的是这个模型虽然叫regression, 但是它是一个用来解决分类问题的模型. 在对率回归(对数几率回归的简称)中, $0\le h_\theta(x)\le1$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_618.png" alt=""></p>
<h3 id="1-2-假设函数"><a href="#1-2-假设函数" class="headerlink" title="1.2 假设函数"></a>1.2 假设函数</h3><p>在对率回归中, 假设函数为$h_\theta(x)=g(\theta^Tx)$, 其中$g(z)=\frac{1}{1+e^{-z}}$, $g(z)$叫做Sigmoid Function或者对率函数(Logistic Function).<br>对数几率函数是Sigmoid函数的一种, 它将z值转化为一个接近0或1的y值, 并且其输出值在$z=0$附近变化很陡. Sigmoid函数即形似S的函数, 对率函数是Sigmoid函数最重要的代表.<br><font size='5'>$${h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}}$$</font><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_72.png" alt=""><br>我们可以将对率函数的输出理解为当输入为x的时候, y=1的概率. 可以用$h_\theta(x)=P(y=1|x;\theta)$表达. 例如, 在下图中, 我们给定一个x, 它的假设函数的输出为0.7, 我们可以说这个病人的肿瘤为恶性的概率是70%.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_73.png" alt=""></p>
<h3 id="1-3-决策边界"><a href="#1-3-决策边界" class="headerlink" title="1.3 决策边界"></a>1.3 决策边界</h3><p>如图所示的Sigmoid函数, 我们可以看到, 当$z&gt;0$的时候$g(z)\ge0.5$即预测$y=1$；当$z&lt;0$的时候$g(z)&lt;0.5$即预测$y=0$.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_619.png" alt=""><br>而在对率回归中, 我们的$z=\theta^Tx$, 所以我们有：当$\theta^Tx\ge0$时, 预测$y=1$；当$\theta^Tx\lt0$时, 预测$y=0$. 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_620.png" alt=""><br>下面举一个例子看一看什么是决策边界. 如下图所示, 左边为数据集. 假设此时我们已经通过训练得到了$\theta=\begin{bmatrix}-3\\ 1\\ 1\end{bmatrix}$, 由上图可知, 当$\theta^Tx\ge0$时, 预测$y=1$. 即当$-3+x_1+x_2\ge0$时, 预测$y=1$；也即当$x_1+x_2\ge3$时, 预测$y=1$. 我们在坐标中画出$x_1+x_2=3$的图形, 如果数据在这条直线的上方, 我们就预测$y=1$；如果数据在这条直线的下方, 我们就预测$y=0$. 我们把$x_1+x_2\ge3$称为决策边界(Decision Boundary).<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_75.png" alt=""><br>下面看一个比较复杂的决策边界的例子. 在线性回归的时候谈到过使用高阶多项式特征, 当然这里我们也可以用. 我们添加两个特征一个是$x_1^2$, 一个是$x_2^2$. 假设我们通过训练得到参数$\theta$, 如下图所示. 当$-1+x_1^2+x_2^2\ge0$的时候, 预测$y=1$. 即$x_1^2+x_2^2\ge1$的时候, 预测$y=1$. 画出$x_1^2+x_2^2=1$的图形, 在圆内$y=0$, 在圆外$y=1$. 这是一个圆形的决策边界.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_621.png" alt=""><br>当我们有更高阶的多项式时, 我们会得到更加复杂的决策边界.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_622.png" alt=""></p>
<h2 id="二-代价函数"><a href="#二-代价函数" class="headerlink" title="二. 代价函数"></a>二. 代价函数</h2><p>在之前的线性回归中, 我们的代价函数为：<font size='4'>$${J(\theta)=\frac{1}{m}\sum_{i=1}^m\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2}$$</font>　　<br>令$$Cost\left(h_\theta(x^{(i)}),y^{(i)}\right)=\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2$$, 简记为$$Cost\left(h_\theta(x),y\right)=\frac{1}{2}\left(h_\theta(x)-y\right)^2$$<br>在线性回归中, 之所以可以使用梯度下降来找到全局最优解是因为代价函数$J(\theta)$是一个凸函数(convex). 但是对于对率回归来说, 假设函数<font size='5'>$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$</font>是一个较为复杂的非线性函数, 直接带入的话得到的代价函数就不是一个凸函数(non-convex), 如下图左侧部分所示. 这样使用梯度下降只能找到局部最优. 所以现在我们需要构造一个合理的并且是凸函数的代价函数<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_77.png" alt=""><br>在对数几率回归中, 使用如下的$Cost\left(h_\theta(x),y\right)$<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_80.png" alt=""><br>当$y=1$时, $Cost\left(h_\theta(x),y\right)$如下图所示. 此时, 如果我们$h_\theta(x)=1$, 那么$Cost=0$, 即当预测结果和真实结果一样时, 我们不对学习算法进行惩罚；但是当结果不一致时, 即$h_\theta(x)→ 0$时, 我们对算法的惩罚趋近于无穷.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_81.png" alt=""><br>同样地, 下图是当$y=0$时的情况.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_82.png" alt=""><br>这样对代价函数处理之后, 我们的代价函数就是一个凸函数, 可以使用梯度下降来站到一个全局最优解.</p>
<h2 id="三-梯度下降"><a href="#三-梯度下降" class="headerlink" title="三. 梯度下降"></a>三. 梯度下降</h2><p>因为y的值只有0或1两种情况, 我们现在将$Cost\left(h_\theta(x),y\right)$用一个式子来表达:<font size='4'>$${Cost\left(h_\theta(x),y\right)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))}$$</font><br>(可以带入验证)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_83.png" alt=""> 　<br>于是得到代价函数:<br><font size='4'>$${J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^my^{(i)}log(h_\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\theta(x^{(i)}))\right]}$$</font><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_84.png" alt=""><br>到这里, 后面的步骤就和线性回归很相似了. 直接利用梯度下降即可. 同样地我们需要求偏导, 求完偏导之后我们发现得到的更新规则和之前线性回归的更性规则是一模一样的. 除了假设函数$h_\theta(x)$不一样. 这里如果特征之间的数量级差别较大也是需要特征缩放的. (注:下图公式中$\alpha$后少了一个$\frac{1}{m}$)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_86.png" alt=""><br>关于偏导数是如何求出的, 可参见<a href="https://share.coursera.org/wiki/index.php/ML:Logistic_Regression" target="_blank" rel="noopener">课程wiki</a>.</p>
<h2 id="四-高级优化算法"><a href="#四-高级优化算法" class="headerlink" title="四. 高级优化算法"></a>四. 高级优化算法</h2><p>除了梯度下降还有其他更加高级更加复杂的算法：Conjugate Gradient、BFGS和L-BFGS. 如下图, 右下角是这些算法的优点和缺点.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_87.png" alt=""><br>下图是一个具体的例子, 右边是自己定义的代价函数, 下方的options是调用fminunc所需的参数, initialTheta是初始的$\theta$, 然后调用fminunc并传入相应的参数就可以得到最优的$\theta$（optTheta）.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_88.png" alt=""><br>代价函数的代码如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function [jVal, gradient] &#x3D; costFunction(theta)</span></pre></td></tr><tr><td class="code"><pre><span class="line">jVal &#x3D; (theta(1)-5)^2 + (theta(2)-5)^2;</span></pre></td></tr><tr><td class="code"><pre><span class="line">gradient &#x3D; zeros(2,1);</span></pre></td></tr><tr><td class="code"><pre><span class="line">gradient(1) &#x3D; 2*(theta(1)-5);</span></pre></td></tr><tr><td class="code"><pre><span class="line">gradient(2) &#x3D; 2*(theta(2)-5);</span></pre></td></tr></table></figure>
<p>在Octave中演示如下:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_91.png" alt=""></p>
<h2 id="五-多分类问题"><a href="#五-多分类问题" class="headerlink" title="五. 多分类问题"></a>五. 多分类问题</h2><p>下图举了一些多分类(Multiclass Classification)的例子.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_93.png" alt=""><br>在之前的二分类(Binary Classification)的问题中, 我们的数据集大概是如下图左侧所示. 而现在的多分类(Multi-class Classification)的问题中数据集如下图左侧所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_94.png" alt=""><br>我们可以使用一对多(One-vs-all/One-vs-rest)方法来处理这个问题, 即将其分成三个二分类的问题. 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_95.png" alt=""><br>预测时, 需要计算出$h_\theta^{(1)}(x)$、$h_\theta^{(2)}(x)$和$h_\theta^{(3)}(x)$的值并得出最大值, 其对应的分类即为预测x的分类.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_96.png" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Logistic Regression</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(四) - Octave教程</title>
    <url>/2016/Coursera-ML-Notes-Week-2-Octave-Tutorial.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_63.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/lecture/9fHfl/basic-operations" target="_blank" rel="noopener">Octave Tutorial</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Octave_Tutorial" target="_blank" rel="noopener">Octave Tutorial</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture5.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture5.pdf" target="_blank" rel="noopener">PDF</a></li>
<li>参考：<a href="http://www.gnu.org/software/octave/doc/interpreter/" target="_blank" rel="noopener">Octave documentation pages</a>　　<a href="http://www.dm.unibo.it/~lenci/teaching/14/maa/octavetut.pdf" target="_blank" rel="noopener">Introduction to Octave</a></li>
</ul>
<a id="more"></a>

<hr>
<h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><h2 id="四则运算"><a href="#四则运算" class="headerlink" title="四则运算"></a>四则运算</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">octave:1&gt; 5+6</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  11</span></pre></td></tr><tr><td class="code"><pre><span class="line">octave:2&gt; 3-2</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  1</span></pre></td></tr><tr><td class="code"><pre><span class="line">octave:3&gt; 5*8</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  40</span></pre></td></tr><tr><td class="code"><pre><span class="line">octave:4&gt; 1&#x2F;2</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  0.50000</span></pre></td></tr></table></figure>

<h2 id="逻辑运算"><a href="#逻辑运算" class="headerlink" title="逻辑运算"></a>逻辑运算</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">octave:6&gt; 1 &#x3D;&#x3D; 2</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D; 0</span></pre></td></tr><tr><td class="code"><pre><span class="line">octave:7&gt; 1 ~&#x3D; 2</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  1</span></pre></td></tr><tr><td class="code"><pre><span class="line">octave:8&gt; 1 &amp;&amp; 0</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D; 0</span></pre></td></tr><tr><td class="code"><pre><span class="line">octave:9&gt; 1 || 0</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  1</span></pre></td></tr><tr><td class="code"><pre><span class="line">octave:10&gt; xor(1,0)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  1</span></pre></td></tr></table></figure>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>更改提示符：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">octave:11&gt; PS1(&#39;&gt;&gt; &#39;)</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt;</span></pre></td></tr></table></figure>
<p>添加分号可抑制输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; a &#x3D; 1</span></pre></td></tr><tr><td class="code"><pre><span class="line">a &#x3D;  1</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; a &#x3D; 1;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt;</span></pre></td></tr></table></figure>
<p>圆周率$\pi$：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; a &#x3D; pi</span></pre></td></tr><tr><td class="code"><pre><span class="line">a &#x3D;  3.1416</span></pre></td></tr></table></figure>
<p>常数$e$：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; e</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  2.7183</span></pre></td></tr></table></figure>
<p>格式化输出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; disp(sprintf(&#39;6 decimals: %0.6f&#39;, a))</span></pre></td></tr><tr><td class="code"><pre><span class="line">6 decimals: 3.141593</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; disp(sprintf(&#39;6 decimals: %0.2f&#39;, a))</span></pre></td></tr><tr><td class="code"><pre><span class="line">6 decimals: 3.14</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; format long </span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; a</span></pre></td></tr><tr><td class="code"><pre><span class="line">a &#x3D;  3.14159265358979</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; format short</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; a</span></pre></td></tr><tr><td class="code"><pre><span class="line">a &#x3D;  3.1416</span></pre></td></tr></table></figure>

<h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>构造一个矩阵，方式一：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A &#x3D; [1 2; 3 4; 5 6;]</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr></table></figure>

<p>构造一个矩阵，方式二：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A &#x3D; [1 2;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt; 3 4;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt; 5 6;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt; ]</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr></table></figure>

<p>构造一个横向量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; v &#x3D; [1 2 3]</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2   3</span></pre></td></tr></table></figure>

<p>构造一个列向量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; v &#x3D; [1; 2; 3]</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3</span></pre></td></tr></table></figure>
<p>从1到2，每次递增0.1</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; v &#x3D; 1:0.1:2</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"> Columns 1 through 5:</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    1.0000    1.1000    1.2000    1.3000    1.4000</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"> Columns 6 through 10:</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    1.5000    1.6000    1.7000    1.8000    1.9000</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line"> Column 11:</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    2.0000</span></pre></td></tr></table></figure>

<p>从1到6，每次递增1(默认)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; v &#x3D; 1:6</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2   3   4   5   6</span></pre></td></tr></table></figure>

<p>所有元素均为1：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; ones(2, 3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   1   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   1   1</span></pre></td></tr></table></figure>

<p>每个元素乘以2：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; C &#x3D; 2*ones(2, 3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">C &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   2   2   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2   2   2</span></pre></td></tr></table></figure>

<p>高斯随机数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; rand(3, 3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.751588   0.906707   0.081204</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.411613   0.457779   0.882052</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.622524   0.774499   0.811092</span></pre></td></tr></table></figure>

<p>所有元素均为0：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; w &#x3D; zeros(1, 3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">w &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   0   0</span></pre></td></tr></table></figure>

<p>单位阵：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; I &#x3D; eye(5)</span></pre></td></tr><tr><td class="code"><pre><span class="line">I &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">Diagonal Matrix</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   0   0   0   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   1   0   0   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   0   1   0   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   0   0   1   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   0   0   0   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   </span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr></table></figure>

<p>读取矩阵A第三行第二列的元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A(3, 2)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  6</span></pre></td></tr></table></figure>

<p>读取矩阵A第2列所有元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A(:,2)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   6</span></pre></td></tr></table></figure>

<p>读取矩阵A第2行所有元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A(2,:)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr></table></figure>

<p>读取矩阵A第1行和第3行的所有元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A([1 3],:)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr></table></figure>

<p>将A第二列替换为[10;11;12]：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A(:,2) &#x3D; [10; 11; 12]</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    1   10</span></pre></td></tr><tr><td class="code"><pre><span class="line">    3   11</span></pre></td></tr><tr><td class="code"><pre><span class="line">    5   12</span></pre></td></tr></table></figure>

<p>在A的最后加上一列：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A &#x3D; [A, [100; 101; 102]]</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">     1    10   100</span></pre></td></tr><tr><td class="code"><pre><span class="line">     3    11   101</span></pre></td></tr><tr><td class="code"><pre><span class="line">     5    12   102</span></pre></td></tr></table></figure>

<p> 将A所有的元素合并成一个列向量 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A(:)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">     1</span></pre></td></tr><tr><td class="code"><pre><span class="line">     3</span></pre></td></tr><tr><td class="code"><pre><span class="line">     5</span></pre></td></tr><tr><td class="code"><pre><span class="line">    10</span></pre></td></tr><tr><td class="code"><pre><span class="line">    11</span></pre></td></tr><tr><td class="code"><pre><span class="line">    12</span></pre></td></tr><tr><td class="code"><pre><span class="line">   100</span></pre></td></tr><tr><td class="code"><pre><span class="line">   101</span></pre></td></tr><tr><td class="code"><pre><span class="line">   102</span></pre></td></tr></table></figure>

<p>两个矩阵的合并（列合并）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A &#x3D; [1 2; 3 4; 5 6]</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; B &#x3D; [7 8; 9 10; 11 12]</span></pre></td></tr><tr><td class="code"><pre><span class="line">B &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    7    8</span></pre></td></tr><tr><td class="code"><pre><span class="line">    9   10</span></pre></td></tr><tr><td class="code"><pre><span class="line">   11   12</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; C &#x3D; [A B]</span></pre></td></tr><tr><td class="code"><pre><span class="line">C &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    1    2    7    8</span></pre></td></tr><tr><td class="code"><pre><span class="line">    3    4    9   10</span></pre></td></tr><tr><td class="code"><pre><span class="line">    5    6   11   12</span></pre></td></tr></table></figure>

<p>两个矩阵的合并（行合并）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; D &#x3D; [A;B]</span></pre></td></tr><tr><td class="code"><pre><span class="line">D &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    1    2</span></pre></td></tr><tr><td class="code"><pre><span class="line">    3    4</span></pre></td></tr><tr><td class="code"><pre><span class="line">    5    6</span></pre></td></tr><tr><td class="code"><pre><span class="line">    7    8</span></pre></td></tr><tr><td class="code"><pre><span class="line">    9   10</span></pre></td></tr><tr><td class="code"><pre><span class="line">   11   12</span></pre></td></tr></table></figure>

<p>查看帮助：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; help eye</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_598.png?imageMogr/v2/thumbnail/!45p" alt=""><br>构造10000个随机数，并绘制出图形(高斯分布)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; w&#x3D;randn(1,10000);</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; hist(w,50)</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/GaussianDistribution.png" alt="高斯分布"> </p>
<h1 id="数据的读取与存储"><a href="#数据的读取与存储" class="headerlink" title="数据的读取与存储"></a>数据的读取与存储</h1><p>本节所用到的数据: <a href="https://raw.githubusercontent.com/tansaku/py-coursera/master/featuresX.dat" target="_blank" rel="noopener">featuresX.dat</a>, <a href="https://raw.githubusercontent.com/tansaku/py-coursera/master/priceY.dat" target="_blank" rel="noopener">priceY.dat</a></p>
<h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">% 找到文件所在目录：</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; cd Desktop&#x2F;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; cd &#39;Machine Learning&#x2F;&#39;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; ls</span></pre></td></tr><tr><td class="code"><pre><span class="line">featuresX.dat	priceY.dat</span></pre></td></tr></table></figure>
<p>数据如下所示：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_599.png?imageMogr/v2/thumbnail/!45p" alt=""><br>读取数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">% 方式一：</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; load featuresX.dat</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; load priceY.dat</span></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">% 方式二：</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; load(&#39;featuresX.dat&#39;)</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; load(&#39;priceY.dat&#39;)</span></pre></td></tr></table></figure>

<p>使用who命令显示当前所有变量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; who</span></pre></td></tr><tr><td class="code"><pre><span class="line">Variables in the current scope:</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">A          a          featuresX  v          y</span></pre></td></tr><tr><td class="code"><pre><span class="line">C          ans        priceY     w</span></pre></td></tr><tr><td class="code"><pre><span class="line">I          c          sz         x</span></pre></td></tr></table></figure>

<p>可以看到，刚才导入的数据已经在变量<code>featuresX</code>和<code>priceY</code>中了。<br>展示数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; featuresX</span></pre></td></tr><tr><td class="code"><pre><span class="line">featuresX &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   2104      3</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1600      3</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2400      3</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1416      2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3000      4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1985      4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1534      3</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ...        ..</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; size(featuresX)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   27    2</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; priceY</span></pre></td></tr><tr><td class="code"><pre><span class="line">priceY &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   3999</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3299</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3690</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2320</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5399</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2999</span></pre></td></tr><tr><td class="code"><pre><span class="line">    ...</span></pre></td></tr><tr><td class="code"><pre><span class="line">    </span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; size(priceY)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   27    1</span></pre></td></tr></table></figure>

<p>使用whos查看变量更详细的信息：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_600.png?imageMogr/v2/thumbnail/!45p" alt=""><br>使用如下命令用来删除某个变量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; clear featuresX</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; whos</span></pre></td></tr></table></figure>
<p>这个时候再使用<code>whos</code>查看，发现featuresX已经不见了。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_601.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h2 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h2><p>假设我们现在需要取出<code>priceY</code>前十个数据，使用如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; v &#x3D; priceY(1:10)</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   3999</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3299</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3690</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2320</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5399</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2999</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3149</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1989</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2120</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2425</span></pre></td></tr></table></figure>
<p>该如何存储这十个数据呢？使用<code>save</code>命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; save hello.mat v</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; ls</span></pre></td></tr><tr><td class="code"><pre><span class="line">featuresX.dat	hello.mat	priceY.dat</span></pre></td></tr></table></figure>
<p>清空所有变量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; clear</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; whos</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; %无任何输出</span></pre></td></tr></table></figure>
<p>刚才存储数据是以二进制的形式进行存储，我们也可以使用人能够读懂的形式存储。例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; load hello.mat</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; whos</span></pre></td></tr><tr><td class="code"><pre><span class="line">Variables in the current scope:</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   Attr Name        Size                     Bytes  Class</span></pre></td></tr><tr><td class="code"><pre><span class="line">   &#x3D;&#x3D;&#x3D;&#x3D; &#x3D;&#x3D;&#x3D;&#x3D;        &#x3D;&#x3D;&#x3D;&#x3D;                     &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;  &#x3D;&#x3D;&#x3D;&#x3D;&#x3D; </span></pre></td></tr><tr><td class="code"><pre><span class="line">        v          10x1                         80  double</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">Total is 10 elements using 80 bytes</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; v</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   3999</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3299</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3690</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2320</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5399</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2999</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3149</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1989</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2120</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2425</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; save hello.txt v -ascii</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; ls</span></pre></td></tr><tr><td class="code"><pre><span class="line">featuresX.dat	hello.mat	hello.txt	priceY.dat</span></pre></td></tr></table></figure>

<h1 id="数据的计算"><a href="#数据的计算" class="headerlink" title="数据的计算"></a>数据的计算</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">% 各种矩阵运算</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; A * B</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; A .* B</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; A .^ 2</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; 1 .&#x2F; A</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; log(A)</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; exp(A)</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; -A</span></pre></td></tr></table></figure>

<p>A中的每个元素都加上1：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A + ones(size(A))</span></pre></td></tr></table></figure>
<p>这样也可以：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A + 1</span></pre></td></tr></table></figure>

<p>矩阵转置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A&#39;</span></pre></td></tr></table></figure>

<p>向量中的最大值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A &#x3D; [1 3 0.5 10 100]</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">     1.00000     3.00000     0.50000    10.00000   100.00000</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; [val ind] &#x3D; max(A)</span></pre></td></tr><tr><td class="code"><pre><span class="line">val &#x3D;  100</span></pre></td></tr><tr><td class="code"><pre><span class="line">ind &#x3D;  5</span></pre></td></tr></table></figure>

<p>比较大小：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A &#x3D; [1 2; 3 4; 5 6]</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; A &gt; 3</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   1</span></pre></td></tr></table></figure>

<p>找出向量中特定元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; find(A &gt; 3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   3</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5</span></pre></td></tr><tr><td class="code"><pre><span class="line">   6</span></pre></td></tr></table></figure>

<p>找出矩阵中特定元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; [r c] &#x3D; find(A &gt;&#x3D; 3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">r &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">c &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr></table></figure>

<p>生成任意行、列、对角线和相等的矩阵：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; magic(3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   8   1   6</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   5   7</span></pre></td></tr><tr><td class="code"><pre><span class="line">   4   9   2</span></pre></td></tr></table></figure>

<p>向量所有元素的和：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; a &#x3D; [1.2 2.3 4.5 6.6]</span></pre></td></tr><tr><td class="code"><pre><span class="line">a &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1.2000   2.3000   4.5000   6.6000</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; sum(a)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  14.600</span></pre></td></tr></table></figure>

<p>向上及向下取整：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; floor(a)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2   4   6</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; ceil(a)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   2   3   5   7</span></pre></td></tr></table></figure>

<p>构造一个由A,B两个矩阵中对应位置较大的数组成的矩阵：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; B &#x3D; [3 1; 4 6; 2 9]</span></pre></td></tr><tr><td class="code"><pre><span class="line">B &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   4   6</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2   9</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; max(A, B)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   4   6</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   9</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr></table></figure>

<p>取出矩阵每列最大的元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; max(A, [], 1)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   5   6</span></pre></td></tr></table></figure>

<p>取出矩阵每行最大的元素：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; max(A, [], 2)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   4</span></pre></td></tr><tr><td class="code"><pre><span class="line">   6</span></pre></td></tr></table></figure>

<p>想要直接获得矩阵中最大的元素，以下两种方式都可以：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">% 方式一：</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; max(max(A))</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  6</span></pre></td></tr><tr><td class="code"><pre><span class="line">% 方式二：</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; max(A(:))</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  6</span></pre></td></tr></table></figure>

<p>矩阵的上下翻转：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; eye(3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">Diagonal Matrix</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   0   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   1   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   0   1</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; flipud(eye(3))</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">Permutation Matrix</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   0   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0   1   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   0   0</span></pre></td></tr></table></figure>

<p>矩阵的逆：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; A &#x3D; rand(3, 3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">A &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.68934   0.12881   0.80507</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.49777   0.41907   0.37271</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.32607   0.27877   0.41814</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; tmp &#x3D; pinv(A)</span></pre></td></tr><tr><td class="code"><pre><span class="line">tmp &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1.795801   4.294380  -7.285421</span></pre></td></tr><tr><td class="code"><pre><span class="line">  -2.180466   0.647802   3.620828</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.053345  -3.780710   5.658801</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; tmp * A</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1.00000   0.00000   0.00000</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0.00000   1.00000   0.00000</span></pre></td></tr><tr><td class="code"><pre><span class="line">  -0.00000  -0.00000   1.00000</span></pre></td></tr></table></figure>

<h1 id="绘制数据"><a href="#绘制数据" class="headerlink" title="绘制数据"></a>绘制数据</h1><p>绘制出sin函数图像：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">x &#x3D; [0: 0.01: 0.98];</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; y &#x3D; sin(2*pi*4*x);</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; plot(x,y);</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_602.png?imageMogr/v2/thumbnail/!55p" alt=""><br>绘制出cos函数图像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">y2 &#x3D; cos(2*pi*4*x);</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_603.png?imageMogr/v2/thumbnail/!55p" alt=""><br>将两个函数绘制在一起：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; plot(x,y);</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; hold on;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; plot(x,y2,&#39;r&#39;)</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_604.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<p>添加说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; xlabel(&quot;time&quot;);</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; ylabel(&quot;value&quot;);</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; lengend(&quot;sin&quot;, &quot;cos&quot;);</span></pre></td></tr><tr><td class="code"><pre><span class="line">error: &#39;lengend&#39; undefined near line 1 column 1</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; legend(&quot;sin&quot;, &quot;cos&quot;);</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_605.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<p>存储图像：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; print -dpng &quot;myPlot.png&quot;</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_606.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<p>关掉绘制的图像：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; close</span></pre></td></tr></table></figure>

<p>分别在两个窗口显示两个图像：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; figure(1); plot(x, y);</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; figure(2); plot(x, y2);</span></pre></td></tr></table></figure>

<p>在同一窗口不同位置显示两个图像：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; subplot(1,2,1);plot(x, y);</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; subplot(1,2,2);plot(x, y2);</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_607.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<p>改变左边图像的横坐标的刻度：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; subplot(1,2,1)</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; axis([0 0.5 -1 1])</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_608.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<p>清除所有绘制的图像：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; clf</span></pre></td></tr></table></figure>

<p>将矩阵可视化：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; imagesc(magic(15))</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_609.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; imagesc(A), colorbar, colormap gray</span></pre></td></tr></table></figure>
<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_610.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<h1 id="控制语句"><a href="#控制语句" class="headerlink" title="控制语句"></a>控制语句</h1><p>for循环：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; for i&#x3D;1:10,</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;      v(i) &#x3D; i^2;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;  end;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; v</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">     1     4     9    16    25    36    49    64    81   100</span></pre></td></tr></table></figure>

<p>while循环：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; i &#x3D; 1;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; while i &lt;&#x3D; 10,</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;      v(i) &#x3D; sqrt(v(i));</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt; </span></pre></td></tr><tr><td class="code"><pre><span class="line">Display all 1753 possibilities? (y or n)</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;      i &#x3D; i + 1;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;  end;</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; v</span></pre></td></tr><tr><td class="code"><pre><span class="line">v &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">    1    2    3    4    5    6    7    8    9   10</span></pre></td></tr></table></figure>
<p>定义一个函数：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_611.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; ls</span></pre></td></tr><tr><td class="code"><pre><span class="line">featuresX.dat		myPlot.png		squareThisNumber.m</span></pre></td></tr><tr><td class="code"><pre><span class="line">hello.mat		octave-workspace</span></pre></td></tr><tr><td class="code"><pre><span class="line">hello.txt		priceY.dat</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; squareThisNumber(3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  9</span></pre></td></tr></table></figure>
<p>如果该定义的函数不在当前目录下，我们就不能使用它：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; cd ~</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; pwd</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D; &#x2F;Users&#x2F;bobo</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; squareThisNumber(3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">error: &#39;squareThisNumber&#39; undefined near line 1 column 1</span></pre></td></tr></table></figure>
<p>不过我们也可以更改Octave的搜索路径：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; addpath(&quot;~&#x2F;Desktop&#x2F;Machine-Learning&quot;)</span></pre></td></tr></table></figure>
<p>更改之后，我们现在虽然在<code>/User/bobo</code>目录下，但是仍然可以使用squareThisNumber函数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; pwd</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D; &#x2F;Users&#x2F;bobo</span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; squareThisNumber(5)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  25</span></pre></td></tr></table></figure>
<p>返回两个值的函数：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_612.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; [y1, y2] &#x3D; squareAndCube(3)</span></pre></td></tr><tr><td class="code"><pre><span class="line">y1 &#x3D;  9</span></pre></td></tr><tr><td class="code"><pre><span class="line">y2 &#x3D;  27</span></pre></td></tr></table></figure>

<p>代价函数：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_613.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; X &#x3D; [1 1; 1 2; 1 3]</span></pre></td></tr><tr><td class="code"><pre><span class="line">X &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1   3</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; y &#x3D; [1; 2; 3]</span></pre></td></tr><tr><td class="code"><pre><span class="line">y &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   1</span></pre></td></tr><tr><td class="code"><pre><span class="line">   2</span></pre></td></tr><tr><td class="code"><pre><span class="line">   3</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; theta &#x3D; [0; 1]</span></pre></td></tr><tr><td class="code"><pre><span class="line">theta &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   1</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; costFunctionJ(X, y, theta)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D; 0</span></pre></td></tr></table></figure>

<p>如果$\theta=[0; 0]$</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt; theta &#x3D; [0; 0]</span></pre></td></tr><tr><td class="code"><pre><span class="line">theta &#x3D;</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">   0</span></pre></td></tr><tr><td class="code"><pre><span class="line">   0</span></pre></td></tr><tr><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="code"><pre><span class="line">&gt;&gt; costFunctionJ(X, y, theta)</span></pre></td></tr><tr><td class="code"><pre><span class="line">ans &#x3D;  2.3333</span></pre></td></tr></table></figure>

<h1 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h1><p><a href="https://www.coursera.org/learn/machine-learning/lecture/WnQWH/vectorization" target="_blank" rel="noopener">Vectorization</a></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Octave</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(三) - 多变量线性回归</title>
    <url>/2016/Coursera-ML-Notes-Week-2-Linear-Regression-with-Multiple-Variables.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_35.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/lecture/6Nj1q/multiple-features" target="_blank" rel="noopener">Linear Regression with Multiple Variables</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Linear_Regression_with_Multiple_Variables" target="_blank" rel="noopener">Linear Regression with Multiple Variables</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture4.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture4.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>

</li>
</ul>
<hr>
<h2 id="一-假设函数-梯度下降"><a href="#一-假设函数-梯度下降" class="headerlink" title="一. 假设函数, 梯度下降"></a>一. 假设函数, 梯度下降</h2><h3 id="1-1-假设函数"><a href="#1-1-假设函数" class="headerlink" title="1.1 假设函数"></a>1.1 假设函数</h3><p>在之前的单变量线性回归中, 我们的问题只涉及到了房子面积这一个特征:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_36.png?imageMogr/v2/thumbnail/!55p" alt=""><br>在实际问题中, 会有很多特征. 例如, 除了房子面积, 还有房子的卧室数量$x_2$, 房子的楼层数$x_3$, 房子建筑年龄$x_4$. 其中, $n$表示特征的数量, $m$表示训练样例的数量, $x^{(i)}$表示$i$个训练样例, $x_j^{(i)}$表示第$i$个训练样例的第$j$个特征.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_37.png?imageMogr/v2/thumbnail/!55p" alt=""><br>在单变量线性回归中假设函数为<font size='4'>$${h_\theta(x)=\theta_0+\theta_1x}$$</font>类似地, 现在假设函数记作：<font size='4'>$${h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n}$$</font>可是每次这样写太麻烦了, 为了方便首先定义$x_0=1$(即$x_0^{(i)}=1$), 此时$h_\theta(x)$为：<font size='4'>$${h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n}$$</font>再令：<font size='3'>${\qquad\qquad\theta=\begin{bmatrix}\theta_0\\ \theta_1\\ \theta_2\\.\\.\\.\\ \theta_n \end{bmatrix}\in \rm I\!R^{n+1}\quad,\qquad\qquad}$ ${x=\begin{bmatrix}x_0\\x_1\\x_2\\.\\.\\.\\x_n \end{bmatrix}\in \rm I\!R^{n+1}}$</font><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_829.png" alt=""><br>这样就得到了假设函数的向量表示:<font size='4'>$${h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n= \theta^Tx}$$</font></p>
<h3 id="1-2-梯度下降"><a href="#1-2-梯度下降" class="headerlink" title="1.2 梯度下降"></a>1.2 梯度下降</h3><p>多变量情况下的梯度下降其实没有区别, 只需要把对应的偏导数项换掉即可.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_40.png?imageMogr/v2/thumbnail/!55p" alt="">　</p>
<h2 id="二-特征处理"><a href="#二-特征处理" class="headerlink" title="二. 特征处理"></a>二. 特征处理</h2><h3 id="2-1-特征缩放"><a href="#2-1-特征缩放" class="headerlink" title="2.1 特征缩放"></a>2.1 特征缩放</h3><p>如果每个特征的范围相差的很大, 梯度下降会很慢. 为了解决这个问题, 我们在梯度下降之前应该对数据做特征归缩放(Feature Scaling)处理, 从而将所有的特征的数量级都在一个差不多的范围之内, 以加快梯度下降的速度.<br>假设现在我们有两个特征, 房子的面积和房间的数量. 如下图所示, 他们的范围相差的非常大. 对于这样的数据, 它的代价函数大概如下图左边, 梯度下降要经过很多很多次的迭代才能达到最优点. 如果我们对这两个特征按照右边给出的公式进行特征缩放, 那么此时的代价函数如下图右边所示, 相对于之前, 可以大大减少梯度下降的迭代次数.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_41.png?imageMogr/v2/thumbnail/!55p" alt=""><br>通常我们需要把特征都缩放到$[-1,1]$(附近)这个范围.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_595.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<h3 id="2-2-均值归一化"><a href="#2-2-均值归一化" class="headerlink" title="2.2 均值归一化"></a>2.2 均值归一化</h3><p>还有一个特征处理的方法就是均值归一化(Mean normalization):<br><font size='4'>$${x_i=\frac{x_i-\mu_i}{max-min}}$$</font>或者,<br><font size='4'>$${x_i=\frac{x_i-\mu_i}{\sigma_i}}$$</font><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_42.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<h2 id="三-代价函数与学习率"><a href="#三-代价函数与学习率" class="headerlink" title="三. 代价函数与学习率"></a>三. 代价函数与学习率</h2><p>我们可以通过画出$\mathop{min}\limits_{\theta}J(\theta)$与迭代次数数的关系图来观察梯度下降的运行. 如下图所示, 横坐标是迭代次数, 纵坐标是代价函数的值. 如果梯度算法正常运行的话, 代价函数的图像大概的形状如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_596.png?imageMogr/v2/thumbnail/!55p" alt=""><br>还有一种叫自动收敛测试的方法, 即每次迭代之后观察$J(\theta)$的值, 如果迭代之后下降的值小于$\epsilon$(例如$\epsilon=10^{-3}$)就判定为收敛. 不过准确地选择阈值$\epsilon$是非常困难的, 通常还是使用画图的方法.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_597.png?imageMogr/v2/thumbnail/!55p" alt=""><br>如果出现了下面的两种情况, 这个时候应该选择更小的$\alpha$. 注意: 1.如果$\alpha$足够小, 那么$J(\theta)$在每次迭代之后都会减小. 2.但是如果太小, 梯度下降会进行的非常缓慢.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_44.png?imageMogr/v2/thumbnail/!55p" alt=""><br>可以使用下面几个值进行尝试.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_45.png?imageMogr/v2/thumbnail/!55p" alt=""></p>
<h2 id="四-特征选择与多项式回归"><a href="#四-特征选择与多项式回归" class="headerlink" title="四. 特征选择与多项式回归"></a>四. 特征选择与多项式回归</h2><p>假设预测房屋价格, 选取房屋的长和宽作为变量, 得到如下的假设函数：<br>$$h(\theta)=\theta_0+\theta_1\times frontage+\theta_1\times depth$$<br>当然, 我们觉得真正决定房屋价格应该是与房屋的面积有关. 这时候我们也可以重新选择我们的特征$x=frontage\times depth$, 此时的假设函数为：<br>$$h(\theta)=\theta_0+\theta_1x$$<br>通过这种特征的选择, 我们可能得到一个更好的模型.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_46.png?imageMogr/v2/thumbnail/!55p" alt=""><br>和这个密切相关的一个概念就是多项式回归(Polynomial Regression). 假设有下图所示的关于房屋价格的数据集, 我们有多种模型去拟合(下图右所示). 第一个模型是一个二次函数, 但是二次函数是一个抛物线, 这里不符合(因为房价不会随着房子面积的增加二减小)；所以我们选择三次函数的模型, 想要使用该模型去拟合. 那么我们该如何将这个模型运用在我们的数据上呢？我们可以将房屋的面积作为第一个特征, 面积的平方作为第二个特征, 面积的立方作为第三个特征, 如下图左下角所示. (这里需要注意的是, $x_0,x_1,x_2$的范围差别会非常大, 所以一定要进行特征缩放处理）<br><img id="polynomialregression" src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_47.png?imageMogr/v2/thumbnail/!55p"/><br>除了三次函数模型, 这里也可以选择平方根函数模型, 如下图所示.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_48.png?imageMogr/v2/thumbnail/!55p" alt="">
　　</p>
<h2 id="五-正规方程"><a href="#五-正规方程" class="headerlink" title="五. 正规方程"></a>五. 正规方程</h2><h3 id="5-1-正规方程"><a href="#5-1-正规方程" class="headerlink" title="5.1 正规方程"></a>5.1 正规方程</h3><p>之前我们一直是用的梯度下降求解最优值. 它的缺点就是需要进行很多次迭代才能得到全局最优解. 有没有更好的方法呢? 我们先来看一个最简单的例子, 假设现在的代价函数为$J(\theta)=a\theta^2+b\theta+c$, $\theta$是一个实数. 怎样得到最优解? 很简单, 只要令它的导数为0就可以了.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_56.png?imageMogr/v2/thumbnail/!55p" alt=""><br>事实上, 代价函数不会像例子那样简单, $\theta$也不是一个实数而是一个$n+1$维的向量. 这样, 我们分别对每个$\theta$求偏导, 再令偏导等于0, 既可以计算出左右的$\theta$了. 但看上去还是很繁琐, 所以下面我们介绍一种向量化的求解方法.<br>首先, 在数据集前加上一列$x_0$, 值都为1；然后将所有的变量都放入矩阵$X$中(包括加上的$x_0$)；再将输出值放入向量$y$中. 最后通过公式$\theta=(X^TX)^{-1}X^Ty$, 就可以算出$\theta$的值.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_57.png?imageMogr/v2/thumbnail/!55p" alt=""><br>下图是一个更通用的表达方式：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_58.png?imageMogr/v2/thumbnail/!55p" alt=""><br>在Octave中, 可用如下命令计算:<br>　　<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">　　pinv(x&#39;*x)*x&#39;*y</span></pre></td></tr></table></figure><br>这个公式叫做正规方程, 使用这种方法还有一个好处就是不需要进行特征缩放处理. </p>
<h3 id="5-2-梯度下降与正规方程的比较"><a href="#5-2-梯度下降与正规方程的比较" class="headerlink" title="5.2 梯度下降与正规方程的比较"></a>5.2 梯度下降与正规方程的比较</h3><p>下图是梯度下降(Gradient Descent)和正规方程(Normal Equation)两种方法优缺点的比较：</p>
<table>
<thead>
<tr>
<th align="center">梯度下降</th>
<th align="center">正规方程</th>
</tr>
</thead>
<tbody><tr>
<td align="center">需要选择学习率$\alpha$</td>
<td align="center">不需要选择学习率$\alpha$</td>
</tr>
<tr>
<td align="center">需要很多次迭代</td>
<td align="center">不需要迭代</td>
</tr>
<tr>
<td align="center">当有大量特征时, 也能正常工作</td>
<td align="center">需要计算$(X^TX)^{-1}$ ($O(n^3)$, n非常大时, 计算非常慢)</td>
</tr>
<tr>
<td align="center"><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_59.png?imageMogr/v2/thumbnail/!55p" alt=""></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">### 5.3 正规方程不可逆的情况</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">使用正规方程还有一个问题就是$X^TX$可能存在不可逆的情况. 这个时候, 可能是因为我们使用了冗余的特征, 还有一个原因是我们使用了太多的特征(特征的数量超过了样本的数量). 对于这种情况我们可以删掉一些特征或者使用正则化(正则化在后面的课中讲).</td>
<td align="center"></td>
</tr>
<tr>
<td align="center"><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_830.png" alt=""></td>
<td align="center"></td>
</tr>
</tbody></table>
<p>　</p>
<p>　　</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Linear Regression</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(二) - 单变量线性回归</title>
    <url>/2016/Coursera-ML-Notes-Week-1-Linear-Regression-with-One-Variable.html</url>
    <content><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_02.png" alt=""></p>
<ul>
<li>课程地址：<a href="https://www.coursera.org/learn/machine-learning/home/week/1" target="_blank" rel="noopener">Linear Regression with One Variable</a></li>
<li>课程Wiki：<a href="https://share.coursera.org/wiki/index.php/ML:Linear_Regression_with_One_Variable" target="_blank" rel="noopener">Linear Regression with One Variable</a></li>
<li>课件：<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture2.pptx" target="_blank" rel="noopener">PPT</a>　<a href="https://d396qusza40orc.cloudfront.net/ml/docs/slides/Lecture2.pdf" target="_blank" rel="noopener">PDF</a><a id="more"></a>
</li>
</ul>
<hr>
<h2 id="一-基本概念"><a href="#一-基本概念" class="headerlink" title="一. 基本概念"></a>一. 基本概念</h2><p>这一节我们来学习单变量的线性回归模型, 首先了解基本概念. </p>
<h3 id="1-1-训练集"><a href="#1-1-训练集" class="headerlink" title="1.1 训练集"></a>1.1 训练集</h3><p>由训练样例(training example)组成的集合就是训练集(training set), 如下图所示, 其中$(x, y)$是一个训练样例, $(x^{(i)}, y^{(i)})$是第$i$个训练样例.<br>   <img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_05.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h3 id="1-2-假设函数"><a href="#1-2-假设函数" class="headerlink" title="1.2 假设函数"></a>1.2 假设函数</h3><p>使用某种学习算法对训练集的数据进行训练, 我们可以得到假设函数(Hypothesis Function), 如下图所示. 在房价的例子中，假设函数就是一个房价关于房子面积的函数。有了这个假设函数之后, 给定一个房子的面积我们就可以预测它的价格了.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_583.png?imageMogr/v2/thumbnail/!55p" alt=""><br>我们使用如下的形式表示假设函数, 为了方便$h_\theta(x)$也可以记作$h(x)$.<br><font size='4'>$${h_\theta(x)=\theta_0+\theta_1x}$$</font><br>以上这个模型就叫做单变量的线性回归(Linear Regression with One Variable). (Linear regression with one variable = Univariate linear regression，univariate是one variable的装逼写法.)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_584.png?imageMogr/v2/thumbnail/!55p" alt="">  </p>
<h2 id="二-代价函数"><a href="#二-代价函数" class="headerlink" title="二. 代价函数"></a>二. 代价函数</h2><h3 id="2-1-什么是代价函数"><a href="#2-1-什么是代价函数" class="headerlink" title="2.1 什么是代价函数"></a>2.1 什么是代价函数</h3><p>只要我们知道了假设函数, 我们就可以进行预测了. 关键是, 假设函数中有两个未知的量$\theta_0, \theta_1$. 当选择不同的$\theta_0$和$\theta_1$时, 我们模型的效果肯定是不一样的. 如下图所示, 列举了三种不同的$\theta_0$和$\theta_1$下的假设函数.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_08.png" alt=""><br>现在的问题就是该如何选择这两个参数了. 我们的想法是选择某个<br>$\theta_0$和$\theta_1$，使得对于训练样例$(x,y)$，$h_\theta(x)$最”接近”$y$。越是接近, 代表这个假设函数越是准确, 这里我们选择均方误差来作为衡量标准, 即我们想要每个样例的估计值与真实值之间差的平方的均值最小。用公式表达为:<br><font size='4'><br>$${\mathop{minimize}\limits_{\theta_0,\theta_1} \frac{1}{2m}\sum_{i=0}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2}$$<br></font><br>(其中的$1/2$只是为了后面计算的方便)我们记:<br><font size='4'><br>$${J(\theta_0,\theta_1)=\frac{1}{2m}\sum_{i=0}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2}$$<br></font><br>这样就得到了我们的代价函数(cost function), 也就是我们的优化目标, 我们想要代价函数最小:<br><font size='4'>$$\mathop{minimize}\limits_{\theta_0,\theta_1}J(\theta_0,\theta_1)$$</font><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_10.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h3 id="2-2-代价函数与假设函数"><a href="#2-2-代价函数与假设函数" class="headerlink" title="2.2 代价函数与假设函数"></a>2.2 代价函数与假设函数</h3><p>现在为了更方便地探究$h_\theta(x)$与$J(\theta_0,\theta_1)$的关系, 先令$\theta_0$等于0, 得到了简化后的假设函数，有假设函数的定义可知此时的假设函数是经过原点的直线. 相应地也也得到简化的代价函数。如图所示:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_11.png?imageMogr/v2/thumbnail/!45p" alt=""><br>简化之后，我们令$\theta_1$等于1, 就得到$h_\theta(x)=x$如下图左所示。图中三个红叉表示训练样例，通过代价函数的定义我们计算得出$J(1)=0$，对应下图右中的$(1,0)$坐标。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_12.png?imageMogr/v2/thumbnail/!45p" alt=""><br>重复上面的步骤，再令$\theta_1=0.5$，得到$h_\theta(x)$如下图左所示。通过计算得出$J(0.5)=0.58$，对应下图右中的$(0.5,0.58)$坐标。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_13.png?imageMogr/v2/thumbnail/!45p" alt=""><br>对于不同的$\theta_1$，对应着不同的假设函数$h_\theta(x)$，于是就有了不同的$J(\theta_1)$的值。将这些点连接起来就可以得到$J(\theta_1)$关于$\theta_1$的函数图像，如下图所示：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_14.png?imageMogr/v2/thumbnail/!45p" alt=""><br>我们的目标就是找到一个$\theta$使得$J(\theta)$最小, 通过上面的描点作图的方式, 我们可以从图中看出, 当$\theta_1=1$的时候, $J(\theta)$取得最小值. </p>
<h3 id="2-3-代价函数与假设函数II"><a href="#2-3-代价函数与假设函数II" class="headerlink" title="2.3 代价函数与假设函数II　　"></a>2.3 代价函数与假设函数II　　</h3><p>在上一节中，我们令$\theta_0$等于0, 并且通过设置不同的$\theta_1$来描点作图得到$J(\theta_1)$的曲线。这一节我们不再令$\theta_0=0$, 而是同时设置$\theta_0$和$\theta_1$的值, 然后再绘出$J(\theta_0, \theta_1)$的图形. 因为此时有两个变量，很容易想到$J(\theta_1)$应该是一个曲面, 如下图所示:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_16.png?imageMogr/v2/thumbnail/!45p" alt=""><br>这个图是教授用matlab绘制的，由于3D图形不太方便我们研究，我们就使用二维的等高线(上图右上角教授写的contour plots/figures)，这样看上去比较清楚一些。如下图右，越靠近中心表示$J(\theta_0,\theta_1)$的值越小(对应3D图中越靠近最低点的位置)。下图左表示当$\theta_0=800$, $\theta_1=0.15$的时候对应的$h_\theta(x)$，通过$\theta_0$, $\theta_1$的值可以找到下图右中$J(\theta_0,\theta_1)$的值。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_17.png?imageMogr/v2/thumbnail/!45p" alt=""><br>类似地：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_18.png?imageMogr/v2/thumbnail/!45p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_19.png?imageMogr/v2/thumbnail/!45p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_20.png?imageMogr/v2/thumbnail/!45p" alt=""><br>我们不断尝试直到找到一个最佳的$h_\theta(x)$。是否有特定的算法能帮助我们找到最佳的$h_\theta(x)$呢? 下面我们就要介绍这个算法-梯度下降算法.</p>
<h2 id="三-梯度下降算法"><a href="#三-梯度下降算法" class="headerlink" title="三. 梯度下降算法"></a>三. 梯度下降算法</h2><h3 id="3-1-梯度下降"><a href="#3-1-梯度下降" class="headerlink" title="3.1 梯度下降"></a>3.1 梯度下降</h3><p><a href="https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95" target="_blank" rel="noopener">梯度下降算法</a>是一种优化算法, 它可以帮助我们找到一个函数的局部极小值点. 它不仅仅可以用在线性回归模型中, 在机器学习许多其他的模型中也可以使用它. 对于我们现在研究的单变量线性回归来说, 我们想要使用梯度下降来找到最优的$\theta_0, \theta_1$. 它的思想是, 首先随机选择两个$\theta_0, \theta_1$(例如, $\theta_0=0, \theta_1=0$), 不断地改变它们的值使得$J(\theta)$变小, 最终找到$J(\theta)$的最小值点.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_21.png?imageMogr/v2/thumbnail/!45p" alt=""><br>可以把梯度下降的过程想象成下山坡, 如果想要尽可能快的下坡, 应该每次都往坡度最大的方向下山.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_22.png?imageMogr/v2/thumbnail/!45p" alt=""><br>梯度下降算法得到的结果会受到初始状态的影响, 即当从不同的点开始时, 可能到达不同的局部极小值, 如下图:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_23.png?imageMogr/v2/thumbnail/!45p" alt=""><br>下面具体看一下算法的过程, 如下图所示, 其中$:=$表示赋值，$\alpha$叫做学习率用来控制下降的幅度，$\frac{\partial}{\partial\theta_j}J(\theta_0, \theta_1)$叫做梯度。这里一定要注意的是，算法每次是同时(simultaneously)改变$\theta_0$和$\theta_1$的值，如图下图所示。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_24.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h3 id="3-2-梯度和学习率"><a href="#3-2-梯度和学习率" class="headerlink" title="3.2 梯度和学习率"></a>3.2 梯度和学习率</h3><p>我们先来看看梯度下降算法的梯度是如何帮助我们找到最优解的. 为了研究问题的方便我们还是同样地令$\theta_0$等于0，假设一开始选取的$\theta_1$在最低点的右侧，此时的梯度(斜率)是一个正数。根据上面的算法更新$\theta_1$的时候，它的值会减小, 即靠近最低点。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_26.png?imageMogr/v2/thumbnail/!45p" alt=""><br>类似地假设一开始选取的$\theta_1$在最低点的左侧，此时的梯度是一个负数，根据上面的算法更新$\theta_1$的时候，它的值会增大，也会靠近最低点.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_27.png?imageMogr/v2/thumbnail/!45p" alt=""><br>如果一开始选取的$\theta_1$恰好在最适位置，那么更新$\theta_1$时，它的值不会发生变化。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_29.png?imageMogr/v2/thumbnail/!45p" alt=""><br>学习率$\alpha$会影响梯度下降的幅度。如果$\alpha$太小, $\theta$的值每次会变化的很小，那么梯度下降就会非常慢；相反地，如果$\alpha$过大，$\theta$的值每次会变化会很大，有可能直接越过最低点，可能导致永远没法到达最低点。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_28.png?imageMogr/v2/thumbnail/!45p" alt=""><br>由于随着越来越接近最低点, 相应的梯度(绝对值)也会逐渐减小，所以每次下降程度就会越来越小, 我们并不需要减小$\alpha$的值来减小下降程度。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_31.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h3 id="3-3-计算梯度"><a href="#3-3-计算梯度" class="headerlink" title="3.3 计算梯度"></a>3.3 计算梯度</h3><p>根据定义, 梯度也就是代价函数对每个$\theta$的偏导:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_585.png?imageMogr/v2/thumbnail/!45p" alt=""><br>我们将$h_\theta(x^{(i)})=\theta_0+\theta_1x^{(i)}$带入到$J(\theta_0,\theta_1)$中，并且分别对$\theta_0$和$\theta_1$求导得:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_32.png?imageMogr/v2/thumbnail/!45p" alt=""><br>由此得到了完整的梯度下降算法:<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_33.png?imageMogr/v2/thumbnail/!45p" alt=""><br>还记得这个图吗, 前面说了梯度下降算法得到的结果会受初始状态的影响, 即初始状态不同, 结果可能是不同的局部最低点.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_23.png?imageMogr/v2/thumbnail/!45p" alt=""><br>事实上，用于线性回归的代价函数总是一个凸函数(Convex Function)。这样的函数没有局部最优解，只有一个全局最优解。所以我们在使用梯度下降的时候，总会得到一个全局最优解。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_16.png?imageMogr/v2/thumbnail/!45p" alt=""><br>下面我们来看一下梯度下降的运行过程：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_586.png?imageMogr/v2/thumbnail/!45p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_587.png?imageMogr/v2/thumbnail/!45p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_588.png?imageMogr/v2/thumbnail/!45p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_589.png?imageMogr/v2/thumbnail/!45p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_590.png?imageMogr/v2/thumbnail/!45p" alt=""><br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_592.png?imageMogr/v2/thumbnail/!45p" alt=""><br>迭代多次后，我们得到了最优解。现在我们可以用最优解对应的假设函数来对房价进行预测了。例如一个1,250平方英尺的房子大概能卖到250k$，如下图所示：<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_593.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<p>　　
　　　　
　　
　　
　　</p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Notes</tag>
        <tag>Coursera</tag>
        <tag>MOOC</tag>
        <tag>Linear Regression</tag>
      </tags>
  </entry>
  <entry>
    <title>Coursera机器学习笔记(一) - 监督学习vs无监督学习</title>
    <url>/2016/Coursera-ML-Notes-Week-1-Introduction.html</url>
    <content><![CDATA[<p><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_03.png" alt=""></p>
<h2 id="一-监督学习"><a href="#一-监督学习" class="headerlink" title="一. 监督学习"></a>一. 监督学习</h2><p>什么是监督学习? 我们来看看<a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92" target="_blank" rel="noopener">维基百科</a>中给出的定义:</p>
<blockquote>
<p>监督式学习（英语：Supervised learning），是一个机器学习中的方法，可以由训练资料中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。训练资料是由输入物件（通常是向量）和预期输出所组成。函数的输出可以是一个连续的值（称为回归分析），或是预测一个分类标签（称作分类）</p>
</blockquote>
<a id="more"></a>

<hr>
<p>从数据的角度来讲, 监督学习和无监督学习的区别就在于监督学习的数据不仅仅有特征组成, 即每一个数据样本都包含一个准确的输出值. 在房价预测的问题中, 数据由特征+房价组成.</p>
<h3 id="1-1-监督学习的分类"><a href="#1-1-监督学习的分类" class="headerlink" title="1.1 监督学习的分类"></a>1.1 监督学习的分类</h3><p>在监督学习中, 我们的预测结果可以是连续值, 也可以是离散值. 我们根据这样的属性将监督学习氛围回归问题和分类问题.</p>
<p>$$<br>\text{监督学习:}<br>   \begin{cases}<br>   \text{回归}(\text{Regression})\<br>      \<br>   \text{分类}(\text{Classification})<br>   \end{cases}<br>$$</p>
<p>下面我们分别举一个例子来看看, 学完这两个例子之后, 我们就会对监督学习, 回归以及分类有比较清晰地认识了.</p>
<h3 id="1-2-监督学习举例"><a href="#1-2-监督学习举例" class="headerlink" title="1.2 监督学习举例"></a>1.2 监督学习举例</h3><h4 id="1-2-1-回归问题"><a href="#1-2-1-回归问题" class="headerlink" title="1.2.1 回归问题"></a>1.2.1 回归问题</h4><p>我们现在有这么一个问题, 我们想通过给定的一个房子的面积来预测这个房子在市场中的价格. 这里的房子的面积就是特征, 房子的价格就是一个输出值. 为了解决这个问题, 我们获取了大量的房地产数据, 每一条数据都包含房子的面积及其对应价格. 第一, 我们的数据不仅包含房屋的面积, 还包含其对应的价格, 而我们的目标就是通过面积预测房价. 所以这应该是一个监督学习; 其次, 我们的输出数据房价可以看做是连续的值, 所以这个问题是一个回归问题. 至于如何通过数据得到可以使用的模型, 后面的几节课我们再做讨论.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/img_1.jpg?imageMogr/v2/thumbnail/!45p" alt=""><br>思考: 如果对于同样的数据, 但是我们的目标是预测这个房子的房价是大于100w还是小于100w, 那么这个时候是什么哪一类问题?</p>
<h4 id="1-2-2-分类问题"><a href="#1-2-2-分类问题" class="headerlink" title="1.2.2 分类问题"></a>1.2.2 分类问题</h4><p>我们再来看一个分类问题, 从名字上来讲, 分类问题还是比较好理解的, 我们的目标应该是要对数据进行分类. 现在我们的数据是有关乳腺癌的医学数据, 它包含了肿瘤的大小以及该肿瘤是良性的还是恶性的. 我们的目标是给定一个肿瘤的大小来预测它是良性还是恶性. 我们可以用0代表良性，1代表恶性. 这就是一个分类问题, 因为我们要预测的是一个离散值. 当然, 在这个例子中, 我们的离散值可以去’良性’或者’恶性’. 在其他分类问题中, 离散值可能会大于两个.例如在该例子中可以有{0,1,2,3}四种输出，分别对应{良性, 第一类肿瘤, 第二类肿瘤, 第三类肿瘤}。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/img_1022aa.jpg?imageMogr/v2/thumbnail/!45p" alt=""><br>在这个例子中特征只有一个即瘤的大小。 对于大多数机器学习的问题, 特征往往有多个(上面的房价问题也是, 实际中特征不止是房子的面积). 例如下图， 有“年龄”和“肿瘤大小”两个特征。(还可以有其他许多特征，如下图右侧所示)<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/img_1018abc.jpg?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h2 id="二-无监督学习"><a href="#二-无监督学习" class="headerlink" title="二. 无监督学习"></a>二. 无监督学习</h2><p>在监督学习中我们也提到了它与无监督学习的区别. 在无监督学习中, 我们的数据并没有给出特定的标签, 例如上面例子中的房价或者是良性还是恶性. 我们目标也从预测某个值或者某个分类便成了寻找数据集中特殊的或者对我们来说有价值结构. 如下图所示, 我们可以直观的感受到监督学习和无监督学习在数据集上的区别.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/screenshot_582.png?imageMogr/v2/thumbnail/!55p" alt=""><br>我们也可以从图中看到, 大概可以将数据及分成两个簇. 将数据集分成不同簇的无监督学习算法也被称为聚类算法.<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/img_1025dadc.jpg?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h3 id="2-1-无监督学习举例"><a href="#2-1-无监督学习举例" class="headerlink" title="2.1 无监督学习举例"></a>2.1 无监督学习举例</h3><p>想要了解这些例子更详细的内容可以看<a href="https://www.coursera.org/learn/machine-learning/lecture/olRZo/unsupervised-learning" target="_blank" rel="noopener">上课视频</a>.</p>
<h4 id="2-1-1-新闻分类"><a href="#2-1-1-新闻分类" class="headerlink" title="2.1.1 新闻分类"></a>2.1.1 新闻分类</h4><p>第一个例子举的是Google News的例子。Google News搜集网上的新闻，并且根据新闻的主题将新闻分成许多簇, 然后将在同一个簇的新闻放在一起。如图中红圈部分都是关于BP Oil Well各种新闻的链接，当打开各个新闻链接的时候，展现的都是关于BP Oil Well的新闻。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/img_0168.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h4 id="2-1-2-根据给定基因将人群分类"><a href="#2-1-2-根据给定基因将人群分类" class="headerlink" title="2.1.2 根据给定基因将人群分类"></a>2.1.2 根据给定基因将人群分类</h4><p>如图是DNA数据，对于一组不同的人我们测量他们DNA中对于一个特定基因的表达程度。然后根据测量结果可以用聚类算法将他们分成不同的类型。<br><img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/img_0169.png?imageMogr/v2/thumbnail/!45p" alt=""></p>
<h4 id="2-1-3-鸡尾酒派对效应"><a href="#2-1-3-鸡尾酒派对效应" class="headerlink" title="2.1.3 鸡尾酒派对效应"></a>2.1.3 鸡尾酒派对效应</h4><p>详见课程: <a href="https://www.coursera.org/learn/machine-learning/lecture/olRZo/unsupervised-learning" target="_blank">Unsupervised Learning</a></p>
<h4 id="2-1-4-其他"><a href="#2-1-4-其他" class="headerlink" title="2.1.4 其他"></a>2.1.4 其他</h4><p>这里又举了其他几个例子，有组织计算机集群，社交网络分析，市场划分，天文数据分析等。具体可以看一下视频：<a href="https://www.coursera.org/learn/machine-learning/lecture/olRZo/unsupervised-learning" target="_blank">Unsupervised Learning</a><br>   <img src="https://hexo-blog-1256212224.cos.ap-shanghai.myqcloud.com/img_1024abc.jpg?imageMogr/v2/thumbnail/!45p" alt=""></p>
]]></content>
      <tags>
        <tag>Machine Learning</tag>
        <tag>Supervised Learning</tag>
        <tag>UnSupervised Learning</tag>
      </tags>
  </entry>
</search>
